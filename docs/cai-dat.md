# üöÄ INSTALLATION GUIDE

H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t m√¥i tr∆∞·ªùng cho d·ª± √°n Money Laundering Detection.

---

## üìã Y√™u c·∫ßu h·ªá th·ªëng

### Hardware
- **RAM:** ‚â• 16GB (khuy·∫øn ngh·ªã 32GB)
- **Disk:** ‚â• 50GB tr·ªëng
- **CPU:** Multi-core (4+ cores khuy·∫øn ngh·ªã)

### Software
- **OS:** Linux (CachyOS/Arch ho·∫∑c Ubuntu/Debian)
- **Python:** 3.10+
- **Java:** 11 ho·∫∑c 17 (cho Hadoop/Spark)
- **HDFS:** Hadoop 3.x

---

## üîß C√†i ƒë·∫∑t t·ª´ng b∆∞·ªõc

### 1. C√†i ƒë·∫∑t UV Package Manager (Khuy·∫øn ngh·ªã)

**UV** l√† package manager c·ª±c nhanh cho Python, thay th·∫ø pip.

```bash
# C√†i UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Ho·∫∑c v·ªõi pacman (Arch/CachyOS)
sudo pacman -S uv

# Reload shell
source ~/.zshrc

# Ki·ªÉm tra
uv --version
```

### 2. Setup Project v·ªõi UV

```bash
# Di chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c project
cd /home/ultimatebrok/Downloads/Final

# T·∫°o virtual environment v·ªõi UV (t·ª± ƒë·ªông)
uv venv

# K√≠ch ho·∫°t
source .venv/bin/activate

# C√†i t·∫•t c·∫£ dependencies (C·ª∞C NHANH!)
uv pip install -r requirements.txt

# Ki·ªÉm tra
python -c "import polars, pyspark, plotly; print('‚úÖ All packages installed!')"
```

### 3. (Alternative) S·ª≠ d·ª•ng pip truy·ªÅn th·ªëng

N·∫øu kh√¥ng mu·ªën d√πng UV:

```bash
# T·∫°o venv
python -m venv .venv
source .venv/bin/activate

# Upgrade pip
pip install --upgrade pip

# C√†i dependencies
pip install -r requirements.txt
```

### 4. Apache Spark

```bash
# Ch·∫°y installation script
./scripts/setup/install_spark.sh

# Reload shell
source ~/.zshrc

# Ki·ªÉm tra
spark-submit --version
```

### 5. Hadoop/HDFS Setup

#### Option A: Standalone HDFS (khuy·∫øn ngh·ªã cho development)

```bash
# Arch/CachyOS
sudo pacman -S hadoop

# Ubuntu/Debian
sudo apt install hadoop
```

#### Option B: Spark local mode (kh√¥ng c·∫ßn HDFS)

Spark c√≥ th·ªÉ ch·∫°y local mode m√† kh√¥ng c·∫ßn HDFS cluster.

---

## ‚úÖ Ki·ªÉm tra c√†i ƒë·∫∑t

### Python packages

```bash
python << EOF
import polars as pl
import numpy as np
import pyspark
import plotly
import matplotlib
import seaborn

print("‚úÖ Polars:", pl.__version__)
print("‚úÖ NumPy:", np.__version__)
print("‚úÖ PySpark:", pyspark.__version__)
print("‚úÖ Plotly:", plotly.__version__)
print("‚úÖ All packages OK!")
EOF
```

### Jupyter

```bash
# Ki·ªÉm tra Jupyter Lab
jupyter lab --version

# Kh·ªüi ƒë·ªông (test)
jupyter lab --no-browser --port=8888
# Ctrl+C ƒë·ªÉ tho√°t
```

### HDFS (n·∫øu d√πng)

```bash
# Kh·ªüi ƒë·ªông HDFS
start-dfs.sh

# Ki·ªÉm tra
hdfs dfsadmin -report

# D·ª´ng
stop-dfs.sh
```

---

## üì¶ Dependencies chi ti·∫øt

### Core Data Processing
| Package | Version | M·ª•c ƒë√≠ch |
|---------|---------|----------|
| polars | ‚â•0.19.0 | Fast DataFrame operations |
| numpy | ‚â•1.24.0 | Numerical computing |
| pandas | ‚â•2.1.0 | Data manipulation |
| pyarrow | ‚â•14.0.0 | Columnar format |

### Big Data
| Package | Version | M·ª•c ƒë√≠ch |
|---------|---------|----------|
| pyspark | ‚â•3.5.0 | Distributed computing |

### Jupyter
| Package | Version | M·ª•c ƒë√≠ch |
|---------|---------|----------|
| jupyter | ‚â•1.0.0 | Notebook environment |
| jupyterlab | ‚â•4.0.0 | Modern interface |
| notebook | ‚â•7.0.0 | Classic notebook |
| ipywidgets | ‚â•8.0.0 | Interactive widgets |

### Visualization
| Package | Version | M·ª•c ƒë√≠ch |
|---------|---------|----------|
| plotly | ‚â•5.17.0 | Interactive plots |
| kaleido | ‚â•0.2.1 | Static export |
| matplotlib | ‚â•3.8.0 | Static plots |
| seaborn | ‚â•0.13.0 | Statistical viz |

---

## üîß Troubleshooting

### L·ªói: pip install fails

**Nguy√™n nh√¢n:** Thi·∫øu build tools

```bash
# Arch/CachyOS
sudo pacman -S base-devel python-pip

# Ubuntu/Debian
sudo apt install build-essential python3-dev
```

### L·ªói: PySpark kh√¥ng t√¨m th·∫•y Java

**Gi·∫£i ph√°p:**

```bash
# Ki·ªÉm tra Java
java -version

# N·∫øu ch∆∞a c√≥, c√†i Java 11
sudo pacman -S jdk11-openjdk  # Arch
sudo apt install openjdk-11-jdk  # Ubuntu

# Set JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk' >> ~/.zshrc
```

### L·ªói: Jupyter Lab kh√¥ng kh·ªüi ƒë·ªông

**Gi·∫£i ph√°p:**

```bash
# Rebuild Jupyter Lab
jupyter lab clean
jupyter lab build

# C√†i l·∫°i
pip install --upgrade --force-reinstall jupyterlab
```

### L·ªói: Plotly kh√¥ng hi·ªÉn th·ªã trong Jupyter

**Gi·∫£i ph√°p:**

```bash
# C√†i extension
jupyter labextension install jupyterlab-plotly

# Ho·∫∑c d√πng renderer
python -c "import plotly.io as pio; pio.renderers.default='notebook'"
```

### L·ªói: Out of memory khi c√†i packages

**Gi·∫£i ph√°p:**

```bash
# C√†i t·ª´ng package m·ªôt
pip install polars
pip install pyspark
pip install plotly
# ...
```

---

## üéØ Workflows c√†i ƒë·∫∑t

### ‚ö° Quick Install v·ªõi UV (Khuy·∫øn ngh·ªã - C·ª∞C NHANH!)

```bash
cd /home/ultimatebrok/Downloads/Final

# C√†i UV (n·∫øu ch∆∞a c√≥)
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.zshrc

# Setup trong 2 l·ªánh!
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt

# Test
python -c "import polars, pyspark, plotly; print('‚úÖ OK!')"
```

### üê¢ Quick Install v·ªõi pip (Traditional)

```bash
cd /home/ultimatebrok/Downloads/Final
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### üöÄ Full Install v·ªõi UV (t·ª´ ƒë·∫ßu)

```bash
# 1. C√†i UV, Python & Java
curl -LsSf https://astral.sh/uv/install.sh | sh
sudo pacman -S python jdk11-openjdk  # Arch/CachyOS
# sudo apt install python3 openjdk-11-jdk  # Ubuntu

# 2. Reload shell
source ~/.zshrc

# 3. Navigate to project
cd /home/ultimatebrok/Downloads/Final

# 4. Setup v·ªõi UV
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt

# 5. C√†i Spark (optional)
./scripts/setup/install_spark.sh
source ~/.zshrc

# 6. Test
python -c "import polars, pyspark, plotly; print('‚úÖ OK!')"
```

---

## üìö T√†i li·ªáu li√™n quan

- [README.md](README.md) - T·ªïng quan project
- [CAU_TRUC_DU_AN.md](CAU_TRUC_DU_AN.md) - C·∫•u tr√∫c th∆∞ m·ª•c
- [HUONG_DAN_CHAY.md](HUONG_DAN_CHAY.md) - H∆∞·ªõng d·∫´n ch·∫°y pipeline

---

## üí° Tips

### UV vs pip - So s√°nh t·ªëc ƒë·ªô

| Task | pip | UV | T·ªëc ƒë·ªô |
|------|-----|----|---------|
| Install all deps | ~5-10 ph√∫t | ~30-60 gi√¢y | **10-20x nhanh h∆°n** |
| Resolve dependencies | Ch·∫≠m | R·∫•t nhanh | **Instant** |
| Cache | Limited | Excellent | **Efficient** |

### UV Commands

```bash
# T·∫°o venv
uv venv

# C√†i packages
uv pip install package_name
uv pip install -r requirements.txt

# Upgrade packages
uv pip install --upgrade package_name

# Sync dependencies (gi·ªëng pip-compile)
uv pip sync requirements.txt

# List installed packages
uv pip list

# Uninstall
uv pip uninstall package_name
```

### Virtual Environment Best Practices

```bash
# K√≠ch ho·∫°t t·ª± ƒë·ªông khi cd v√†o folder (zsh)
echo 'cd() { builtin cd "$@" && [ -f .venv/bin/activate ] && source .venv/bin/activate }' >> ~/.zshrc

# Deactivate
deactivate
```

### Upgrade packages

```bash
# V·ªõi UV (khuy·∫øn ngh·ªã)
uv pip install --upgrade -r requirements.txt
uv pip install --upgrade polars pyspark plotly

# V·ªõi pip
pip install --upgrade -r requirements.txt
pip install --upgrade polars pyspark plotly
```

### Export current environment

```bash
# V·ªõi UV
uv pip freeze > requirements_freeze.txt

# V·ªõi pip
pip freeze > requirements_freeze.txt
```

---

**C·∫≠p nh·∫≠t:** 2025-10-29  
**H·ªó tr·ª£:** Xem [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) n·∫øu c·∫ßn
