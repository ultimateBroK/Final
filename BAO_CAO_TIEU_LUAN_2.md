# BÃO CÃO TIá»‚U LUáº¬N: PhÃ¢n cá»¥m K-means

## Má»¤C Lá»¤C

- [Báº£ng phÃ¢n chia cÃ´ng viá»‡c](#bang-phan-chia-cong-viec)
- [I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t](#i-tong-quan-va-ly-thuyet)
  - [A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means](#a-gioi-thieu-ve-cac-thuat-toan-k-means)
    - [1. Thuáº­t toÃ¡n K-means](#1-thuat-toan-k-means)
      - [a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means](#a-cach-thuc-hoat-dong-cua-k-means)
      - [b. K-means++](#b-k-means)
      - [c. Æ¯u Ä‘iá»ƒm cá»§a K-means](#c-uu-diem-cua-k-means)
      - [d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means](#d-nhuoc-diem-cua-k-means)
      - [e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means](#e-cac-tham-so-quan-trong-cua-k-means)
      - [f. á»¨ng dá»¥ng cá»§a K-means](#f-ung-dung-cua-k-means)
  - [B. LÃ½ thuyáº¿t HDFS](#b-ly-thuyet-hdfs)
  - [C. LÃ½ thuyáº¿t Apache Spark](#c-ly-thuyet-apache-spark)
  - [D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng](#d-cac-cong-nghe-su-dung)
    - [Polars](#polars)
    - [PySpark](#pyspark)
    - [NumPy](#numpy)
    - [HDFS](#hdfs)
    - [Apache Spark](#apache-spark)
- [II. MÃ´ táº£ bÃ i toÃ¡n](#ii-mo-ta-bai-toan)
  - [A. LÃ½ do chá»n Ä‘á» tÃ i](#a-ly-do-chon-de-tai)
  - [B. MÃ´ táº£ bÃ i toÃ¡n](#b-mo-ta-bai-toan)
  - [C. Quy trÃ¬nh thá»±c hiá»‡n](#c-quy-trinh-thuc-hien)

---

<a id="bang-phan-chia-cong-viec"></a>
## Báº£ng phÃ¢n chia cÃ´ng viá»‡c

| Háº¡ng má»¥c | Sinh viÃªn 1 | Sinh viÃªn 2 | Ghi chÃº |
|---|---|---|---|
| Kháº£o sÃ¡t thuáº­t toÃ¡n K-means | X |  | TÃ i liá»‡u, vÃ­ dá»¥ minh há»a |
| Thiáº¿t káº¿ quy trÃ¬nh, pipeline |  | X | 8 bÆ°á»›c tá»« thÃ´ Ä‘áº¿n phÃ¢n tÃ­ch |
| Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Polars) | X |  | Chuáº©n hÃ³a, mÃ£ hÃ³a |
| Spark K-means vÃ  tá»‘i Æ°u |  | X | Cáº¥u hÃ¬nh, theo dÃµi há»™i tá»¥ |
| GÃ¡n nhÃ£n vÃ  phÃ¢n tÃ­ch | X | X | Tá»•ng há»£p káº¿t quáº£ |
| Viáº¿t bÃ¡o cÃ¡o, trÃ¬nh bÃ y | X | X | BiÃªn táº­p cuá»‘i |

---

<a id="i-tong-quan-va-ly-thuyet"></a>
## I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t

<a id="a-gioi-thieu-ve-cac-thuat-toan-k-means"></a>
### A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means

<a id="1-thuat-toan-k-means"></a>
#### 1. Thuáº­t toÃ¡n K-means

<a id="a-cach-thuc-hoat-dong-cua-k-means"></a>
##### a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means

- Khá»Ÿi táº¡o K tÃ¢m cá»¥m (centroid) ban Ä‘áº§u.
- Láº·p cho Ä‘áº¿n khi há»™i tá»¥:
  1) GÃ¡n má»—i Ä‘iá»ƒm vÃ o cá»¥m cÃ³ centroid gáº§n nháº¥t (thÆ°á»ng dÃ¹ng khoáº£ng cÃ¡ch Euclidean).
  2) Cáº­p nháº­t centroid báº±ng trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m.
- Dá»«ng khi tÃ¢m cá»¥m thay Ä‘á»•i ráº¥t nhá» (dÆ°á»›i ngÆ°á»¡ng) hoáº·c Ä‘áº¡t sá»‘ vÃ²ng láº·p tá»‘i Ä‘a.

<a id="b-k-means"></a>
##### b. K-means++

- CÃ¡ch khá»Ÿi táº¡o tÃ¢m cá»¥m thÃ´ng minh nháº±m giáº£m rá»§i ro rÆ¡i vÃ o nghiá»‡m kÃ©m:
  - Chá»n ngáº«u nhiÃªn 1 Ä‘iá»ƒm lÃ m tÃ¢m Ä‘áº§u tiÃªn.
  - Vá»›i má»—i tÃ¢m tiáº¿p theo, chá»n xÃ¡c suáº¥t tá»‰ lá»‡ vá»›i bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch Ä‘áº¿n tÃ¢m gáº§n nháº¥t.
- Lá»£i Ã­ch: thÆ°á»ng há»™i tá»¥ nhanh hÆ¡n vÃ  cháº¥t lÆ°á»£ng phÃ¢n cá»¥m tá»‘t hÆ¡n so vá»›i khá»Ÿi táº¡o ngáº«u nhiÃªn.

<a id="c-uu-diem-cua-k-means"></a>
##### c. Æ¯u Ä‘iá»ƒm cá»§a K-means

- ÄÆ¡n giáº£n, dá»… cÃ i Ä‘áº·t vÃ  giáº£i thÃ­ch.
- Tá»‘c Ä‘á»™ nhanh, má»Ÿ rá»™ng tá»‘t cho dá»¯ liá»‡u lá»›n.
- Hiá»‡u quáº£ khi cá»¥m cÃ³ dáº¡ng lá»“i vÃ  phÃ¢n tÃ¡ch khÃ¡ rÃµ.

<a id="d-nhuoc-diem-cua-k-means"></a>
##### d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means

- Cáº§n chá»n trÆ°á»›c K (sá»‘ cá»¥m).
- Nháº¡y cáº£m vá»›i tÃ¢m khá»Ÿi táº¡o vÃ  outlier.
- Giáº£ Ä‘á»‹nh cá»¥m cÃ³ phÆ°Æ¡ng sai gáº§n nhau (hÃ¬nh cáº§u) vÃ  dÃ¹ng cÃ¹ng má»™t thÆ°á»›c Ä‘o khoáº£ng cÃ¡ch.

<a id="e-cac-tham-so-quan-trong-cua-k-means"></a>
##### e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means

- K (sá»‘ cá»¥m), init (random/K-means++), max_iter, n_init, tol (ngÆ°á»¡ng há»™i tá»¥), metric (thÆ°á»ng lÃ  Euclidean).

<a id="f-ung-dung-cua-k-means"></a>
##### f. á»¨ng dá»¥ng cá»§a K-means

- PhÃ¢n khÃºc khÃ¡ch hÃ ng, gá»£i Ã½ sáº£n pháº©m, phÃ¡t hiá»‡n báº¥t thÆ°á»ng sÆ¡ bá»™, nÃ©n dá»¯ liá»‡u (vector quantization), khá»Ÿi táº¡o cho cÃ¡c thuáº­t toÃ¡n khÃ¡c.

<a id="b-ly-thuyet-hdfs"></a>
### B. LÃ½ thuyáº¿t HDFS

- HDFS (Hadoop Distributed File System) lÃ  há»‡ thá»‘ng file phÃ¢n tÃ¡n, thiáº¿t káº¿ Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c file ráº¥t lá»›n trÃªn cá»¥m mÃ¡y.
- ThÃ nh pháº§n chÃ­nh:
  - NameNode: LÆ°u metadata (namespace, vá»‹ trÃ­ block), Ä‘iá»u phá»‘i truy cáº­p.
  - DataNode: LÆ°u dá»¯ liá»‡u dáº¡ng block trÃªn Ä‘Ä©a, phá»¥c vá»¥ Ä‘á»c/ghi.
- KhÃ¡i niá»‡m cá»‘t lÃµi:
  - Block: ÄÆ¡n vá»‹ lÆ°u trá»¯ (máº·c Ä‘á»‹nh 128MB hoáº·c 256MB).
  - Replication Factor: Má»—i block Ä‘Æ°á»£c sao chÃ©p N báº£n Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n.
  - Rack Awareness: PhÃ¢n phá»‘i báº£n sao trÃªn nhiá»u rack Ä‘á»ƒ tÄƒng tÃ­nh sáºµn sÃ ng.
- Luá»“ng ghi: Client yÃªu cáº§u NameNode â†’ nháº­n danh sÃ¡ch DataNode â†’ pipeline ghi theo chuá»—i, tá»«ng block Ä‘Æ°á»£c replicate.
- Luá»“ng Ä‘á»c: Client há»i NameNode vá»‹ trÃ­ block â†’ Ä‘á»c trá»±c tiáº¿p tá»« DataNode gáº§n nháº¥t (data locality).
- Æ¯u Ä‘iá»ƒm: Dung lÆ°á»£ng má»Ÿ rá»™ng tuyáº¿n tÃ­nh, chá»‹u lá»—i tá»‘t, throughput cao. NhÆ°á»£c: Äá»™ trá»… (latency) cao, khÃ´ng phÃ¹ há»£p file nhá» ráº¥t nhiá»u.

VÃ­ dá»¥ lá»‡nh HDFS thÆ°á»ng dÃ¹ng:

```bash
# Kiá»ƒm tra cá»¥m HDFS
hdfs dfsadmin -report

# Táº¡o thÆ° má»¥c vÃ  upload
hdfs dfs -mkdir -p /user/spark/hi_large/input
hdfs dfs -put data/processed/hadoop_input_temp.txt /user/spark/hi_large/input/

# Liá»‡t kÃª vÃ  kiá»ƒm tra kÃ­ch thÆ°á»›c
hdfs dfs -ls -h /user/spark/hi_large/input
hdfs dfs -du -h /user/spark/hi_large/input
```

<a id="c-ly-thuyet-apache-spark"></a>
### C. LÃ½ thuyáº¿t Apache Spark

- Kiáº¿n trÃºc: Driver (Ä‘iá»u phá»‘i) + Executors (thá»±c thi) + Cluster Manager (Standalone/YARN/K8s).
- MÃ´ hÃ¬nh thá»±c thi: DAG cá»§a transformations â†’ chia thÃ nh stages â†’ tasks song song trÃªn partitions.
- KhÃ¡i niá»‡m chÃ­nh:
  - RDD/DataFrame/Dataset: Abstraction dá»¯ liá»‡u báº¥t biáº¿n, phÃ¢n tÃ¡n.
  - Lazy Evaluation: Chá»‰ thá»±c thi khi cÃ³ action (count, collect, write...).
  - Catalyst Optimizer & Tungsten: Tá»‘i Æ°u logic vÃ  thá»±c thi trong bá»™ nhá»›.
  - Shuffle: Trao Ä‘á»•i dá»¯ liá»‡u giá»¯a nodes theo key, chi phÃ­ cao cáº§n háº¡n cháº¿.
- Bá»™ nhá»›: PhÃ¢n vÃ¹ng cho execution vs. storage; cache/persist Ä‘á»ƒ chia sáº» trung gian giá»¯a cÃ¡c bÆ°á»›c láº·p.

VÃ­ dá»¥ K-means vá»›i PySpark MLlib (rÃºt gá»n):

```python
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans

spark = SparkSession.builder.getOrCreate()

# Äá»c dá»¯ liá»‡u Ä‘Ã£ chuáº©n hoÃ¡ tá»« HDFS (vÃ­ dá»¥)
df = spark.read.csv(
    "hdfs:///user/spark/hi_large/input/hadoop_input.txt",
    header=False,
    inferSchema=True,
)

# GhÃ©p cá»™t Ä‘áº·c trÆ°ng thÃ nh vector cho MLlib
assembler = VectorAssembler(
    inputCols=[
        # Ä‘iá»n danh sÃ¡ch cá»™t Ä‘áº·c trÆ°ng sá»‘ á»Ÿ Ä‘Ã¢y
    ],
    outputCol="features",
)
vec = assembler.transform(df).select("features").cache()

kmeans = KMeans(k=5, maxIter=15, seed=42, featuresCol="features", predictionCol="cluster")
model = kmeans.fit(vec)
centers = model.clusterCenters()
```

<a id="d-cac-cong-nghe-su-dung"></a>
### D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng

<a id="polars"></a>
#### Polars

- Vai trÃ²: Tiá»n xá»­ lÃ½ nhanh trÃªn 1 mÃ¡y (CSV lá»›n), lazy/streaming vÆ°á»£t quÃ¡ RAM.
- TÃ­nh nÄƒng: Expression API, parallel compute, memory efficient (Rust backend).
- VÃ­ dá»¥:

```python
import polars as pl

df = pl.scan_csv("data/raw/HI-Large_Trans.csv")  # lazy, khÃ´ng táº£i háº¿t vÃ o RAM

features = (
    df.with_columns([
        (pl.col("Amount Received") / pl.col("Amount Paid")).alias("amount_ratio"),
    ])
    .select([
        pl.col("amount_ratio").clip(0, 10),
        pl.col("Payment Currency"),
    ])
)

features.sink_csv("data/processed/sample_features.csv")  # streaming
```

<a id="pyspark"></a>
#### PySpark

- Vai trÃ²: API Python cho Spark; cháº¡y phÃ¢n tÃ¡n, phÃ¹ há»£p thuáº­t toÃ¡n láº·p nhÆ° K-means.
- TÃ­nh nÄƒng: DataFrame, MLlib, Structured Streaming, Catalyst optimizer.
- VÃ­ dá»¥ lá»‡nh submit:

```bash
spark-submit \
  --driver-memory 4g \
  --executor-memory 4g \
  scripts/spark/kmeans_spark.py
```

<a id="numpy"></a>
#### NumPy

- Vai trÃ²: TÄƒng tá»‘c tÃ­nh toÃ¡n vector/matrix, Ä‘áº·c biá»‡t khi gÃ¡n nhÃ£n theo khoáº£ng cÃ¡ch.
- VÃ­ dá»¥ tÃ­nh khoáº£ng cÃ¡ch Euclid theo batch:

```python
import numpy as np

X = np.random.rand(1_000_000, 9)  # features
C = np.random.rand(5, 9)          # centroids

dists = np.sqrt(((X[:, None, :] - C[None, :, :]) ** 2).sum(axis=2))
labels = dists.argmin(axis=1)
```

<a id="hdfs"></a>
#### HDFS

- Vai trÃ²: LÆ°u trá»¯ phÃ¢n tÃ¡n dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ  káº¿t quáº£ mÃ´ hÃ¬nh; Ä‘áº£m báº£o an toÃ n vÃ  má»Ÿ rá»™ng.
- Lá»‡nh há»¯u Ã­ch: `hdfs dfs -put`, `-get`, `-ls -h`, `-du -h`, `dfsadmin -report`.

<a id="apache-spark"></a>
#### Apache Spark

- Vai trÃ²: Ná»n táº£ng thá»±c thi phÃ¢n tÃ¡n trong bá»™ nhá»›; tá»‘i Æ°u cho xá»­ lÃ½ láº·p vÃ  ETL.
- Best practices: Cache dá»¯ liá»‡u dÃ¹ng láº¡i; tá»‘i Æ°u sá»‘ partitions; giáº£m shuffle; giÃ¡m sÃ¡t UI táº¡i `http://localhost:4040` khi cháº¡y local.

---

<a id="ii-mo-ta-bai-toan"></a>
## II. MÃ´ táº£ bÃ i toÃ¡n

<a id="a-ly-do-chon-de-tai"></a>
### A. LÃ½ do chá»n Ä‘á» tÃ i

- Dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh cá»±c lá»›n, cáº§n phÃ¢n cá»¥m Ä‘á»ƒ hiá»ƒu hÃ nh vi vÃ  nháº­n diá»‡n báº¥t thÆ°á»ng.
- K-means lÃ  thuáº­t toÃ¡n nhanh, dá»… má»Ÿ rá»™ng, phÃ¹ há»£p cho bÆ°á»›c phÃ¢n nhÃ³m ná»n táº£ng trÆ°á»›c khi Ä‘i sÃ¢u.
- Táº­n dá»¥ng háº¡ táº§ng phÃ¢n tÃ¡n (Spark) vÃ  xá»­ lÃ½ cá»¥c bá»™ nhanh (Polars) Ä‘á»ƒ rÃºt ngáº¯n thá»i gian.

<a id="b-mo-ta-bai-toan"></a>
### B. MÃ´ táº£ bÃ i toÃ¡n

- Äáº§u vÃ o: Táº­p dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh nhiá»u cá»™t (thá»i gian, ngÃ¢n hÃ ng, tÃ i khoáº£n, sá»‘ tiá»n, loáº¡i tiá»n...).
- Má»¥c tiÃªu: Tiá»n xá»­ lÃ½ vÃ  chuáº©n hÃ³a Ä‘áº·c trÆ°ng, sau Ä‘Ã³ phÃ¢n cá»¥m K-means Ä‘á»ƒ phÃ¢n nhÃ³m giao dá»‹ch cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±; dÃ¹ng káº¿t quáº£ Ä‘á»ƒ phÃ¢n tÃ­ch cá»¥m rá»§i ro.
- RÃ ng buá»™c: Tá»‘i Æ°u thá»i gian xá»­ lÃ½; khÃ´ng lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™ sau khi Ä‘áº©y lÃªn HDFS.

<a id="c-quy-trinh-thuc-hien"></a>
### C. Quy trÃ¬nh thá»±c hiá»‡n

#### Tá»•ng quan quy trÃ¬nh 8 bÆ°á»›c

```
BÆ¯á»šC 1        BÆ¯á»šC 2        BÆ¯á»šC 3        BÆ¯á»šC 4
KhÃ¡m phÃ¡  â†’   Xá»­ lÃ½    â†’   Khá»Ÿi táº¡o  â†’   Upload
 (30s)        (10 phÃºt)      (30s)       (5 phÃºt)

BÆ¯á»šC 5        BÆ¯á»šC 6        BÆ¯á»šC 7        BÆ¯á»šC 8
K-means   â†’   Táº£i vá»   â†’   GÃ¡n nhÃ£n  â†’   PhÃ¢n tÃ­ch
(15-30p)       (30s)       (10 phÃºt)     (2 phÃºt)

Tá»”NG THá»œI GIAN: 40-60 phÃºt
```

#### Chi tiáº¿t tá»«ng bÆ°á»›c

##### BÆ¯á»šC 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u ğŸ”
**Má»¥c Ä‘Ã­ch**: Hiá»ƒu cáº¥u trÃºc vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u
**File thá»±c thi**: `scripts/polars/explore_fast.py`
**Thá»i gian**: ~30 giÃ¢y
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)
**Output**: Thá»‘ng kÃª in ra mÃ n hÃ¬nh

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. Äá»c 100,000 dÃ²ng Ä‘áº§u (Ä‘áº¡i diá»‡n)
2. Xem schema: TÃªn cá»™t, kiá»ƒu dá»¯ liá»‡u
3. Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median, std
4. PhÃ¢n tÃ­ch nhÃ£n: Bao nhiÃªu % rá»­a tiá»n?
5. Top loáº¡i tiá»n tá»‡ phá»• biáº¿n

**Káº¿t quáº£ vÃ­ dá»¥**:
```
Total rows: 179,702,229
Laundering rate: 0.126%
Top currencies: Euro (23%), Yuan (7.2%)
```

##### BÆ¯á»šC 2: Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ğŸ”§
**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n xá»­ lÃ½
**File thá»±c thi**: `scripts/polars/prepare_polars.py`
**Thá»i gian**: ~10 phÃºt
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)
**Output**: `data/processed/hadoop_input_temp.txt` (33GB, Táº M THá»œI)

**CÃ¡c bÆ°á»›c xá»­ lÃ½**:
1. **Parse timestamp**: "2022/08/01 00:17" â†’ giá»=0, ngÃ y=0 (Thá»© 2)
2. **TÃ­nh ratio**: amount_ratio = 6794.63 / 7739.29 = 0.878
3. **Hash route**: hash(20, 20) = 400 (vÃ­ dá»¥)
4. **Encode currency**: "US Dollar" â†’ 0, "Yuan" â†’ 1
5. **Normalize**: ÄÆ°a táº¥t cáº£ vá» [0, 1]

**Táº¡i sao láº¡i tÄƒng tá»« 16GB lÃªn 33GB?**
- Dá»¯ liá»‡u gá»‘c: Chá»‰ cÃ³ 11 cá»™t
- Sau xá»­ lÃ½: ThÃªm nhiá»u cá»™t Ä‘áº·c trÆ°ng
- Má»—i sá»‘ float64 = 8 bytes
- 179M rows Ã— 9 features Ã— 8 bytes â‰ˆ 12GB + overhead â‰ˆ 33GB

##### BÆ¯á»šC 3: Khá»Ÿi táº¡o tÃ¢m cá»¥m ğŸ¯
**Má»¥c Ä‘Ã­ch**: Chá»n Ä‘iá»ƒm báº¯t Ä‘áº§u cho thuáº­t toÃ¡n K-means
**File thá»±c thi**: `scripts/polars/init_centroids.py`
**Thá»i gian**: ~30 giÃ¢y
**Input**: `data/processed/hadoop_input_temp.txt`
**Output**: `data/processed/centroids_temp.txt` (440 bytes)

**Thuáº­t toÃ¡n**:
1. Sample ngáº«u nhiÃªn 100,000 dÃ²ng
2. Chá»n ngáº«u nhiÃªn K=5 dÃ²ng lÃ m tÃ¢m cá»¥m
3. LÆ°u 5 dÃ²ng nÃ y vÃ o file

**VÃ­ dá»¥ tÃ¢m cá»¥m**:
```
Cluster 0: [0.12, 0.34, 0.56, 0.78, 0.90, 0.11, 0.33, 0.55, 0.77]
Cluster 1: [0.88, 0.22, 0.44, 0.66, 0.11, 0.99, 0.22, 0.44, 0.66]
...
```

##### BÆ¯á»šC 4: Upload lÃªn HDFS â˜ï¸
**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u lÃªn há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n
**File thá»±c thi**: `scripts/spark/setup_hdfs.sh`
**Thá»i gian**: ~5 phÃºt
**Input**: 2 file temp cá»¥c bá»™
**Output**: Dá»¯ liá»‡u trÃªn HDFS

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n**:
1. Kiá»ƒm tra HDFS Ä‘ang cháº¡y: `hdfs dfsadmin -report`
2. Táº¡o thÆ° má»¥c: `hdfs dfs -mkdir -p /user/spark/hi_large/input`
3. Upload input: `hdfs dfs -put hadoop_input_temp.txt /user/.../input/`
4. Upload centroids: `hdfs dfs -put centroids_temp.txt /user/.../`
5. **XÃ“A file temp cá»¥c bá»™**: `rm -rf data/processed/*`
6. Verify: Kiá»ƒm tra kÃ­ch thÆ°á»›c file trÃªn HDFS

**ğŸ”’ TuÃ¢n thá»§ quy Ä‘á»‹nh**:
- Sau bÆ°á»›c nÃ y, KHÃ”NG cÃ²n dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
- Chá»‰ tá»“n táº¡i trÃªn HDFS (phÃ¢n tÃ¡n, an toÃ n)
- Náº¿u cáº§n, cÃ³ thá»ƒ táº£i láº¡i tá»« HDFS

##### BÆ¯á»šC 5: Cháº¡y K-means trÃªn Spark ğŸš€
**Má»¥c Ä‘Ã­ch**: PhÃ¢n cá»¥m 179 triá»‡u giao dá»‹ch
**File thá»±c thi**: `scripts/spark/run_spark.sh` + `kmeans_spark.py`
**Thá»i gian**: 15-30 phÃºt (tÃ¹y pháº§n cá»©ng)
**Input**: Dá»¯ liá»‡u tá»« HDFS
**Output**: TÃ¢m cá»¥m cuá»‘i cÃ¹ng trÃªn HDFS

**Thuáº­t toÃ¡n K-means**:
```
KHá» Táº O:
  - K=5 tÃ¢m cá»¥m ban Ä‘áº§u (tá»« bÆ°á»›c 3)
  - Max iterations = 15

Láº¶P Láº I 15 Láº¦N:
  1. GÃ¡n má»—i giao dá»‹ch vÃ o cá»¥m gáº§n nháº¥t
     - TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n 5 tÃ¢m cá»¥m
     - Chá»n cá»¥m cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t
  
  2. Cáº­p nháº­t tÃ¢m cá»¥m
     - TÃ­nh trung bÃ¬nh táº¥t cáº£ Ä‘iá»ƒm trong má»—i cá»¥m
     - TÃ¢m cá»¥m má»›i = trung bÃ¬nh cÃ¡c Ä‘iá»ƒm
  
  3. Kiá»ƒm tra há»™i tá»¥
     - TÃ­nh Ä‘á»™ dá»‹ch chuyá»ƒn tÃ¢m cá»¥m
     - Náº¿u < threshold â†’ Dá»«ng láº¡i

Káº¾T QUáº¢:
  - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng
  - Má»—i cá»¥m chá»©a bao nhiÃªu Ä‘iá»ƒm
```

**QuÃ¡ trÃ¬nh há»™i tá»¥ (tá»« log thá»±c táº¿)**:
```
Iteration  1: Centroid shift = 2.232  (chÆ°a á»•n Ä‘á»‹nh)
Iteration  2: Centroid shift = 1.409
Iteration  5: Centroid shift = 0.383
Iteration 10: Centroid shift = 0.046
Iteration 15: Centroid shift = 0.010  (Ä‘Ã£ há»™i tá»¥ âœ“)
```

**PhÃ¢n phá»‘i káº¿t quáº£**:
```
Cluster 0:  40,034,828 giao dá»‹ch (22.28%)
Cluster 1:  42,665,741 giao dá»‹ch (23.74%)
Cluster 2:  24,884,738 giao dá»‹ch (13.85%)
Cluster 3:  50,933,660 giao dá»‹ch (28.34%)  â† Lá»›n nháº¥t
Cluster 4:  21,183,262 giao dá»‹ch (11.79%)
```

##### BÆ¯á»šC 6: Táº£i káº¿t quáº£ vá» ğŸ“¥
**Má»¥c Ä‘Ã­ch**: Láº¥y tÃ¢m cá»¥m cuá»‘i cÃ¹ng tá»« HDFS
**File thá»±c thi**: `scripts/spark/download_from_hdfs.sh`
**Thá»i gian**: ~30 giÃ¢y
**Input**: `/user/spark/hi_large/output_centroids/` trÃªn HDFS
**Output**: `data/results/final_centroids.txt` (~4KB)

**CÃ¡c bÆ°á»›c**:
1. `hdfs dfs -cat /user/.../output_centroids/part-*`
2. LÆ°u vÃ o file cá»¥c bá»™
3. Verify: Kiá»ƒm tra cÃ³ Ä‘Ãºng 5 dÃ²ng

**Táº¡i sao Ä‘Æ°á»£c phÃ©p táº£i vá»?**
- File ráº¥t nhá» (~4KB)
- Chá»‰ chá»©a káº¿t quáº£ tá»•ng há»£p, khÃ´ng pháº£i dá»¯ liá»‡u gá»‘c
- Cáº§n thiáº¿t cho bÆ°á»›c phÃ¢n tÃ­ch tiáº¿p theo

##### BÆ¯á»šC 7: GÃ¡n nhÃ£n cá»¥m cho tá»«ng giao dá»‹ch ğŸ·ï¸
**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh má»—i giao dá»‹ch thuá»™c cá»¥m nÃ o
**File thá»±c thi**: `scripts/polars/assign_clusters_polars.py`
**Thá»i gian**: ~10 phÃºt
**Input**: 
  - CSV gá»‘c tá»« HDFS (streaming)
  - 5 tÃ¢m cá»¥m tá»« bÆ°á»›c 6
**Output**: `data/results/clustered_results.txt`

**Thuáº­t toÃ¡n**:
```python
FOR má»—i giao dá»‹ch:
    distances = []
    FOR má»—i tÃ¢m cá»¥m (5 cá»¥m):
        d = euclidean_distance(giao_dá»‹ch, tÃ¢m_cá»¥m)
        distances.append(d)
    
    cluster_id = argmin(distances)  # Chá»n cá»¥m gáº§n nháº¥t
    ghi_káº¿t_quáº£(giao_dá»‹ch, cluster_id)
```

**Xá»­ lÃ½ batch Ä‘á»ƒ tÄƒng tá»‘c**:
- KhÃ´ng xá»­ lÃ½ tá»«ng giao dá»‹ch
- Xá»­ lÃ½ 1 triá»‡u giao dá»‹ch cÃ¹ng lÃºc
- Sá»­ dá»¥ng NumPy vectorization

##### BÆ¯á»šC 8: PhÃ¢n tÃ­ch káº¿t quáº£ ğŸ“Š
**Má»¥c Ä‘Ã­ch**: TÃ¬m cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao
**File thá»±c thi**: `scripts/polars/analyze_polars.py`
**Thá»i gian**: ~2 phÃºt
**Input**: `data/results/clustered_results.txt`
**Output**: BÃ¡o cÃ¡o phÃ¢n tÃ­ch

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. **KÃ­ch thÆ°á»›c cá»¥m**: Má»—i cá»¥m cÃ³ bao nhiÃªu giao dá»‹ch?
2. **Tá»· lá»‡ rá»­a tiá»n**: % rá»­a tiá»n trong tá»«ng cá»¥m
3. **High-risk clusters**: Cá»¥m nÃ o > 10% rá»­a tiá»n?
4. **Feature averages**: Äáº·c Ä‘iá»ƒm trung bÃ¬nh má»—i cá»¥m

**Káº¿t quáº£ tá»« log thá»±c táº¿**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ Giao dá»‹ch   â•‘ Rá»­a tiá»n  â•‘ Tá»· lá»‡ (%)       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 40,034,832  â•‘  52,327   â•‘ 0.13%           â•‘
â•‘    1     â•‘ 42,665,746  â•‘  70,450   â•‘ 0.17% â† CAO     â•‘
â•‘    2     â•‘ 24,884,738  â•‘  16,686   â•‘ 0.07%           â•‘
â•‘    3     â•‘ 50,933,651  â•‘  82,943   â•‘ 0.16%           â•‘
â•‘    4     â•‘ 21,183,262  â•‘   3,140   â•‘ 0.01% â† THáº¤P    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ NHáº¬N XÃ‰T:
- Cluster 1 nghi ngá» nháº¥t (0.17%, cao hÆ¡n trung bÃ¬nh)
- Cluster 4 an toÃ n nháº¥t (0.01%, tháº¥p hÆ¡n nhiá»u)
- KHÃ”NG cÃ³ cá»¥m nÃ o > 10% (good sign)
```

---


