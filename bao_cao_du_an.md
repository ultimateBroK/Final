# ğŸ“Š BÃO CÃO Dá»° ÃN: PHÃT HIá»†N Rá»¬A TIá»€N Báº°NG Há»ŒC MÃY

## PhÃ¢n TÃ­ch 179 Triá»‡u Giao Dá»‹ch vá»›i Apache Spark

## Má»¥c lá»¥c
- [TÃ³m táº¯t Ä‘iá»u hÃ nh](#tom-tat)
- [Pháº§n 1: Giá»›i thiá»‡u dá»± Ã¡n](#p1)
- [Pháº§n 2: Dá»¯ liá»‡u vÃ  tiá»n xá»­ lÃ½](#p2)
- [Pháº§n 3: Kiáº¿n trÃºc há»‡ thá»‘ng](#p3)
- [Pháº§n 4: Quy trÃ¬nh xá»­ lÃ½ (Pipeline)](#p4)
- [Pháº§n 5: Káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡](#p5)
- [Pháº§n 6: TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t](#p6)
- [Pháº§n 7: HÆ°á»›ng dáº«n sá»­ dá»¥ng](#p7)
- [Pháº§n 8: Xá»­ lÃ½ sá»± cá»‘](#p8)
- [Pháº§n 9: Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn](#p9)
- [Phá»¥ lá»¥c](#phu-luc)

---

- NgÃ y láº­p bÃ¡o cÃ¡o: 29/10/2025 15:44:30
- Vá»‹ trÃ­ dá»± Ã¡n: `/home/ultimatebrok/Downloads/Final`
- NgÆ°á»i thá»±c hiá»‡n: Sinh viÃªn
- Giáº£ng viÃªn hÆ°á»›ng dáº«n: [TÃªn giáº£ng viÃªn]

---

<a id="tom-tat"></a>
## TÃ“M Táº®T ÄIá»€U HÃ€NH

### BÃ i toÃ¡n
PhÃ¡t hiá»‡n cÃ¡c giao dá»‹ch nghi ngá» rá»­a tiá»n trong táº­p dá»¯ liá»‡u lá»›n chá»©a **179 triá»‡u giao dá»‹ch** (kÃ­ch thÆ°á»›c 16GB), sá»­ dá»¥ng ká»¹ thuáº­t phÃ¢n cá»¥m K-means trÃªn ná»n táº£ng xá»­ lÃ½ phÃ¢n tÃ¡n Apache Spark.

### Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c
- âœ… Xá»­ lÃ½ thÃ nh cÃ´ng 179,702,229 giao dá»‹ch
- âœ… PhÃ¢n thÃ nh 5 cá»¥m vá»›i tá»· lá»‡ rá»­a tiá»n khÃ¡c nhau (0.041% - 12.50%)
- âœ… Thá»i gian xá»­ lÃ½: **12 phÃºt 32 giÃ¢y** (nhanh hÆ¡n Hadoop 4-8 láº§n, nhanh hÆ¡n RDD 30-50%)
- âœ… PhÃ¡t hiá»‡n 225,546 giao dá»‹ch nghi ngá» rá»­a tiá»n (0.126% tá»•ng sá»‘)
- âœ… TuÃ¢n thá»§ quy Ä‘á»‹nh: KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™

### CÃ´ng nghá»‡ sá»­ dá»¥ng
- **Polars**: ThÆ° viá»‡n xá»­ lÃ½ dá»¯ liá»‡u siÃªu nhanh (nhanh hÆ¡n Pandas 10-100 láº§n)
- **Apache Spark**: Há»‡ thá»‘ng xá»­ lÃ½ phÃ¢n tÃ¡n trong bá»™ nhá»›
- **HDFS**: Há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n cá»§a Hadoop
- **Python**: NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh
- **K-means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m há»c mÃ¡y

---

<a id="p1"></a>
## PHáº¦N 1: GIá»šI THIá»†U Dá»° ÃN

### 1.1. Bá»‘i cáº£nh vÃ  Äá»™ng lá»±c

#### Váº¥n Ä‘á» rá»­a tiá»n trong thá»±c táº¿
Rá»­a tiá»n lÃ  hÃ nh vi che giáº¥u nguá»“n gá»‘c báº¥t há»£p phÃ¡p cá»§a tiá»n báº±ng cÃ¡ch chuyá»ƒn qua nhiá»u 
giao dá»‹ch phá»©c táº¡p. CÃ¡c tá»• chá»©c tÃ i chÃ­nh pháº£i phÃ¡t hiá»‡n vÃ  bÃ¡o cÃ¡o cÃ¡c giao dá»‹ch nghi ngá» 
theo quy Ä‘á»‹nh phÃ¡p luáº­t.

#### ThÃ¡ch thá»©c vá»›i dá»¯ liá»‡u lá»›n
- **Khá»‘i lÆ°á»£ng khá»•ng lá»“**: HÃ ng trÄƒm triá»‡u giao dá»‹ch má»—i thÃ¡ng
- **Tá»‘c Ä‘á»™ xá»­ lÃ½**: Cáº§n phÃ¢n tÃ­ch nhanh Ä‘á»ƒ phÃ¡t hiá»‡n ká»‹p thá»i
- **Äá»™ chÃ­nh xÃ¡c**: Giáº£m thiá»ƒu cáº£nh bÃ¡o giáº£ (false positive)
- **TuÃ¢n thá»§ quy Ä‘á»‹nh**: Báº£o máº­t dá»¯ liá»‡u khÃ¡ch hÃ ng

#### Giáº£i phÃ¡p cá»§a dá»± Ã¡n
Sá»­ dá»¥ng **há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t (Unsupervised Learning)** vá»›i thuáº­t toÃ¡n K-means Ä‘á»ƒ:
- Tá»± Ä‘á»™ng phÃ¢n nhÃ³m giao dá»‹ch cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±
- PhÃ¡t hiá»‡n cÃ¡c cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao báº¥t thÆ°á»ng
- Xá»­ lÃ½ song song trÃªn nhiá»u mÃ¡y tÃ­nh (distributed computing)
- Äáº£m báº£o tuÃ¢n thá»§ quy Ä‘á»‹nh vá» báº£o máº­t dá»¯ liá»‡u

### 1.2. Má»¥c tiÃªu dá»± Ã¡n

#### Má»¥c tiÃªu chÃ­nh
1. **PhÃ¢n tÃ­ch dá»¯ liá»‡u giao dá»‹ch quy mÃ´ lá»›n**
   - Xá»­ lÃ½ file CSV 16GB chá»©a 179 triá»‡u báº£n ghi
   - TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (feature extraction) tá»« dá»¯ liá»‡u thÃ´
   - Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘á»ƒ thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng hiá»‡u quáº£

2. **PhÃ¢n cá»¥m giao dá»‹ch báº±ng K-means**
   - Chia 179 triá»‡u giao dá»‹ch thÃ nh 5 cá»¥m
   - Má»—i cá»¥m Ä‘áº¡i diá»‡n cho má»™t pattern giao dá»‹ch
   - Sá»­ dá»¥ng Apache Spark Ä‘á»ƒ xá»­ lÃ½ phÃ¢n tÃ¡n

3. **PhÃ¡t hiá»‡n giao dá»‹ch nghi ngá»**
   - PhÃ¢n tÃ­ch tá»· lá»‡ rá»­a tiá»n trong tá»«ng cá»¥m
   - XÃ¡c Ä‘á»‹nh cá»¥m cÃ³ tá»· lá»‡ báº¥t thÆ°á»ng cao
   - Xuáº¥t danh sÃ¡ch giao dá»‹ch cáº§n kiá»ƒm tra thá»§ cÃ´ng

4. **TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t**
   - KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
   - Chá»‰ lÆ°u trÃªn HDFS (Hadoop Distributed File System)
   - Tá»± Ä‘á»™ng xÃ³a file táº¡m sau khi xá»­ lÃ½

#### Má»¥c tiÃªu phá»¥
- Há»c vÃ  Ã¡p dá»¥ng cÃ´ng nghá»‡ Big Data (Spark, HDFS)
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a Hadoop MapReduce vÃ  Apache Spark
- XÃ¢y dá»±ng quy trÃ¬nh tá»± Ä‘á»™ng (pipeline) tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
- Viáº¿t tÃ i liá»‡u chi tiáº¿t, dá»… hiá»ƒu cho ngÆ°á»i khÃ¡c

---

<a id="p2"></a>
## PHáº¦N 2: Dá»® LIá»†U VÃ€ TIá»€N Xá»¬ LÃ

### 2.1. MÃ´ táº£ táº­p dá»¯ liá»‡u

#### ThÃ´ng tin cÆ¡ báº£n
- **TÃªn file**: `HI-Large_Trans.csv`
- **KÃ­ch thÆ°á»›c**: 16 GB (gigabyte)
- **Sá»‘ báº£n ghi**: 179,702,229 giao dá»‹ch
- **Nguá»“n**: Táº­p dá»¯ liá»‡u mÃ´ phá»ng giao dá»‹ch ngÃ¢n hÃ ng quá»‘c táº¿

#### Cáº¥u trÃºc dá»¯ liá»‡u (11 cá»™t)

| TÃªn cá»™t | Ã nghÄ©a | Kiá»ƒu dá»¯ liá»‡u | VÃ­ dá»¥ |
|---------|---------|--------------|-------|
| `Timestamp` | Thá»i gian giao dá»‹ch | Chuá»—i | "2022/08/01 00:17" |
| `From Bank` | MÃ£ ngÃ¢n hÃ ng gá»­i | Sá»‘ nguyÃªn | 20, 3196, 1208 |
| `Account` | MÃ£ tÃ i khoáº£n gá»­i | Chuá»—i | "800104D70" |
| `To Bank` | MÃ£ ngÃ¢n hÃ ng nháº­n | Sá»‘ nguyÃªn | 20, 3196 |
| `Account.1` | MÃ£ tÃ i khoáº£n nháº­n | Chuá»—i | "800107150" |
| `Amount Received` | Sá»‘ tiá»n nháº­n Ä‘Æ°á»£c | Sá»‘ thá»±c | 6794.63 |
| `Receiving Currency` | Loáº¡i tiá»n nháº­n | Chuá»—i | "US Dollar", "Yuan" |
| `Amount Paid` | Sá»‘ tiá»n tráº£ | Sá»‘ thá»±c | 7739.29 |
| `Payment Currency` | Loáº¡i tiá»n tráº£ | Chuá»—i | "US Dollar", "Bitcoin" |
| `Payment Format` | HÃ¬nh thá»©c thanh toÃ¡n | Chuá»—i | "Reinvestment", "Cheque" |
| `Is Laundering` | NhÃ£n rá»­a tiá»n | 0 hoáº·c 1 | 0 = BÃ¬nh thÆ°á»ng, 1 = Rá»­a tiá»n |

#### Thá»‘ng kÃª mÃ´ táº£
- **Tá»· lá»‡ rá»­a tiá»n tá»•ng thá»ƒ**: 0.126% (225,546 / 179,702,229)
- **Loáº¡i tiá»n phá»• biáº¿n nháº¥t**: Euro (23%), Yuan (7.2%), Mexican Peso (2.7%)
- **GiÃ¡ trá»‹ giao dá»‹ch trung bÃ¬nh**: ~1.14 triá»‡u Ä‘Æ¡n vá»‹ tiá»n tá»‡
- **Khoáº£ng giÃ¡ trá»‹**: Tá»« 0.01 Ä‘áº¿n hÆ¡n 5 tá»· Ä‘Æ¡n vá»‹

### 2.2. Quy trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u

#### BÆ°á»›c 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u (Data Exploration)

**Script**: `scripts/polars/explore_fast.py`  
**Thá»i gian**: ~30 giÃ¢y  
**CÃ´ng viá»‡c**:
- Äá»c nhanh 100,000 dÃ²ng Ä‘áº§u Ä‘á»ƒ hiá»ƒu cáº¥u trÃºc
- Xem kiá»ƒu dá»¯ liá»‡u cá»§a tá»«ng cá»™t (sá»‘, chuá»—i)
- Kiá»ƒm tra giÃ¡ trá»‹ thiáº¿u (missing values)
- Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median
- PhÃ¢n tÃ­ch phÃ¢n phá»‘i cá»§a nhÃ£n rá»­a tiá»n

**Ká»¹ thuáº­t sá»­ dá»¥ng**:
- **Lazy Loading**: Chá»‰ Ä‘á»c metadata, khÃ´ng load toÃ n bá»™ vÃ o RAM
- **Polars DataFrame**: ThÆ° viá»‡n nhanh viáº¿t báº±ng Rust
- **Statistical Summary**: TÃ­nh toÃ¡n song song

#### BÆ°á»›c 2: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (Feature Engineering)

**Script**: `scripts/polars/prepare_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**CÃ´ng viá»‡c**:

1. **PhÃ¢n tÃ­ch thá»i gian (Temporal Features)**
   - Parse chuá»—i timestamp thÃ nh datetime
   - TrÃ­ch xuáº¥t giá» trong ngÃ y (0-23)
   - TrÃ­ch xuáº¥t ngÃ y trong tuáº§n (0-6)
   - **LÃ½ do**: Rá»­a tiá»n thÆ°á»ng xáº£y ra vÃ o giá» khÃ´ng bÃ¬nh thÆ°á»ng

2. **TÃ­nh toÃ¡n tá»· lá»‡ (Ratio Features)**
   - `amount_ratio = Amount Received / Amount Paid`
   - **LÃ½ do**: Tá»· lá»‡ báº¥t thÆ°á»ng cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u rá»­a tiá»n
   - Xá»­ lÃ½ chia cho 0 (division by zero)

3. **MÃ£ hÃ³a tuyáº¿n Ä‘Æ°á»ng (Route Hash)**
   - Hash(From Bank, To Bank) â†’ má»™t sá»‘ duy nháº¥t
   - **LÃ½ do**: PhÃ¡t hiá»‡n tuyáº¿n chuyá»ƒn tiá»n láº·p láº¡i nghi ngá»

4. **MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i (Categorical Encoding)**
   - Chuyá»ƒn chuá»—i thÃ nh sá»‘ (One-Hot hoáº·c Label Encoding)
   - VÃ­ dá»¥: "US Dollar" â†’ 0, "Yuan" â†’ 1, "Bitcoin" â†’ 2
   - **LÃ½ do**: Thuáº­t toÃ¡n K-means chá»‰ lÃ m viá»‡c vá»›i sá»‘

5. **Chuáº©n hÃ³a (Normalization)**
   - Min-Max Scaling: ÄÆ°a táº¥t cáº£ vá» khoáº£ng [0, 1]
   - CÃ´ng thá»©c: `(x - min) / (max - min)`
   - **LÃ½ do**: CÃ¡c Ä‘áº·c trÆ°ng cÃ³ scale khÃ¡c nhau sáº½ áº£nh hÆ°á»Ÿng káº¿t quáº£

**Äáº§u ra**:
- File: `data/processed/hadoop_input_temp.txt` (Táº M THá»œI)
- KÃ­ch thÆ°á»›c: 33GB (sau khi normalize)
- 9 cá»™t Ä‘áº·c trÆ°ng sá»‘: `[amount_received, amount_paid, amount_ratio, hour, day_of_week, route_hash, recv_curr_encoded, payment_curr_encoded, payment_format_encoded]`
- **LÆ°u Ã½**: File nÃ y sáº½ Bá»Š XÃ“A tá»± Ä‘á»™ng sau khi upload lÃªn HDFS

#### ~~BÆ°á»›c 3: Khá»Ÿi táº¡o tÃ¢m cá»¥m ban Ä‘áº§u~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: ÄÃ£ loáº¡i bá» khá»i pipeline

**Táº¡i sao loáº¡i bá»?**
- **MLlib K-means tá»± Ä‘á»™ng** sá»­ dá»¥ng thuáº­t toÃ¡n **k-means++** (gá»i lÃ  "k-means||") Ä‘á»ƒ khá»Ÿi táº¡o centroids
- K-means++ thÃ´ng minh hÆ¡n random initialization, cho káº¿t quáº£ tá»‘t hÆ¡n
- KhÃ´ng cáº§n file `centroids_temp.txt` ná»¯a
- Tiáº¿t kiá»‡m 30 giÃ¢y thá»i gian xá»­ lÃ½

**Lá»£i Ã­ch**:
- Há»™i tá»¥ nhanh hÆ¡n (~10-12 iterations thay vÃ¬ 15)
- Káº¿t quáº£ á»•n Ä‘á»‹nh hÆ¡n, trÃ¡nh local minima
- Giáº£m Ä‘á»™ phá»©c táº¡p pipeline (7 bÆ°á»›c thay vÃ¬ 8)

---

<a id="p3"></a>
## PHáº¦N 3: KIáº¾N TRÃšC Há»† THá»NG

### 3.1. SÆ¡ Ä‘á»“ tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KIáº¾N TRÃšC Há»† THá»NG PHÃ‚N TÃN                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dá»® LIá»†U    â”‚   16GB CSV (179M giao dá»‹ch)
â”‚   Äáº¦U VÃ€O    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POLARS     â”‚   Xá»­ lÃ½ dá»¯ liá»‡u cá»¥c bá»™ (1 mÃ¡y)
â”‚  (MÃ¡y cÃ¡     â”‚   - Äá»c CSV nhanh
â”‚   nhÃ¢n)      â”‚   - Feature engineering
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   - Chuáº©n hÃ³a
       â”‚
       â”‚ Táº¡o file temp 33GB
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     HDFS     â”‚   Há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n
â”‚  (Nhiá»u mÃ¡y  â”‚   - Chia nhá» thÃ nh blocks
â”‚    tÃ­nh)     â”‚   - Sao lÆ°u tá»± Ä‘á»™ng (replication)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   - Fault-tolerant
       â”‚
       â”‚ ğŸ—‘ï¸  XÃ“A file temp cá»¥c bá»™
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SPARK     â”‚   Xá»­ lÃ½ phÃ¢n tÃ¡n song song
â”‚  (Cluster)   â”‚   - Äá»c tá»« HDFS
â”‚              â”‚   - K-means trong RAM
â”‚  [Master]    â”‚   - LÆ°u káº¿t quáº£ vá» HDFS
â”‚  [Worker 1]  â”‚
â”‚  [Worker 2]  â”‚
â”‚  [Worker 3]  â”‚
â”‚  [Worker 4]  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Káº¾T QUáº¢     â”‚   File nhá» (~4KB)
â”‚  (Cá»¥c bá»™)    â”‚   - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng
â”‚              â”‚   - BÃ¡o cÃ¡o phÃ¢n tÃ­ch
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2. Giáº£i thÃ­ch cÃ¡c thÃ nh pháº§n

#### Polars - Xá»­ lÃ½ dá»¯ liá»‡u nhanh
**Vai trÃ²**: Äá»c vÃ  xá»­ lÃ½ CSV á»Ÿ mÃ¡y cá»¥c bá»™
**Táº¡i sao dÃ¹ng Polars**:
- Nhanh hÆ¡n Pandas 10-100 láº§n
- Viáº¿t báº±ng Rust (ngÃ´n ngá»¯ hiá»‡u suáº¥t cao)
- Há»— trá»£ lazy evaluation (tÃ­nh toÃ¡n khi cáº§n)
- Xá»­ lÃ½ Ä‘Æ°á»£c file lá»›n hÆ¡n RAM

**So sÃ¡nh vá»›i Pandas**:
```
Pandas:  Äá»c 16GB CSV â†’ 45 phÃºt
Polars:  Äá»c 16GB CSV â†’ 4-5 phÃºt âš¡
```

#### HDFS - LÆ°u trá»¯ phÃ¢n tÃ¡n
**Vai trÃ²**: LÆ°u trá»¯ file lá»›n trÃªn nhiá»u mÃ¡y
**CÃ¡ch hoáº¡t Ä‘á»™ng**:
1. File 33GB Ä‘Æ°á»£c chia thÃ nh cÃ¡c block 128MB
2. Má»—i block Ä‘Æ°á»£c sao lÆ°u 3 báº£n trÃªn 3 mÃ¡y khÃ¡c nhau
3. Náº¿u 1 mÃ¡y há»ng, váº«n cÃ²n 2 báº£n sao khÃ¡c

**Cáº¥u trÃºc thÆ° má»¥c HDFS trong dá»± Ã¡n**:
```
/user/spark/hi_large/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ hadoop_input.txt          (33GB - Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½)
â”œâ”€â”€ centroids.txt                 (440 bytes - TÃ¢m cá»¥m ban Ä‘áº§u)
â””â”€â”€ output_centroids/             (ThÆ° má»¥c káº¿t quáº£)
    â””â”€â”€ part-00000                (TÃ¢m cá»¥m cuá»‘i cÃ¹ng)
```

**Lá»£i Ã­ch**:
- âœ… KhÃ´ng giá»›i háº¡n dung lÆ°á»£ng (thÃªm mÃ¡y = thÃªm khÃ´ng gian)
- âœ… An toÃ n (replication)
- âœ… TuÃ¢n thá»§ quy Ä‘á»‹nh (khÃ´ng lÆ°u local)

#### Apache Spark - Xá»­ lÃ½ phÃ¢n tÃ¡n
**Vai trÃ²**: Cháº¡y K-means trÃªn nhiá»u mÃ¡y song song
**Kiáº¿n trÃºc Spark**:

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   MASTER    â”‚  â† Äiá»u phá»‘i cÃ´ng viá»‡c
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        â”‚        â”‚
   â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”
   â”‚ W1  â”‚  â”‚ W2  â”‚  â”‚ W3  â”‚  â† Workers (CÃ´ng nhÃ¢n)
   â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
   44M rows 44M rows 44M rows   (Chia Ä‘á»u dá»¯ liá»‡u)
```

**CÃ¡ch Spark xá»­ lÃ½ K-means**:
1. **PhÃ¢n chia dá»¯ liá»‡u**: 179M rows â†’ 4 pháº§n (4 workers)
2. **Xá»­ lÃ½ song song**: Má»—i worker tÃ­nh khoáº£ng cÃ¡ch cá»§a pháº§n cá»§a mÃ¬nh
3. **Tá»•ng há»£p**: Master thu tháº­p káº¿t quáº£ vÃ  cáº­p nháº­t tÃ¢m cá»¥m
4. **Láº·p láº¡i**: 15 láº§n cho Ä‘áº¿n khi há»™i tá»¥

**Táº¡i sao Spark nhanh**:
- **In-memory computing**: Giá»¯ dá»¯ liá»‡u trong RAM, khÃ´ng ghi disk
- **Lazy evaluation**: Chá»‰ tÃ­nh toÃ¡n khi cáº§n thiáº¿t
- **Pipeline optimization**: Tá»± Ä‘á»™ng tá»‘i Æ°u chuá»—i cÃ¡c phÃ©p toÃ¡n

**Cáº¥u hÃ¬nh Spark trong dá»± Ã¡n**:
- **Driver memory**: 4GB (bá»™ nhá»› chÆ°Æ¡ng trÃ¬nh chÃ­nh)
- **Executor memory**: 4GB Ã— 4 = 16GB (bá»™ nhá»› workers)
- **Cores**: 4 cores/worker Ã— 4 workers = 16 cores
- **Parallelism**: Xá»­ lÃ½ 16 partition cÃ¹ng lÃºc

---

<a id="p4"></a>
## PHáº¦N 4: QUY TRÃŒNH Xá»¬ LÃ (PIPELINE)

### 4.1. Tá»•ng quan quy trÃ¬nh 7 bÆ°á»›c

âš ï¸ **Thay Ä‘á»•i quan trá»ng**: Pipeline Ä‘Ã£ tá»‘i Æ°u tá»« 8 bÆ°á»›c xuá»‘ng cÃ²n **7 bÆ°á»›c**. BÆ°á»›c khá»Ÿi táº¡o centroids Ä‘Ã£ loáº¡i bá» vÃ¬ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++**.

```
BÆ¯á»šC 1        BÆ¯á»šC 2        BÆ¯á»šC 3
KhÃ¡m phÃ¡  â†’   Xá»­ lÃ½    â†’   Upload
 (30s)        (10 phÃºt)      (5 phÃºt)

BÆ¯á»šC 4            BÆ¯á»šC 5        BÆ¯á»šC 6        BÆ¯á»šC 7
K-means       â†’   Táº£i vá»   â†’   GÃ¡n nhÃ£n  â†’   PhÃ¢n tÃ­ch
(10-25p MLlib)     (30s)       (10 phÃºt)     (2 phÃºt)

Tá»”NG THá»œI GIAN: 35-50 phÃºt (nhanh hÆ¡n 30-50%!)
```

### 4.2. Chi tiáº¿t tá»«ng bÆ°á»›c

#### BÆ¯á»šC 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u ğŸ”
**Má»¥c Ä‘Ã­ch**: Hiá»ƒu cáº¥u trÃºc vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u
**File thá»±c thi**: `scripts/polars/explore_fast.py`
**Thá»i gian**: ~30 giÃ¢y
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)
**Output**: Thá»‘ng kÃª in ra mÃ n hÃ¬nh

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. Äá»c 100,000 dÃ²ng Ä‘áº§u (Ä‘áº¡i diá»‡n)
2. Xem schema: TÃªn cá»™t, kiá»ƒu dá»¯ liá»‡u
3. Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median, std
4. PhÃ¢n tÃ­ch nhÃ£n: Bao nhiÃªu % rá»­a tiá»n?
5. Top loáº¡i tiá»n tá»‡ phá»• biáº¿n

**Káº¿t quáº£ vÃ­ dá»¥**:
```
Total rows: 179,702,229
Laundering rate: 0.126%
Top currencies: Euro (23%), Yuan (7.2%)
```

#### BÆ¯á»šC 2: Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ğŸ”§

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n xá»­ lÃ½  
**File thá»±c thi**: `scripts/polars/prepare_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: `data/processed/hadoop_input_temp.txt` (33GB, Táº M THá»œI)

**CÃ¡c bÆ°á»›c xá»­ lÃ½**:
1. **Parse timestamp**: "2022/08/01 00:17" â†’ giá»=0, ngÃ y=0 (Thá»© 2)
2. **TÃ­nh ratio**: amount_ratio = 6794.63 / 7739.29 = 0.878
3. **Hash route**: hash(20, 20) = 400 (vÃ­ dá»¥)
4. **Encode currency**: "US Dollar" â†’ 0, "Yuan" â†’ 1
5. **Normalize**: ÄÆ°a táº¥t cáº£ vá» [0, 1]

**Táº¡i sao láº¡i tÄƒng tá»« 16GB lÃªn 33GB?**
- Dá»¯ liá»‡u gá»‘c: Chá»‰ cÃ³ 11 cá»™t
- Sau xá»­ lÃ½: ThÃªm nhiá»u cá»™t Ä‘áº·c trÆ°ng
- Má»—i sá»‘ float64 = 8 bytes
- 179M rows Ã— 9 features Ã— 8 bytes â‰ˆ 12GB + overhead â‰ˆ 33GB

#### ~~BÆ¯á»šC 3: Khá»Ÿi táº¡o tÃ¢m cá»¥m~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: Loáº¡i bá» â€“ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++** khá»Ÿi táº¡o thÃ´ng minh.

---

#### BÆ¯á»šC 3: Upload lÃªn HDFS â˜ï¸

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u lÃªn há»‡ thá»‘ng phÃ¢n tÃ¡n  
**File thá»±c thi**: `scripts/spark/setup_hdfs.sh`  
**Thá»i gian**: ~5 phÃºt  
**Input**: 1 file temp cá»¥c bá»™ (hadoop_input_temp.txt)  
**Output**: Dá»¯ liá»‡u trÃªn HDFS

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n**:
1. Kiá»ƒm tra HDFS Ä‘ang cháº¡y: `hdfs dfsadmin -report`
2. Táº¡o thÆ° má»¥c: `hdfs dfs -mkdir -p /user/spark/hi_large/input`
3. Upload input: `hdfs dfs -put hadoop_input_temp.txt /user/.../input/`
4. **XÃ“A file temp cá»¥c bá»™**: `rm -rf data/processed/*`
5. Verify: Kiá»ƒm tra kÃ­ch thÆ°á»›c file trÃªn HDFS

**ğŸ”’ TuÃ¢n thá»§ quy Ä‘á»‹nh**:
- Sau bÆ°á»›c nÃ y, KHÃ”NG cÃ²n dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
- Chá»‰ tá»“n táº¡i trÃªn HDFS (phÃ¢n tÃ¡n, an toÃ n)
- Náº¿u cáº§n, cÃ³ thá»ƒ táº£i láº¡i tá»« HDFS

#### BÆ¯á»šC 4: Cháº¡y K-means trÃªn Spark ğŸš€

**Má»¥c Ä‘Ã­ch**: PhÃ¢n cá»¥m 179 triá»‡u giao dá»‹ch báº±ng **MLlib K-means**  
**File thá»±c thi**: `scripts/spark/run_spark.sh` + `kmeans_spark.py`  
**Thá»i gian**: 10-25 phÃºt (nhanh hÆ¡n 30-50% nhá» MLlib!)  
**Input**: Dá»¯ liá»‡u tá»« HDFS  
**Output**: TÃ¢m cá»¥m cuá»‘i cÃ¹ng trÃªn HDFS

**MLlib K-means vá»›i k-means++ initialization**:
```
KHá» Táº O (Tá»° Äá»˜NG bá»Ÿi MLlib):
  - K=5 tÃ¢m cá»¥m
  - Sá»­ dá»¥ng k-means++ (thÃ´ng minh, khÃ´ng random)
  - Max iterations = 15
  - Tá»‘i Æ°u Catalyst + Tungsten engine

Láº¶P Láº I 15 Láº¦N:
  1. GÃ¡n má»—i giao dá»‹ch vÃ o cá»¥m gáº§n nháº¥t
     - TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n 5 tÃ¢m cá»¥m
     - Chá»n cá»¥m cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t
  
  2. Cáº­p nháº­t tÃ¢m cá»¥m
     - TÃ­nh trung bÃ¬nh táº¥t cáº£ Ä‘iá»ƒm trong má»—i cá»¥m
     - TÃ¢m cá»¥m má»›i = trung bÃ¬nh cÃ¡c Ä‘iá»ƒm
  
  3. Kiá»ƒm tra há»™i tá»¥
     - TÃ­nh Ä‘á»™ dá»‹ch chuyá»ƒn tÃ¢m cá»¥m
     - Náº¿u < threshold â†’ Dá»«ng láº¡i

Káº¾T QUáº¢:
  - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng (tá»‘t hÆ¡n random init)
  - Má»—i cá»¥m chá»©a bao nhiÃªu Ä‘iá»ƒm
  - Há»™i tá»¥ nhanh hÆ¡n (~10-12 iterations thay vÃ¬ 15)
```

**QuÃ¡ trÃ¬nh há»™i tá»¥ (tá»« log thá»±c táº¿)**:
```
Iteration  1: Centroid shift = 2.232  (chÆ°a á»•n Ä‘á»‹nh)
Iteration  2: Centroid shift = 1.409
Iteration  5: Centroid shift = 0.383
Iteration 10: Centroid shift = 0.046
Iteration 15: Centroid shift = 0.010  (Ä‘Ã£ há»™i tá»¥ âœ“)
```

**PhÃ¢n phá»‘i káº¿t quáº£**:
```
Cluster 0:  40,034,828 giao dá»‹ch (22.28%)
Cluster 1:  42,665,741 giao dá»‹ch (23.74%)
Cluster 2:  24,884,738 giao dá»‹ch (13.85%)
Cluster 3:  50,933,660 giao dá»‹ch (28.34%)  â† Lá»›n nháº¥t
Cluster 4:  21,183,262 giao dá»‹ch (11.79%)
```

#### BÆ¯á»šC 5: Táº£i káº¿t quáº£ vá» ğŸ“¥

**Má»¥c Ä‘Ã­ch**: Láº¥y tÃ¢m cá»¥m cuá»‘i cÃ¹ng tá»« HDFS  
**File thá»±c thi**: `scripts/spark/download_from_hdfs.sh`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `/user/spark/hi_large/output_centroids/` trÃªn HDFS  
**Output**: `data/results/final_centroids.txt` (~4KB)

**CÃ¡c bÆ°á»›c**:
1. `hdfs dfs -cat /user/.../output_centroids/part-*`
2. LÆ°u vÃ o file cá»¥c bá»™
3. Verify: Kiá»ƒm tra cÃ³ Ä‘Ãºng 5 dÃ²ng

**Táº¡i sao Ä‘Æ°á»£c phÃ©p táº£i vá»?**
- File ráº¥t nhá» (~4KB)
- Chá»‰ chá»©a káº¿t quáº£ tá»•ng há»£p, khÃ´ng pháº£i dá»¯ liá»‡u gá»‘c
- Cáº§n thiáº¿t cho bÆ°á»›c phÃ¢n tÃ­ch tiáº¿p theo

#### BÆ¯á»šC 6: GÃ¡n nhÃ£n cá»¥m cho tá»«ng giao dá»‹ch ğŸ·ï¸

**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh má»—i giao dá»‹ch thuá»™c cá»¥m nÃ o  
**File thá»±c thi**: `scripts/polars/assign_clusters_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: 
  - CSV gá»‘c tá»« HDFS (streaming)
  - 5 tÃ¢m cá»¥m tá»« bÆ°á»›c 6  
**Output**: `data/results/clustered_results.txt`

**Thuáº­t toÃ¡n**:
```python
FOR má»—i giao dá»‹ch:
    distances = []
    FOR má»—i tÃ¢m cá»¥m (5 cá»¥m):
        d = euclidean_distance(giao_dá»‹ch, tÃ¢m_cá»¥m)
        distances.append(d)
    
    cluster_id = argmin(distances)  # Chá»n cá»¥m gáº§n nháº¥t
    ghi_káº¿t_quáº£(giao_dá»‹ch, cluster_id)
```

**Xá»­ lÃ½ batch Ä‘á»ƒ tÄƒng tá»‘c**:
- KhÃ´ng xá»­ lÃ½ tá»«ng giao dá»‹ch
- Xá»­ lÃ½ 1 triá»‡u giao dá»‹ch cÃ¹ng lÃºc
- Sá»­ dá»¥ng NumPy vectorization

#### BÆ¯á»šC 7: PhÃ¢n tÃ­ch káº¿t quáº£ ğŸ“Š

**Má»¥c Ä‘Ã­ch**: TÃ¬m cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao  
**File thá»±c thi**: `scripts/polars/analyze_polars.py`  
**Thá»i gian**: ~2 phÃºt  
**Input**: `data/results/clustered_results.txt`  
**Output**: BÃ¡o cÃ¡o phÃ¢n tÃ­ch

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. **KÃ­ch thÆ°á»›c cá»¥m**: Má»—i cá»¥m cÃ³ bao nhiÃªu giao dá»‹ch?
2. **Tá»· lá»‡ rá»­a tiá»n**: % rá»­a tiá»n trong tá»«ng cá»¥m
3. **High-risk clusters**: Cá»¥m nÃ o > 10% rá»­a tiá»n?
4. **Feature averages**: Äáº·c Ä‘iá»ƒm trung bÃ¬nh má»—i cá»¥m

**Káº¿t quáº£ tá»« log thá»±c táº¿ (cháº¡y láº§n cuá»‘i 29/10/2025)**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ Giao dá»‹ch   â•‘ Rá»­a tiá»n  â•‘ Tá»· lá»‡ (%)       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 69,716,345  â•‘  90,355   â•‘ 0.130%          â•‘
â•‘    1     â•‘ 69,068,010  â•‘ 102,886   â•‘ 0.149%          â•‘
â•‘    2     â•‘ 37,012,845  â•‘  30,696   â•‘ 0.083%          â•‘
â•‘    3     â•‘         8   â•‘       1   â•‘ 12.500% â† CAO  â•‘
â•‘    4     â•‘  3,905,021  â•‘   1,608   â•‘ 0.041% â† THáº¤P â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ NHáº¬N XÃ‰T:
- Cluster 3 rá»§i ro cao (12.50%) nhÆ°ng chá»‰ cÃ³ 8 giao dá»‹ch â†’ outlier
- Cluster 4 an toÃ n nháº¥t (0.041%)
- Äa sá»‘ cá»¥m (0, 1, 2) cÃ³ tá»· lá»‡ rá»­a tiá»n < 0.15% (tá»‘t)
```

---

<a id="p5"></a>
## PHáº¦N 5: Káº¾T QUáº¢ VÃ€ ÄÃNH GIÃ

### 5.1. Káº¿t quáº£ phÃ¢n cá»¥m

#### Thá»‘ng kÃª tá»•ng quan
- **Tá»•ng giao dá»‹ch xá»­ lÃ½**: 179,702,229
- **Sá»‘ cá»¥m**: 5
- **Sá»‘ vÃ²ng láº·p**: 15
- **Thá»i gian cháº¡y**: 12 phÃºt 32 giÃ¢y
- **Convergence**: Äáº¡t Ä‘Æ°á»£c (shift < 0.01)

#### PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng cá»¥m

**ğŸ”µ Cluster 0 - Cá»¥m Lá»›n Nháº¥t**
- Sá»‘ lÆ°á»£ng: 69,716,345 (38.80%)
- Rá»­a tiá»n: 90,355 giao dá»‹ch (0.130%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh: 8.8M
  - Tá»· lá»‡ received/paid: 3.38
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO THáº¤P**

**ğŸœ¢ Cluster 1 - Cá»¥m ÄÃ´ng Thá»© Hai**
- Sá»‘ lÆ°á»£ng: 69,068,010 (38.43%)
- Rá»­a tiá»n: 102,886 giao dá»‹ch (0.149%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh: 3.32M
  - Tá»· lá»‡ received/paid: 1.00
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO THáº¤P**

**ğŸœ¡ Cluster 2 - Cá»¥m Giao Dá»‹ch Vá»«a**
- Sá»‘ lÆ°á»£ng: 37,012,845 (20.60%)
- Rá»­a tiá»n: 30,696 giao dá»‹ch (0.083%) âœ“
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh: 3.17M
  - Tá»· lá»‡ received/paid: 1.08
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO Ráº¤T THáº¤P**

**ğŸ”´ Cluster 3 - Outlier (Rá»§i Ro Cao)**
- Sá»‘ lÆ°á»£ng: 8 (0.00%) â† Ráº¤T ÃT
- Rá»­a tiá»n: 1 giao dá»‹ch (12.50%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh: 5.9 nghÃ¬n tá»· (outlier ráº¥t lá»›n)
  - Tá»· lá»‡ received/paid: 23.42
  - ÄÃ¡nh giÃ¡: **OUTLIER - Kiá»ƒm tra thá»§ cÃ´ng**

**ğŸŸª Cluster 4 - Cá»¥m An ToÃ n Nháº¥t**
- Sá»‘ lÆ°á»£ng: 3,905,021 (2.17%)
- Rá»­a tiá»n: 1,608 giao dá»‹ch (0.041%) âœ“âœ“âœ“
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh: 804
  - Tá»· lá»‡ received/paid: 1.00
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO Ráº¤T THáº¤P**

### 5.2. Nháº­n xÃ©t vÃ  Insights

#### PhÃ¡t hiá»‡n chÃ­nh
1. **Cluster 3 lÃ  outlier rá»§i ro cao**
   - Tá»· lá»‡ rá»­a tiá»n 12.50% (vÆ°á»£t ngÆ°á»¡ng 10%)
   - NHÆ¯NG chá»‰ cÃ³ 8 giao dá»‹ch trong cá»¥m nÃ y
   - ÄÃ¢y lÃ  cÃ¡c giao dá»‹ch outlier vá»›i giÃ¡ trá»‹ ráº¥t lá»›n (nghÃ¬n tá»·)
   - Khuyáº¿n nghá»‹: Kiá»ƒm tra thá»§ cÃ´ng 8 giao dá»‹ch nÃ y

2. **CÃ¡c cá»¥m chÃ­nh (0, 1, 2) ráº¥t an toÃ n**
   - Cluster 0: 0.130% (38.80% tá»•ng giao dá»‹ch)
   - Cluster 1: 0.149% (38.43% tá»•ng giao dá»‹ch)
   - Cluster 2: 0.083% (20.60% tá»•ng giao dá»‹ch)
   - Táº¥t cáº£ Ä‘á»u dÆ°á»›i 0.15% - ráº¥t tá»‘t!

3. **Cluster 4 an toÃ n nháº¥t**
   - Chá»‰ 0.041% rá»­a tiá»n (tháº¥p nháº¥t)
   - CÃ³ thá»ƒ Æ°u tiÃªn tháº¥p khi kiá»ƒm tra

4. **PhÃ¢n phá»‘i khÃ´ng Ä‘á»u**
   - 2 cá»¥m lá»›n chiáº¿m ~77% (Cluster 0, 1)
   - 1 cá»¥m outlier nhá» (Cluster 3: 8 giao dá»‹ch)
   - Thuáº­t toÃ¡n phÃ¢n biá»‡t rÃµ cÃ¡c giao dá»‹ch báº¥t thÆ°á»ng

#### So sÃ¡nh vá»›i ngÆ°á»¡ng
```
NgÆ°á»¡ng cáº£nh bÃ¡o: > 10% rá»­a tiá»n

Cluster 0: 0.130% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (38.8% giao dá»‹ch)
Cluster 1: 0.149% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (38.4% giao dá»‹ch)
Cluster 2: 0.083% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (20.6% giao dá»‹ch)
Cluster 3: 12.50% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” WARNING (chá»‰ 8 giao dá»‹ch)
Cluster 4: 0.041% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (2.2% giao dá»‹ch)
```

### 5.3. Hiá»‡u suáº¥t há»‡ thá»‘ng

#### Thá»i gian xá»­ lÃ½ chi tiáº¿t (29/10/2025 15:26-15:39)
| BÆ°á»›c | CÃ´ng viá»‡c | Thá»i gian | % Tá»•ng |
|------|-----------|-----------|--------|
| 1 | KhÃ¡m phÃ¡ | 8s | 1.1% |
| 2 | Feature Engineering | 66s | 8.8% |
| 3 | Upload HDFS | 39s | 5.2% |
| 4 | Spark MLlib K-means | 363s | 48.3% |
| 5 | Download | 3s | 0.4% |
| 6 | GÃ¡n nhÃ£n | 195s | 25.9% |
| 7 | PhÃ¢n tÃ­ch | 78s | 10.4% |
| Tá»•ng | | 752s (12 phÃºt 32 giÃ¢y) | 100% |

âœ… **Cáº£i thiá»‡n**: Nhanh hÆ¡n 30-50% so vá»›i RDD-based K-means

**Nháº­n xÃ©t**:
- K-means chiáº¿m 80.5% thá»i gian (Ä‘iá»u nÃ y lÃ  bÃ¬nh thÆ°á»ng)
- CÃ¡c bÆ°á»›c cÃ²n láº¡i ráº¥t nhanh nhá» Polars

#### So sÃ¡nh vá»›i Hadoop MapReduce
| TiÃªu chÃ­ | Hadoop (Legacy) | Spark (Hiá»‡n táº¡i) | Cáº£i thiá»‡n |
|----------|-----------------|------------------|-----------|
| Thá»i gian K-means | 1-2 giá» | 26 phÃºt | **4-8x nhanh hÆ¡n** |
| RAM sá»­ dá»¥ng | Ãt (disk-based) | Nhiá»u (in-memory) | Trade-off |
| Äá»™ phá»©c táº¡p code | Cao (mapper/reducer) | Tháº¥p (PySpark API) | Dá»… maintain |
| Debug | KhÃ³ | Dá»… (local mode) | Developer friendly |

**Káº¿t luáº­n**: Spark lÃ  lá»±a chá»n Ä‘Ãºng Ä‘áº¯n cho K-means iterative!

---

<a id="p6"></a>
## PHáº¦N 6: TUÃ‚N THá»¦ QUY Äá»ŠNH Báº¢O Máº¬T

### 6.1. Quy Ä‘á»‹nh: KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™

#### LÃ½ do cÃ³ quy Ä‘á»‹nh nÃ y
1. **Báº£o máº­t**: Dá»¯ liá»‡u khÃ¡ch hÃ ng nháº¡y cáº£m
2. **TuÃ¢n thá»§ phÃ¡p luáº­t**: GDPR, CCPA, v.v.
3. **NgÄƒn cháº·n rÃ² rá»‰**: MÃ¡y cÃ¡ nhÃ¢n dá»… bá»‹ hack
4. **Kiá»ƒm soÃ¡t truy cáº­p**: HDFS cÃ³ authentication

### 6.2. CÃ¡ch dá»± Ã¡n tuÃ¢n thá»§

#### âœ… ÄÆ¯á»¢C PHÃ‰P lÆ°u á»Ÿ mÃ¡y cá»¥c bá»™
```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ HI-Large_Trans.csv     âœ“ (File gá»‘c tá»« giáº£ng viÃªn)
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ final_centroids.txt    âœ“ (Chá»‰ 4KB - káº¿t quáº£ tá»•ng há»£p)
    â””â”€â”€ clustered_results.txt  âœ“ (CÃ³ thá»ƒ táº¡o láº¡i tá»« HDFS)
```

#### âŒ KHÃ”NG ÄÆ¯á»¢C lÆ°u á»Ÿ mÃ¡y cá»¥c bá»™
```
data/
â””â”€â”€ processed/
    â”œâ”€â”€ hadoop_input_temp.txt  âŒ (33GB - Tá»° Äá»˜NG XÃ“A)
    â””â”€â”€ centroids_temp.txt     âŒ (440B - Tá»° Äá»˜NG XÃ“A)
```

#### CÆ¡ cháº¿ tá»± Ä‘á»™ng xÃ³a
**Trong file** `scripts/spark/setup_hdfs.sh`:
```bash
# Upload lÃªn HDFS
hdfs dfs -put data/processed/hadoop_input_temp.txt /user/spark/hi_large/

# XÃ“A NGAY SAU KHI UPLOAD THÃ€NH CÃ”NG
echo "Cleaning up temp files..."
rm -rf "$PROJECT_ROOT/data/processed/"*

echo "âœ… Temp files deleted (data now only on HDFS)"
```

#### Verification (Kiá»ƒm chá»©ng)
**Kiá»ƒm tra trÆ°á»›c khi upload**:
```bash
$ du -sh data/processed/
33G    data/processed/  â† CÃ³ file temp
```

**Kiá»ƒm tra sau khi upload**:
```bash
$ du -sh data/processed/
0      data/processed/  â† ÄÃ£ xÃ³a sáº¡ch! âœ“

$ hdfs dfs -du -h /user/spark/hi_large/
31.0 G  /user/spark/hi_large/input/hadoop_input.txt  â† TrÃªn HDFS
```

### 6.3. Quy trÃ¬nh khÃ´i phá»¥c (náº¿u cáº§n)
Náº¿u cáº§n xem láº¡i dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½:
```bash
# Táº£i vá» tá»« HDFS
hdfs dfs -get /user/spark/hi_large/input/hadoop_input.txt data/processed/

# Sá»­ dá»¥ng
python scripts/polars/analyze_polars.py

# XÃ³a láº¡i sau khi dÃ¹ng xong
rm data/processed/hadoop_input.txt
```

---

<a id="p7"></a>
## PHáº¦N 7: HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### 7.1. YÃªu cáº§u há»‡ thá»‘ng

#### Pháº§n cá»©ng tá»‘i thiá»ƒu
- **CPU**: 4 cores (khuyáº¿n nghá»‹ 8+ cores)
- **RAM**: 16GB (khuyáº¿n nghá»‹ 32GB)
- **á»” cá»©ng**: 50GB trá»‘ng (cho HDFS)
- **Máº¡ng**: Náº¿u dÃ¹ng cluster, cáº§n LAN tá»‘c Ä‘á»™ cao

#### Pháº§n má»m
- **Há»‡ Ä‘iá»u hÃ nh**: Linux (Ubuntu, CentOS, Arch)
- **Java**: JDK 11 hoáº·c 17
- **Python**: 3.12+
- **Hadoop**: 3.x (HDFS)
- **Spark**: 4.0.1

#### ThÆ° viá»‡n Python
```bash
polars==0.20.x   # DataFrame library
numpy==1.26.x    # Numerical computing
pyspark==4.0.x   # Spark Python API
```

### 7.2. HÆ°á»›ng dáº«n cÃ i Ä‘áº·t tá»« Ä‘áº§u

#### BÆ°á»›c 1: CÃ i Ä‘áº·t Java
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install openjdk-17-jdk

# Arch Linux
sudo pacman -S jdk17-openjdk

# Kiá»ƒm tra
java -version  # Pháº£i tháº¥y version 17.x.x
```

#### BÆ°á»›c 2: CÃ i Ä‘áº·t Hadoop
```bash
# Download Hadoop
cd /tmp
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /opt/hadoop

# Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng (~/.bashrc hoáº·c ~/.zshrc)
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# Reload
source ~/.zshrc

# Kiá»ƒm tra
hadoop version
```

#### BÆ°á»›c 3: CÃ i Ä‘áº·t Spark (tá»± Ä‘á»™ng)
```bash
cd /home/ultimatebrok/Downloads/Final
./scripts/setup/install_spark.sh

# Script sáº½ tá»± Ä‘á»™ng:
# - Download Spark 4.0.1
# - Giáº£i nÃ©n vÃ o /opt/spark
# - ThÃªm vÃ o PATH
# - Cáº¥u hÃ¬nh SPARK_HOME

# Reload shell
source ~/.zshrc

# Kiá»ƒm tra
spark-submit --version
```

#### BÆ°á»›c 4: CÃ i Ä‘áº·t Python packages
```bash
# Táº¡o virtual environment (khuyáº¿n nghá»‹)
python3 -m venv .venv
source .venv/bin/activate

# CÃ i Ä‘áº·t
pip install polars numpy pyspark

# Kiá»ƒm tra
python -c "import polars; print(polars.__version__)"
```

#### BÆ°á»›c 5: Khá»Ÿi Ä‘á»™ng HDFS
```bash
# Format namenode (CHá»ˆ Láº¦N Äáº¦U)
hdfs namenode -format

# Khá»Ÿi Ä‘á»™ng HDFS
start-dfs.sh

# Kiá»ƒm tra
hdfs dfsadmin -report
# Pháº£i tháº¥y "Live datanodes (1)"
```

### 7.3. Cháº¡y pipeline

#### CÃ¡ch 1: Tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)
```bash
cd /home/ultimatebrok/Downloads/Final

# Äáº£m báº£o cÃ³ file CSV
ls -lh data/raw/HI-Large_Trans.csv

# Cháº¡y toÃ n bá»™ pipeline
./scripts/pipeline/full_pipeline_spark.sh

# Pipeline sáº½ tá»± Ä‘á»™ng cháº¡y 7 bÆ°á»›c (MLlib K-means)
# Thá»i gian: 35-50 phÃºt (nhanh hÆ¡n 30-50%)
# Log: logs/pipeline_log_YYYYMMDD_HHMMSS.md
```

#### CÃ¡ch 2: Tá»«ng bÆ°á»›c (Debug)
```bash
# BÆ°á»›c 1
python scripts/polars/explore_fast.py

# BÆ°á»›c 2
python scripts/polars/prepare_polars.py

# BÆ°á»›c 3 (Upload to HDFS)
scripts/spark/setup_hdfs.sh

# BÆ°á»›c 4 (MLlib K-means - tá»± Ä‘á»™ng dÃ¹ng k-means++)
scripts/spark/run_spark.sh

# BÆ°á»›c 5
scripts/spark/download_from_hdfs.sh

# BÆ°á»›c 6
python scripts/polars/assign_clusters_polars.py

# BÆ°á»›c 7
python scripts/polars/analyze_polars.py
```

### 7.4. Xem káº¿t quáº£

```bash
# Xem log pipeline
cat logs/pipeline_log_*.md

# Xem tÃ¢m cá»¥m cuá»‘i cÃ¹ng
cat data/results/final_centroids.txt

# Xem dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n (10 dÃ²ng Ä‘áº§u)
head data/results/clustered_results.txt
```

---

<a id="p8"></a>
## PHáº¦N 8: Xá»¬ LÃ Sá»° Cá»

### 8.1. Lá»—i thÆ°á»ng gáº·p

#### Lá»—i 1: HDFS khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c
**Triá»‡u chá»©ng**:
```
hdfs dfsadmin -report
Connection refused
```

**NguyÃªn nhÃ¢n**: HDFS chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng
**Giáº£i phÃ¡p**:
```bash
# Kiá»ƒm tra process
jps  # Pháº£i tháº¥y NameNode vÃ  DataNode

# Náº¿u khÃ´ng tháº¥y, khá»Ÿi Ä‘á»™ng láº¡i
stop-dfs.sh
start-dfs.sh

# Äá»£i 10 giÃ¢y rá»“i kiá»ƒm tra
hdfs dfsadmin -report
```

#### Lá»—i 2: Out of Memory trong Spark
**Triá»‡u chá»©ng**:
```
java.lang.OutOfMemoryError: Java heap space
```

**NguyÃªn nhÃ¢n**: RAM khÃ´ng Ä‘á»§ cho executor
**Giáº£i phÃ¡p**: TÄƒng memory trong `scripts/spark/run_spark.sh`
```bash
# TÃ¬m dÃ²ng:
--driver-memory 4g \
--executor-memory 4g \

# Sá»­a thÃ nh (náº¿u cÃ³ Ä‘á»§ RAM):
--driver-memory 8g \
--executor-memory 8g \
```

#### Lá»—i 3: File temp khÃ´ng tá»± Ä‘á»™ng xÃ³a
**Triá»‡u chá»©ng**: Váº«n tháº¥y file trong `data/processed/`
**NguyÃªn nhÃ¢n**: Script bá»‹ lá»—i giá»¯a chá»«ng
**Giáº£i phÃ¡p**: XÃ³a thá»§ cÃ´ng
```bash
rm -rf data/processed/*

# Hoáº·c cháº¡y script cleanup
./scripts/pipeline/clean_spark.sh
```

#### Lá»—i 4: Polars bÃ¡o lá»—i memory
**Triá»‡u chá»©ng**:
```
MemoryError: Unable to allocate array
```

**NguyÃªn nhÃ¢n**: RAM khÃ´ng Ä‘á»§ khi load CSV
**Giáº£i phÃ¡p**: DÃ¹ng streaming mode
```python
# Thay vÃ¬:
df = pl.read_csv('file.csv')

# DÃ¹ng:
df = pl.scan_csv('file.csv')  # Lazy, khÃ´ng load háº¿t vÃ o RAM
df.sink_csv('output.csv')     # Stream ra file
```

### 8.2. Kiá»ƒm tra há»‡ thá»‘ng

#### Checklist trÆ°á»›c khi cháº¡y
```bash
# 1. Java
java -version  # Pháº£i cÃ³ version 11 hoáº·c 17

# 2. HDFS
hdfs dfsadmin -report  # Pháº£i tháº¥y "Live datanodes"

# 3. Spark
spark-submit --version  # Pháº£i cÃ³ version 4.x

# 4. Python packages
python -c "import polars, numpy, pyspark"  # KhÃ´ng lá»—i

# 5. File CSV
ls -lh data/raw/HI-Large_Trans.csv  # Pháº£i ~16GB

# 6. Disk space
df -h  # Pháº£i cÃ²n > 50GB trá»‘ng
```

---

<a id="p9"></a>
## PHáº¦N 9: Káº¾T LUáº¬N VÃ€ HÆ¯á»šNG PHÃT TRIá»‚N

### 9.1. Tá»•ng káº¿t dá»± Ã¡n

#### Nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c
âœ… **Vá» ká»¹ thuáº­t**:
- Xá»­ lÃ½ thÃ nh cÃ´ng 179 triá»‡u giao dá»‹ch (16GB CSV)
- Ãp dá»¥ng **MLlib K-means** vá»›i k-means++ trÃªn Apache Spark
- Thá»i gian xá»­ lÃ½: 30 phÃºt (nhanh hÆ¡n Hadoop 4-8 láº§n, nhanh hÆ¡n RDD 30-50%)
- XÃ¢y dá»±ng pipeline tá»± Ä‘á»™ng **7 bÆ°á»›c** (tá»‘i Æ°u tá»« 8 bÆ°á»›c)
- TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t dá»¯ liá»‡u

âœ… **Vá» há»c mÃ¡y**:
- PhÃ¢n cá»¥m thÃ nh cÃ´ng thÃ nh 5 nhÃ³m
- Thuáº­t toÃ¡n há»™i tá»¥ tá»‘t (shift < 0.01)
- PhÃ¡t hiá»‡n 225,546 giao dá»‹ch nghi ngá»
- XÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cá»¥m rá»§i ro cao nháº¥t (Cluster 1)

âœ… **Vá» phÃ¡t triá»ƒn pháº§n má»m**:
- Code cÃ³ cáº¥u trÃºc rÃµ rÃ ng (modular)
- TÃ i liá»‡u Ä‘áº§y Ä‘á»§, dá»… hiá»ƒu
- Dá»… báº£o trÃ¬ vÃ  má»Ÿ rá»™ng
- CÃ³ há»‡ thá»‘ng log chi tiáº¿t

#### Háº¡n cháº¿
âš ï¸ **Vá» thuáº­t toÃ¡n**:
- K-means nháº¡y cáº£m vá»›i K ban Ä‘áº§u
- ChÆ°a tá»± Ä‘á»™ng chá»n K tá»‘i Æ°u (hiá»‡n táº¡i fix K=5)
- ChÆ°a xá»­ lÃ½ outliers (Ä‘iá»ƒm ngoáº¡i lai)

âš ï¸ **Vá» infrastructure**:
- Cháº¡y trÃªn single machine (pseudo-distributed)
- ChÆ°a test trÃªn cluster tháº­t
- ChÆ°a cÃ³ monitoring real-time

### 9.2. HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

#### 1. Cáº£i thiá»‡n thuáº­t toÃ¡n
**Tá»± Ä‘á»™ng chá»n K tá»‘i Æ°u**:
- DÃ¹ng Elbow Method
- DÃ¹ng Silhouette Score
- Cháº¡y K-means vá»›i nhiá»u K (3, 5, 7, 10) vÃ  so sÃ¡nh

**Khá»Ÿi táº¡o tá»‘t hÆ¡n**:
- âœ… **ÄÃ£ Ã¡p dá»¥ng**: MLlib K-means tá»± Ä‘á»™ng dÃ¹ng k-means++
- Káº¿t quáº£: Giáº£m sá»‘ vÃ²ng láº·p (15 â†’ 10-12), á»•n Ä‘á»‹nh hÆ¡n

**Xá»­ lÃ½ outliers**:
- PhÃ¡t hiá»‡n vÃ  loáº¡i bá» outliers trÆ°á»›c khi cluster
- DÃ¹ng DBSCAN hoáº·c Isolation Forest

#### 2. Machine Learning nÃ¢ng cao
**Supervised Learning**:
- DÃ¹ng nhÃ£n "Is Laundering" Ä‘á»ƒ train model
- Thá»­ Random Forest, XGBoost
- So sÃ¡nh accuracy, precision, recall

**Deep Learning**:
- Neural Network cho phÃ¡t hiá»‡n anomaly
- Autoencoder Ä‘á»ƒ há»c representation
- LSTM cho time series patterns

**Ensemble Methods**:
- Káº¿t há»£p nhiá»u models
- Voting mechanism
- TÄƒng Ä‘á»™ chÃ­nh xÃ¡c

#### 3. Real-time Processing
**Spark Streaming**:
- Xá»­ lÃ½ giao dá»‹ch real-time khi chÃºng xáº£y ra
- Cáº£nh bÃ¡o tá»©c thÃ¬ khi phÃ¡t hiá»‡n nghi ngá»
- DÃ¹ng Kafka lÃ m message queue

**Dashboard**:
- Visualize clusters báº±ng Plotly
- Real-time monitoring
- Alert system

#### 4. Deployment
**Containerization**:
```dockerfile
# Dockerfile
FROM apache/spark:4.0.1
COPY scripts/ /app/scripts/
COPY data/ /app/data/
CMD ["./scripts/pipeline/full_pipeline_spark.sh"]
```

**Kubernetes**:
- Orchestrate Spark cluster
- Auto-scaling based on load
- High availability

**CI/CD**:
- GitHub Actions cho testing
- Automated deployment
- Version control

#### 5. Báº£o máº­t nÃ¢ng cao
- Encryption at rest (HDFS)
- Encryption in transit (SSL/TLS)
- Role-based access control
- Audit logging

### 9.3. BÃ i há»c kinh nghiá»‡m

#### Vá» ká»¹ thuáº­t
1. **Chá»n cÃ´ng nghá»‡ phÃ¹ há»£p**:
   - Polars cho single-machine processing
   - Spark cho distributed processing
   - HDFS cho storage
   - Má»—i tool cÃ³ strengths riÃªng

2. **Pipeline automation**:
   - Viáº¿t scripts Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a
   - Sá»­ dá»¥ng checkpoints
   - Logging Ä‘áº§y Ä‘á»§

3. **TuÃ¢n thá»§ quy Ä‘á»‹nh tá»« Ä‘áº§u**:
   - Thiáº¿t káº¿ kiáº¿n trÃºc vá»›i security in mind
   - Tá»± Ä‘á»™ng xÃ³a temp files
   - KhÃ´ng lÆ°u dá»¯ liá»‡u nháº¡y cáº£m local

#### Vá» há»c mÃ¡y
1. **Feature engineering quan trá»ng**:
   - Parse timestamp â†’ temporal features
   - TÃ­nh ratio Ä‘á»ƒ phÃ¡t hiá»‡n báº¥t thÆ°á»ng
   - Normalize Ä‘á»ƒ thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng tá»‘t

2. **K-means cáº§n fine-tuning**:
   - Chá»n K phÃ¹ há»£p
   - Khá»Ÿi táº¡o centroids tá»‘t
   - Kiá»ƒm tra convergence

3. **Validation ráº¥t quan trá»ng**:
   - PhÃ¢n tÃ­ch káº¿t quáº£ sau má»—i run
   - So sÃ¡nh vá»›i ground truth
   - Iterate Ä‘á»ƒ cáº£i thiá»‡n

---

<a id="phu-luc"></a>
## PHá»¤ Lá»¤C

### A. Thuáº­t ngá»¯ vÃ  Giáº£i thÃ­ch

**Big Data**: Dá»¯ liá»‡u cÃ³ quy mÃ´ lá»›n (>1TB), cáº§n cÃ´ng nghá»‡ Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½

**Cluster**: NhÃ³m mÃ¡y tÃ­nh lÃ m viá»‡c cÃ¹ng nhau nhÆ° má»™t há»‡ thá»‘ng

**Distributed Computing**: Xá»­ lÃ½ phÃ¢n tÃ¡n trÃªn nhiá»u mÃ¡y song song

**HDFS**: Hadoop Distributed File System - Há»‡ thá»‘ng file phÃ¢n tÃ¡n

**In-memory Computing**: Xá»­ lÃ½ trong RAM thay vÃ¬ Ä‘á»c/ghi disk liÃªn tá»¥c

**K-means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m khÃ´ng giÃ¡m sÃ¡t

**Polars**: ThÆ° viá»‡n DataFrame nhanh cho Python

**Spark**: Framework xá»­ lÃ½ big data in-memory

**Unsupervised Learning**: Há»c mÃ¡y khÃ´ng cáº§n nhÃ£n (tá»± phÃ¢n nhÃ³m)

**Centroid**: TÃ¢m cá»¥m - Äiá»ƒm trung tÃ¢m cá»§a má»™t nhÃ³m dá»¯ liá»‡u

**Convergence**: Há»™i tá»¥ - Thuáº­t toÃ¡n Ä‘áº¡t tráº¡ng thÃ¡i á»•n Ä‘á»‹nh

**Feature Engineering**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u thÃ´

**Normalize**: Chuáº©n hÃ³a - ÄÆ°a dá»¯ liá»‡u vá» cÃ¹ng scale

**Pipeline**: Quy trÃ¬nh tá»± Ä‘á»™ng tá»« input Ä‘áº¿n output

**Replication**: Sao lÆ°u dá»¯ liá»‡u trÃªn nhiá»u mÃ¡y

### B. Cáº¥u trÃºc thÆ° má»¥c Ä‘áº§y Ä‘á»§

```
Final/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ HI-Large_Trans.csv
â”‚   â”œâ”€â”€ processed/              (rá»—ng - files tá»± Ä‘á»™ng xÃ³a)
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ final_centroids.txt
â”‚       â””â”€â”€ clustered_results.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ polars/
â”‚   â”‚   â”œâ”€â”€ explore_fast.py
â”‚   â”‚   â”œâ”€â”€ prepare_polars.py
â”‚   â”‚   â”œâ”€â”€ assign_clusters_polars.py
â”‚   â”‚   â””â”€â”€ analyze_polars.py
â”‚   â”‚
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ setup_hdfs.sh
â”‚   â”‚   â”œâ”€â”€ run_spark.sh
â”‚   â”‚   â”œâ”€â”€ kmeans_spark.py
â”‚   â”‚   â””â”€â”€ download_from_hdfs.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ full_pipeline_spark.sh
â”‚   â”‚   â”œâ”€â”€ clean_spark.sh
â”‚   â”‚   â””â”€â”€ reset_pipeline.sh
â”‚   â”‚
â”‚   â””â”€â”€ setup/
â”‚       â””â”€â”€ install_spark.sh
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md
â”‚   â””â”€â”€ HADOOP_ALTERNATIVES.md
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline_log_20251028_202850.md
â”‚
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ hadoop/                (legacy code)
â”‚
â”œâ”€â”€ .venv/                     (Python virtual env)
â”œâ”€â”€ .git/                      (Version control)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ CHANGELOG.md
â””â”€â”€ PROJECT_REPORT.md          (BÃ¡o cÃ¡o nÃ y)
```

### C. Thá»‘ng kÃª dá»± Ã¡n

- **Tá»•ng sá»‘ file Python**: 6 files, 442 dÃ²ng code
- **Tá»•ng sá»‘ file Shell**: 7 files, 661 dÃ²ng code
- **Tá»•ng dÃ²ng code**: 1,103 dÃ²ng
- **Thá»i gian phÃ¡t triá»ƒn**: 3 tuáº§n
- **CÃ´ng nghá»‡ sá»­ dá»¥ng**: 5 (Polars, Spark, HDFS, Python, NumPy)
- **Sá»‘ bÆ°á»›c pipeline**: 7
- **Thá»i gian cháº¡y**: 30 phÃºt

---

### D. TÃ i liá»‡u tham kháº£o

1. Apache Spark Documentation: https://spark.apache.org/docs/latest/
2. Polars Guide: https://pola-rs.github.io/polars-book/
3. Hadoop HDFS: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/
4. K-means Algorithm: https://scikit-learn.org/stable/modules/clustering.html#k-means
5. Money Laundering Detection: Research papers on financial crime

---


**Háº¾T BÃO CÃO**


_BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi `generate_vietnamese_report.py`_  
_NgÃ y: 28/10/2025 22:04:46_
# BÃO CÃO TIá»‚U LUáº¬N: PhÃ¢n cá»¥m K-means

## Má»¤C Lá»¤C

- [Báº£ng phÃ¢n chia cÃ´ng viá»‡c](#bang-phan-chia-cong-viec)
- [I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t](#i-tong-quan-va-ly-thuyet)
  - [A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means](#a-gioi-thieu-ve-cac-thuat-toan-k-means)
    - [1. Thuáº­t toÃ¡n K-means](#1-thuat-toan-k-means)
      - [a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means](#a-cach-thuc-hoat-dong-cua-k-means)
      - [b. K-means++](#b-k-means)
      - [c. Æ¯u Ä‘iá»ƒm cá»§a K-means](#c-uu-diem-cua-k-means)
      - [d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means](#d-nhuoc-diem-cua-k-means)
      - [e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means](#e-cac-tham-so-quan-trong-cua-k-means)
      - [f. á»¨ng dá»¥ng cá»§a K-means](#f-ung-dung-cua-k-means)
  - [B. LÃ½ thuyáº¿t HDFS](#b-ly-thuyet-hdfs)
  - [C. LÃ½ thuyáº¿t Apache Spark](#c-ly-thuyet-apache-spark)
  - [D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng](#d-cac-cong-nghe-su-dung)
    - [Polars](#polars)
    - [PySpark](#pyspark)
    - [NumPy](#numpy)
    - [HDFS](#hdfs)
    - [Apache Spark](#apache-spark)
- [II. MÃ´ táº£ bÃ i toÃ¡n](#ii-mo-ta-bai-toan)
  - [A. LÃ½ do chá»n Ä‘á» tÃ i](#a-ly-do-chon-de-tai)
  - [B. MÃ´ táº£ bÃ i toÃ¡n](#b-mo-ta-bai-toan)
  - [C. Quy trÃ¬nh thá»±c hiá»‡n](#c-quy-trinh-thuc-hien)

---

<a id="bang-phan-chia-cong-viec"></a>
## Báº£ng phÃ¢n chia cÃ´ng viá»‡c

| Háº¡ng má»¥c                        | Sinh viÃªn 1 | Sinh viÃªn 2 | Ghi chÃº                         |
|-------------------------------------|-------------|-------------|------------------------------------|
| Kháº£o sÃ¡t thuáº­t toÃ¡n K-means      | X           |             | TÃ i liá»‡u, vÃ­ dá»¥ minh há»a       |
| Thiáº¿t káº¿ quy trÃ¬nh, pipeline     |             | X           | **7 bÆ°á»›c** (MLlib k-means++) |
| Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Polars)  | X           |             | Chuáº©n hÃ³a, mÃ£ hÃ³a             |
| Spark MLlib K-means vÃ  tá»‘i Æ°u     |             | X           | Cáº¥u hÃ¬nh, theo dÃµi há»™i tá»¥     |
| GÃ¡n nhÃ£n vÃ  phÃ¢n tÃ­ch           | X           | X           | Tá»•ng há»£p káº¿t quáº£              |
| Viáº¿t bÃ¡o cÃ¡o, trÃ¬nh bÃ y       | X           | X           | BiÃªn táº­p cuá»‘i                |

---

<a id="i-tong-quan-va-ly-thuyet"></a>
## I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t

<a id="a-gioi-thieu-ve-cac-thuat-toan-k-means"></a>
### A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means

<a id="1-thuat-toan-k-means"></a>
#### 1. Thuáº­t toÃ¡n K-means

<a id="a-cach-thuc-hoat-dong-cua-k-means"></a>
##### a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means

- Khá»Ÿi táº¡o K tÃ¢m cá»¥m (centroid) ban Ä‘áº§u.
- Láº·p cho Ä‘áº¿n khi há»™i tá»¥:
  1) GÃ¡n má»—i Ä‘iá»ƒm vÃ o cá»¥m cÃ³ centroid gáº§n nháº¥t (thÆ°á»ng dÃ¹ng khoáº£ng cÃ¡ch Euclidean).
  2) Cáº­p nháº­t centroid báº±ng trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m.
- Dá»«ng khi tÃ¢m cá»¥m thay Ä‘á»•i ráº¥t nhá» (dÆ°á»›i ngÆ°á»¡ng) hoáº·c Ä‘áº¡t sá»‘ vÃ²ng láº·p tá»‘i Ä‘a.

<a id="b-k-means"></a>
##### b. K-means++

- CÃ¡ch khá»Ÿi táº¡o tÃ¢m cá»¥m thÃ´ng minh nháº±m giáº£m rá»§i ro rÆ¡i vÃ o nghiá»‡m kÃ©m:
  - Chá»n ngáº«u nhiÃªn 1 Ä‘iá»ƒm lÃ m tÃ¢m Ä‘áº§u tiÃªn.
  - Vá»›i má»—i tÃ¢m tiáº¿p theo, chá»n xÃ¡c suáº¥t tá»‰ lá»‡ vá»›i bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch Ä‘áº¿n tÃ¢m gáº§n nháº¥t.
- Lá»£i Ã­ch: thÆ°á»ng há»™i tá»¥ nhanh hÆ¡n vÃ  cháº¥t lÆ°á»£ng phÃ¢n cá»¥m tá»‘t hÆ¡n so vá»›i khá»Ÿi táº¡o ngáº«u nhiÃªn.

<a id="c-uu-diem-cua-k-means"></a>
##### c. Æ¯u Ä‘iá»ƒm cá»§a K-means

- ÄÆ¡n giáº£n, dá»… cÃ i Ä‘áº·t vÃ  giáº£i thÃ­ch.
- Tá»‘c Ä‘á»™ nhanh, má»Ÿ rá»™ng tá»‘t cho dá»¯ liá»‡u lá»›n.
- Hiá»‡u quáº£ khi cá»¥m cÃ³ dáº¡ng lá»“i vÃ  phÃ¢n tÃ¡ch khÃ¡ rÃµ.

<a id="d-nhuoc-diem-cua-k-means"></a>
##### d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means

- Cáº§n chá»n trÆ°á»›c K (sá»‘ cá»¥m).
- Nháº¡y cáº£m vá»›i tÃ¢m khá»Ÿi táº¡o vÃ  outlier.
- Giáº£ Ä‘á»‹nh cá»¥m cÃ³ phÆ°Æ¡ng sai gáº§n nhau (hÃ¬nh cáº§u) vÃ  dÃ¹ng cÃ¹ng má»™t thÆ°á»›c Ä‘o khoáº£ng cÃ¡ch.

<a id="e-cac-tham-so-quan-trong-cua-k-means"></a>
##### e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means

- K (sá»‘ cá»¥m), init (random/K-means++), max_iter, n_init, tol (ngÆ°á»¡ng há»™i tá»¥), metric (thÆ°á»ng lÃ  Euclidean).

<a id="f-ung-dung-cua-k-means"></a>
##### f. á»¨ng dá»¥ng cá»§a K-means

- PhÃ¢n khÃºc khÃ¡ch hÃ ng, gá»£i Ã½ sáº£n pháº©m, phÃ¡t hiá»‡n báº¥t thÆ°á»ng sÆ¡ bá»™, nÃ©n dá»¯ liá»‡u (vector quantization), khá»Ÿi táº¡o cho cÃ¡c thuáº­t toÃ¡n khÃ¡c.

<a id="b-ly-thuyet-hdfs"></a>
### B. LÃ½ thuyáº¿t HDFS

- HDFS (Hadoop Distributed File System) lÃ  há»‡ thá»‘ng file phÃ¢n tÃ¡n, thiáº¿t káº¿ Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c file ráº¥t lá»›n trÃªn cá»¥m mÃ¡y.
- ThÃ nh pháº§n chÃ­nh:
  - NameNode: LÆ°u metadata (namespace, vá»‹ trÃ­ block), Ä‘iá»u phá»‘i truy cáº­p.
  - DataNode: LÆ°u dá»¯ liá»‡u dáº¡ng block trÃªn Ä‘Ä©a, phá»¥c vá»¥ Ä‘á»c/ghi.
- KhÃ¡i niá»‡m cá»‘t lÃµi:
  - Block: ÄÆ¡n vá»‹ lÆ°u trá»¯ (máº·c Ä‘á»‹nh 128MB hoáº·c 256MB).
  - Replication Factor: Má»—i block Ä‘Æ°á»£c sao chÃ©p N báº£n Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n.
  - Rack Awareness: PhÃ¢n phá»‘i báº£n sao trÃªn nhiá»u rack Ä‘á»ƒ tÄƒng tÃ­nh sáºµn sÃ ng.
- Luá»“ng ghi: Client yÃªu cáº§u NameNode â†’ nháº­n danh sÃ¡ch DataNode â†’ pipeline ghi theo chuá»—i, tá»«ng block Ä‘Æ°á»£c replicate.
- Luá»“ng Ä‘á»c: Client há»i NameNode vá»‹ trÃ­ block â†’ Ä‘á»c trá»±c tiáº¿p tá»« DataNode gáº§n nháº¥t (data locality).
- Æ¯u Ä‘iá»ƒm: Dung lÆ°á»£ng má»Ÿ rá»™ng tuyáº¿n tÃ­nh, chá»‹u lá»—i tá»‘t, throughput cao. NhÆ°á»£c: Äá»™ trá»… (latency) cao, khÃ´ng phÃ¹ há»£p file nhá» ráº¥t nhiá»u.

VÃ­ dá»¥ lá»‡nh HDFS thÆ°á»ng dÃ¹ng:

```bash
# Kiá»ƒm tra cá»¥m HDFS
hdfs dfsadmin -report

# Táº¡o thÆ° má»¥c vÃ  upload
hdfs dfs -mkdir -p /user/spark/hi_large/input
hdfs dfs -put data/processed/hadoop_input_temp.txt /user/spark/hi_large/input/

# Liá»‡t kÃª vÃ  kiá»ƒm tra kÃ­ch thÆ°á»›c
hdfs dfs -ls -h /user/spark/hi_large/input
hdfs dfs -du -h /user/spark/hi_large/input
```

<a id="c-ly-thuyet-apache-spark"></a>
### C. LÃ½ thuyáº¿t Apache Spark

- Kiáº¿n trÃºc: Driver (Ä‘iá»u phá»‘i) + Executors (thá»±c thi) + Cluster Manager (Standalone/YARN/K8s).
- MÃ´ hÃ¬nh thá»±c thi: DAG cá»§a transformations â†’ chia thÃ nh stages â†’ tasks song song trÃªn partitions.
- KhÃ¡i niá»‡m chÃ­nh:
  - RDD/DataFrame/Dataset: Abstraction dá»¯ liá»‡u báº¥t biáº¿n, phÃ¢n tÃ¡n.
  - Lazy Evaluation: Chá»‰ thá»±c thi khi cÃ³ action (count, collect, write...).
  - Catalyst Optimizer & Tungsten: Tá»‘i Æ°u logic vÃ  thá»±c thi trong bá»™ nhá»›.
  - Shuffle: Trao Ä‘á»•i dá»¯ liá»‡u giá»¯a nodes theo key, chi phÃ­ cao cáº§n háº¡n cháº¿.
- Bá»™ nhá»›: PhÃ¢n vÃ¹ng cho execution vs. storage; cache/persist Ä‘á»ƒ chia sáº» trung gian giá»¯a cÃ¡c bÆ°á»›c láº·p.

VÃ­ dá»¥ K-means vá»›i PySpark MLlib (rÃºt gá»n):

```python
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans

spark = SparkSession.builder.getOrCreate()

# Äá»c dá»¯ liá»‡u Ä‘Ã£ chuáº©n hoÃ¡ tá»« HDFS (vÃ­ dá»¥)
df = spark.read.csv(
    "hdfs:///user/spark/hi_large/input/hadoop_input.txt",
    header=False,
    inferSchema=True,
)

# GhÃ©p cá»™t Ä‘áº·c trÆ°ng thÃ nh vector cho MLlib
assembler = VectorAssembler(
    inputCols=[
        # Ä‘iá»n danh sÃ¡ch cá»™t Ä‘áº·c trÆ°ng sá»‘ á»Ÿ Ä‘Ã¢y
    ],
    outputCol="features",
)
vec = assembler.transform(df).select("features").cache()

kmeans = KMeans(k=5, maxIter=15, seed=42, featuresCol="features", predictionCol="cluster")
model = kmeans.fit(vec)
centers = model.clusterCenters()
```

<a id="d-cac-cong-nghe-su-dung"></a>
### D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng

<a id="polars"></a>
#### Polars

- Vai trÃ²: Tiá»n xá»­ lÃ½ nhanh trÃªn 1 mÃ¡y (CSV lá»›n), lazy/streaming vÆ°á»£t quÃ¡ RAM.
- TÃ­nh nÄƒng: Expression API, parallel compute, memory efficient (Rust backend).
- VÃ­ dá»¥:

```python
import polars as pl

df = pl.scan_csv("data/raw/HI-Large_Trans.csv")  # lazy, khÃ´ng táº£i háº¿t vÃ o RAM

features = (
    df.with_columns([
        (pl.col("Amount Received") / pl.col("Amount Paid")).alias("amount_ratio"),
    ])
    .select([
        pl.col("amount_ratio").clip(0, 10),
        pl.col("Payment Currency"),
    ])
)

features.sink_csv("data/processed/sample_features.csv")  # streaming
```

<a id="pyspark"></a>
#### PySpark

- Vai trÃ²: API Python cho Spark; cháº¡y phÃ¢n tÃ¡n, phÃ¹ há»£p thuáº­t toÃ¡n láº·p nhÆ° K-means.
- TÃ­nh nÄƒng: DataFrame, MLlib, Structured Streaming, Catalyst optimizer.
- VÃ­ dá»¥ lá»‡nh submit:

```bash
spark-submit \
  --driver-memory 4g \
  --executor-memory 4g \
  scripts/spark/kmeans_spark.py
```

<a id="numpy"></a>
#### NumPy

- Vai trÃ²: TÄƒng tá»‘c tÃ­nh toÃ¡n vector/matrix, Ä‘áº·c biá»‡t khi gÃ¡n nhÃ£n theo khoáº£ng cÃ¡ch.
- VÃ­ dá»¥ tÃ­nh khoáº£ng cÃ¡ch Euclid theo batch:

```python
import numpy as np

X = np.random.rand(1_000_000, 9)  # features
C = np.random.rand(5, 9)          # centroids

dists = np.sqrt(((X[:, None, :] - C[None, :, :]) ** 2).sum(axis=2))
labels = dists.argmin(axis=1)
```

<a id="hdfs"></a>
#### HDFS

- Vai trÃ²: LÆ°u trá»¯ phÃ¢n tÃ¡n dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ  káº¿t quáº£ mÃ´ hÃ¬nh; Ä‘áº£m báº£o an toÃ n vÃ  má»Ÿ rá»™ng.
- Lá»‡nh há»¯u Ã­ch: `hdfs dfs -put`, `-get`, `-ls -h`, `-du -h`, `dfsadmin -report`.

<a id="apache-spark"></a>
#### Apache Spark

- Vai trÃ²: Ná»n táº£ng thá»±c thi phÃ¢n tÃ¡n trong bá»™ nhá»›; tá»‘i Æ°u cho xá»­ lÃ½ láº·p vÃ  ETL.
- Best practices: Cache dá»¯ liá»‡u dÃ¹ng láº¡i; tá»‘i Æ°u sá»‘ partitions; giáº£m shuffle; giÃ¡m sÃ¡t UI táº¡i `http://localhost:4040` khi cháº¡y local.

---

<a id="ii-mo-ta-bai-toan"></a>
## II. MÃ´ táº£ bÃ i toÃ¡n

<a id="a-ly-do-chon-de-tai"></a>
### A. LÃ½ do chá»n Ä‘á» tÃ i

- Dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh cá»±c lá»›n, cáº§n phÃ¢n cá»¥m Ä‘á»ƒ hiá»ƒu hÃ nh vi vÃ  nháº­n diá»‡n báº¥t thÆ°á»ng.
- K-means lÃ  thuáº­t toÃ¡n nhanh, dá»… má»Ÿ rá»™ng, phÃ¹ há»£p cho bÆ°á»›c phÃ¢n nhÃ³m ná»n táº£ng trÆ°á»›c khi Ä‘i sÃ¢u.
- Táº­n dá»¥ng háº¡ táº§ng phÃ¢n tÃ¡n (Spark) vÃ  xá»­ lÃ½ cá»¥c bá»™ nhanh (Polars) Ä‘á»ƒ rÃºt ngáº¯n thá»i gian.

<a id="b-mo-ta-bai-toan"></a>
### B. MÃ´ táº£ bÃ i toÃ¡n

- Äáº§u vÃ o: Táº­p dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh nhiá»u cá»™t (thá»i gian, ngÃ¢n hÃ ng, tÃ i khoáº£n, sá»‘ tiá»n, loáº¡i tiá»n...).
- Má»¥c tiÃªu: Tiá»n xá»­ lÃ½ vÃ  chuáº©n hÃ³a Ä‘áº·c trÆ°ng, sau Ä‘Ã³ phÃ¢n cá»¥m K-means Ä‘á»ƒ phÃ¢n nhÃ³m giao dá»‹ch cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±; dÃ¹ng káº¿t quáº£ Ä‘á»ƒ phÃ¢n tÃ­ch cá»¥m rá»§i ro.
- RÃ ng buá»™c: Tá»‘i Æ°u thá»i gian xá»­ lÃ½; khÃ´ng lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™ sau khi Ä‘áº©y lÃªn HDFS.

<a id="c-quy-trinh-thuc-hien"></a>
### C. Quy trÃ¬nh thá»±c hiá»‡n

#### Tá»•ng quan quy trÃ¬nh 7 bÆ°á»›c

âš ï¸ **LÆ°u Ã½**: Pipeline Ä‘Ã£ tá»‘i Æ°u tá»« 8 bÆ°á»›c xuá»‘ng cÃ²n 7 bÆ°á»›c. BÆ°á»›c khá»Ÿi táº¡o centroids Ä‘Ã£ loáº¡i bá» vÃ¬ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng k-means++.

```
BÆ¯á»šC 1        BÆ¯á»šC 2        BÆ¯á»šC 3
KhÃ¡m phÃ¡  â†’   Xá»­ lÃ½    â†’   Upload
 (30s)        (10 phÃºt)      (5 phÃºt)

BÆ¯á»šC 4            BÆ¯á»šC 5        BÆ¯á»šC 6        BÆ¯á»šC 7
K-means (MLlib) â†’   Táº£i vá»   â†’   GÃ¡n nhÃ£n  â†’   PhÃ¢n tÃ­ch
(10-25p k-means++)    (30s)       (10 phÃºt)     (2 phÃºt)

Tá»”NG THá»œI GIAN: 35-50 phÃºt (nhanh hÆ¡n 30-50%!)
```

#### Chi tiáº¿t tá»«ng bÆ°á»›c

##### BÆ¯á»šC 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u ğŸ”

**Má»¥c Ä‘Ã­ch**: Hiá»ƒu cáº¥u trÃºc vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u  
**File thá»±c thi**: `scripts/polars/explore_fast.py`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: Thá»‘ng kÃª in ra mÃ n hÃ¬nh

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. Äá»c 100,000 dÃ²ng Ä‘áº§u (Ä‘áº¡i diá»‡n)
2. Xem schema: TÃªn cá»™t, kiá»ƒu dá»¯ liá»‡u
3. Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median, std
4. PhÃ¢n tÃ­ch nhÃ£n: Bao nhiÃªu % rá»­a tiá»n?
5. Top loáº¡i tiá»n tá»‡ phá»• biáº¿n

**Káº¿t quáº£ vÃ­ dá»¥**:
```
Total rows: 179,702,229
Laundering rate: 0.126%
Top currencies: Euro (23%), Yuan (7.2%)
```

##### BÆ¯á»šC 2: Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ğŸ”§

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n xá»­ lÃ½  
**File thá»±c thi**: `scripts/polars/prepare_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: `data/processed/hadoop_input_temp.txt` (33GB, Táº M THá»œI)

**CÃ¡c bÆ°á»›c xá»­ lÃ½**:
1. **Parse timestamp**: "2022/08/01 00:17" â†’ giá»=0, ngÃ y=0 (Thá»© 2)
2. **TÃ­nh ratio**: amount_ratio = 6794.63 / 7739.29 = 0.878
3. **Hash route**: hash(20, 20) = 400 (vÃ­ dá»¥)
4. **Encode currency**: "US Dollar" â†’ 0, "Yuan" â†’ 1
5. **Normalize**: ÄÆ°a táº¥t cáº£ vá» [0, 1]

**Táº¡i sao láº¡i tÄƒng tá»« 16GB lÃªn 33GB?**
- Dá»¯ liá»‡u gá»‘c: Chá»‰ cÃ³ 11 cá»™t
- Sau xá»­ lÃ½: ThÃªm nhiá»u cá»™t Ä‘áº·c trÆ°ng
- Má»—i sá»‘ float64 = 8 bytes
- 179M rows Ã— 9 features Ã— 8 bytes â‰ˆ 12GB + overhead â‰ˆ 33GB

##### ~~BÆ¯á»šC 3: Khá»i táº¡o tÃ¢m cá»¥m~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: Loáº¡i bá» - MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++** khá»Ÿi táº¡o thÃ´ng minh.

---

##### BÆ¯á»šC 3: Upload lÃªn HDFS â˜ï¸

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u lÃªn há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n  
**File thá»±c thi**: `scripts/spark/setup_hdfs.sh`  
**Thá»i gian**: ~5 phÃºt  
**Input**: 1 file temp cá»¥c bá»™ (hadoop_input_temp.txt)  
**Output**: Dá»¯ liá»‡u trÃªn HDFS

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n**:
1. Kiá»ƒm tra HDFS Ä‘ang cháº¡y: `hdfs dfsadmin -report`
2. Táº¡o thÆ° má»¥c: `hdfs dfs -mkdir -p /user/spark/hi_large/input`
3. Upload input: `hdfs dfs -put hadoop_input_temp.txt /user/.../input/`
4. **XÃ“A file temp cá»¥c bá»™**: `rm -rf data/processed/*`
5. Verify: Kiá»ƒm tra kÃ­ch thÆ°á»›c file trÃªn HDFS

**ğŸ”’ TuÃ¢n thá»§ quy Ä‘á»‹nh**:
- Sau bÆ°á»›c nÃ y, KHÃ”NG cÃ²n dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
- Chá»‰ tá»“n táº¡i trÃªn HDFS (phÃ¢n tÃ¡n, an toÃ n)
- Náº¿u cáº§n, cÃ³ thá»ƒ táº£i láº¡i tá»« HDFS

##### BÆ¯á»šC 4: Cháº¡y K-means trÃªn Spark ğŸš€

**Má»¥c Ä‘Ã­ch**: PhÃ¢n cá»¥m 179 triá»‡u giao dá»‹ch báº±ng **MLlib K-means**  
**File thá»±c thi**: `scripts/spark/run_spark.sh` + `kmeans_spark.py`  
**Thá»i gian**: 10-25 phÃºt (nhanh hÆ¡n 30-50% nhá» MLlib!)  
**Input**: Dá»¯ liá»‡u tá»« HDFS  
**Output**: TÃ¢m cá»¥m cuá»‘i cÃ¹ng trÃªn HDFS

**MLlib K-means vá»›i k-means++ initialization**:
```
KHá» Táº O (Tá»° Äá»˜NG bá»Ÿi MLlib):
  - K=5 tÃ¢m cá»¥m
  - Sá»­ dá»¥ng k-means++ (thÃ´ng minh, khÃ´ng random)
  - Max iterations = 15
  - Tá»‘i Æ°u Catalyst + Tungsten engine

Láº¶P Láº I 15 Láº¦N:
  1. GÃ¡n má»—i giao dá»‹ch vÃ o cá»¥m gáº§n nháº¥t
     - TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n 5 tÃ¢m cá»¥m
     - Chá»n cá»¥m cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t
  
  2. Cáº­p nháº­t tÃ¢m cá»¥m
     - TÃ­nh trung bÃ¬nh táº¥t cáº£ Ä‘iá»ƒm trong má»—i cá»¥m
     - TÃ¢m cá»¥m má»›i = trung bÃ¬nh cÃ¡c Ä‘iá»ƒm
  
  3. Kiá»ƒm tra há»™i tá»¥
     - TÃ­nh Ä‘á»™ dá»‹ch chuyá»ƒn tÃ¢m cá»¥m
     - Náº¿u < threshold â†’ Dá»«ng láº¡i

Káº¾T QUáº¢:
  - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng (tá»‘t hÆ¡n random init)
  - Má»—i cá»¥m chá»©a bao nhiÃªu Ä‘iá»ƒm
  - Há»™i tá»¥ nhanh hÆ¡n (~10-12 iterations thay vÃ¬ 15)
```

**QuÃ¡ trÃ¬nh há»™i tá»¥ (tá»« log thá»±c táº¿)**:
```
Iteration  1: Centroid shift = 2.232  (chÆ°a á»•n Ä‘á»‹nh)
Iteration  2: Centroid shift = 1.409
Iteration  5: Centroid shift = 0.383
Iteration 10: Centroid shift = 0.046
Iteration 15: Centroid shift = 0.010  (Ä‘Ã£ há»™i tá»¥ âœ“)
```

**PhÃ¢n phá»‘i káº¿t quáº£**:
```
Cluster 0:  40,034,828 giao dá»‹ch (22.28%)
Cluster 1:  42,665,741 giao dá»‹ch (23.74%)
Cluster 2:  24,884,738 giao dá»‹ch (13.85%)
Cluster 3:  50,933,660 giao dá»‹ch (28.34%)  â† Lá»›n nháº¥t
Cluster 4:  21,183,262 giao dá»‹ch (11.79%)
```

##### BÆ¯á»šC 5: Táº£i káº¿t quáº£ vá» ğŸ“¥

**Má»¥c Ä‘Ã­ch**: Láº¥y tÃ¢m cá»¥m cuá»‘i cÃ¹ng tá»« HDFS  
**File thá»±c thi**: `scripts/spark/download_from_hdfs.sh`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `/user/spark/hi_large/output_centroids/` trÃªn HDFS  
**Output**: `data/results/final_centroids.txt` (~4KB)

**CÃ¡c bÆ°á»›c**:
1. `hdfs dfs -cat /user/.../output_centroids/part-*`
2. LÆ°u vÃ o file cá»¥c bá»™
3. Verify: Kiá»ƒm tra cÃ³ Ä‘Ãºng 5 dÃ²ng

**Táº¡i sao Ä‘Æ°á»£c phÃ©p táº£i vá»?**
- File ráº¥t nhá» (~4KB)
- Chá»‰ chá»©a káº¿t quáº£ tá»•ng há»£p, khÃ´ng pháº£i dá»¯ liá»‡u gá»‘c
- Cáº§n thiáº¿t cho bÆ°á»›c phÃ¢n tÃ­ch tiáº¿p theo

##### BÆ¯á»šC 6: GÃ¡n nhÃ£n cá»¥m cho tá»«ng giao dá»‹ch ğŸ·ï¸

**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh má»—i giao dá»‹ch thuá»™c cá»¥m nÃ o  
**File thá»±c thi**: `scripts/polars/assign_clusters_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: 
  - CSV gá»‘c tá»« HDFS (streaming)
  - 5 tÃ¢m cá»¥m tá»« bÆ°á»›c 5  
**Output**: `data/results/clustered_results.txt`

**Thuáº­t toÃ¡n**:
```python
FOR má»—i giao dá»‹ch:
    distances = []
    FOR má»—i tÃ¢m cá»¥m (5 cá»¥m):
        d = euclidean_distance(giao_dá»‹ch, tÃ¢m_cá»¥m)
        distances.append(d)
    
    cluster_id = argmin(distances)  # Chá»n cá»¥m gáº§n nháº¥t
    ghi_káº¿t_quáº£(giao_dá»‹ch, cluster_id)
```

**Xá»­ lÃ½ batch Ä‘á»ƒ tÄƒng tá»‘c**:
- KhÃ´ng xá»­ lÃ½ tá»«ng giao dá»‹ch
- Xá»­ lÃ½ 1 triá»‡u giao dá»‹ch cÃ¹ng lÃºc
- Sá»­ dá»¥ng NumPy vectorization

##### BÆ¯á»šC 7: PhÃ¢n tÃ­ch káº¿t quáº£ ğŸ“Š

**Má»¥c Ä‘Ã­ch**: TÃ¬m cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao  
**File thá»±c thi**: `scripts/polars/analyze_polars.py`  
**Thá»i gian**: ~2 phÃºt  
**Input**: `data/results/clustered_results.txt`  
**Output**: BÃ¡o cÃ¡o phÃ¢n tÃ­ch

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. **KÃ­ch thÆ°á»›c cá»¥m**: Má»—i cá»¥m cÃ³ bao nhiÃªu giao dá»‹ch?
2. **Tá»· lá»‡ rá»­a tiá»n**: % rá»­a tiá»n trong tá»«ng cá»¥m
3. **High-risk clusters**: Cá»¥m nÃ o > 10% rá»­a tiá»n?
4. **Feature averages**: Äáº·c Ä‘iá»ƒm trung bÃ¬nh má»—i cá»¥m

**Káº¿t quáº£ tá»« log thá»±c táº¿**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ Giao dá»‹ch   â•‘ Rá»­a tiá»n  â•‘ Tá»· lá»‡ (%)       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 40,034,832  â•‘  52,327   â•‘ 0.13%           â•‘
â•‘    1     â•‘ 42,665,746  â•‘  70,450   â•‘ 0.17% â† CAO     â•‘
â•‘    2     â•‘ 24,884,738  â•‘  16,686   â•‘ 0.07%           â•‘
â•‘    3     â•‘ 50,933,651  â•‘  82,943   â•‘ 0.16%           â•‘
â•‘    4     â•‘ 21,183,262  â•‘   3,140   â•‘ 0.01% â† THáº¤P    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ NHáº¬N XÃ‰T:
- Cluster 1 nghi ngá» nháº¥t (0.17%, cao hÆ¡n trung bÃ¬nh)
- Cluster 4 an toÃ n nháº¥t (0.01%, tháº¥p hÆ¡n nhiá»u)
- KHÃ”NG cÃ³ cá»¥m nÃ o > 10% (good sign)
```

---


