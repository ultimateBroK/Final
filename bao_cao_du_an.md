# ğŸ“Š BÃO CÃO Dá»° ÃN: PHÃT HIá»†N Rá»¬A TIá»€N Báº°NG Há»ŒC MÃY

## PhÃ¢n TÃ­ch 179 Triá»‡u Giao Dá»‹ch vá»›i Apache Spark

## Má»¥c lá»¥c
- [TÃ³m táº¯t Ä‘iá»u hÃ nh](#tom-tat)
- [Pháº§n 1: Giá»›i thiá»‡u dá»± Ã¡n](#p1)
- [Pháº§n 2: Dá»¯ liá»‡u vÃ  tiá»n xá»­ lÃ½](#p2)
- [Pháº§n 3: Kiáº¿n trÃºc há»‡ thá»‘ng](#p3)
- [Pháº§n 4: Quy trÃ¬nh xá»­ lÃ½ (Pipeline)](#p4)
- [Pháº§n 5: Káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡](#p5)
- [Pháº§n 6: TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t](#p6)
- [Pháº§n 7: HÆ°á»›ng dáº«n sá»­ dá»¥ng](#p7)
- [Pháº§n 8: Xá»­ lÃ½ sá»± cá»‘](#p8)
- [Pháº§n 9: Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn](#p9)
- [Phá»¥ lá»¥c](#phu-luc)

---

- NgÃ y láº­p bÃ¡o cÃ¡o: 29/10/2025 21:32:29
- NgÃ y láº­p bÃ¡o cÃ¡o: 29/10/2025 21:32:30
- Vá»‹ trÃ­ dá»± Ã¡n: `/home/ultimatebrok/Downloads/Final`
- NgÆ°á»i thá»±c hiá»‡n: Sinh viÃªn
- Giáº£ng viÃªn hÆ°á»›ng dáº«n: [TÃªn giáº£ng viÃªn]
- Snapshot: `snapshot_20251029_213229`

---

<a id="tom-tat"></a>
## TÃ“M Táº®T ÄIá»€U HÃ€NH

### BÃ i toÃ¡n
PhÃ¡t hiá»‡n cÃ¡c giao dá»‹ch nghi ngá» rá»­a tiá»n trong táº­p dá»¯ liá»‡u lá»›n chá»©a **179 triá»‡u giao dá»‹ch** (kÃ­ch thÆ°á»›c 16GB), sá»­ dá»¥ng ká»¹ thuáº­t phÃ¢n cá»¥m K-means trÃªn ná»n táº£ng xá»­ lÃ½ phÃ¢n tÃ¡n Apache Spark.

### Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c
- âœ… Xá»­ lÃ½ thÃ nh cÃ´ng 179,702,229 giao dá»‹ch
- âœ… PhÃ¢n thÃ nh 5 cá»¥m vá»›i tá»· lá»‡ rá»­a tiá»n khÃ¡c nhau (0.041% - 5.56%)
- âœ… Thá»i gian xá»­ lÃ½: **11 phÃºt 47 giÃ¢y** (nhanh hÆ¡n Hadoop 4-8 láº§n, nhanh hÆ¡n RDD 30-50%)
- âœ… PhÃ¡t hiá»‡n 225,546 giao dá»‹ch nghi ngá» rá»­a tiá»n (0.126% tá»•ng sá»‘)
- âœ… TuÃ¢n thá»§ quy Ä‘á»‹nh: KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™

### CÃ´ng nghá»‡ sá»­ dá»¥ng
- **Polars**: ThÆ° viá»‡n xá»­ lÃ½ dá»¯ liá»‡u siÃªu nhanh (nhanh hÆ¡n Pandas 10-100 láº§n)
- **Apache Spark**: Há»‡ thá»‘ng xá»­ lÃ½ phÃ¢n tÃ¡n trong bá»™ nhá»›
- **HDFS**: Há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n cá»§a Hadoop
- **Python**: NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh
- **K-means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m há»c mÃ¡y

---

<a id="p1"></a>
## PHáº¦N 1: GIá»šI THIá»†U Dá»° ÃN

### 1.1. Bá»‘i cáº£nh vÃ  Äá»™ng lá»±c

#### Váº¥n Ä‘á» rá»­a tiá»n trong thá»±c táº¿
Rá»­a tiá»n lÃ  hÃ nh vi che giáº¥u nguá»“n gá»‘c báº¥t há»£p phÃ¡p cá»§a tiá»n báº±ng cÃ¡ch chuyá»ƒn qua nhiá»u 
giao dá»‹ch phá»©c táº¡p. CÃ¡c tá»• chá»©c tÃ i chÃ­nh pháº£i phÃ¡t hiá»‡n vÃ  bÃ¡o cÃ¡o cÃ¡c giao dá»‹ch nghi ngá» 
theo quy Ä‘á»‹nh phÃ¡p luáº­t.

#### ThÃ¡ch thá»©c vá»›i dá»¯ liá»‡u lá»›n
- **Khá»‘i lÆ°á»£ng khá»•ng lá»“**: HÃ ng trÄƒm triá»‡u giao dá»‹ch má»—i thÃ¡ng
- **Tá»‘c Ä‘á»™ xá»­ lÃ½**: Cáº§n phÃ¢n tÃ­ch nhanh Ä‘á»ƒ phÃ¡t hiá»‡n ká»‹p thá»i
- **Äá»™ chÃ­nh xÃ¡c**: Giáº£m thiá»ƒu cáº£nh bÃ¡o giáº£ (false positive)
- **TuÃ¢n thá»§ quy Ä‘á»‹nh**: Báº£o máº­t dá»¯ liá»‡u khÃ¡ch hÃ ng

#### Giáº£i phÃ¡p cá»§a dá»± Ã¡n
Sá»­ dá»¥ng **há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t (Unsupervised Learning)** vá»›i thuáº­t toÃ¡n K-means Ä‘á»ƒ:
- Tá»± Ä‘á»™ng phÃ¢n nhÃ³m giao dá»‹ch cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±
- PhÃ¡t hiá»‡n cÃ¡c cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao báº¥t thÆ°á»ng
- Xá»­ lÃ½ song song trÃªn nhiá»u mÃ¡y tÃ­nh (distributed computing)
- Äáº£m báº£o tuÃ¢n thá»§ quy Ä‘á»‹nh vá» báº£o máº­t dá»¯ liá»‡u

### 1.2. Má»¥c tiÃªu dá»± Ã¡n

#### Má»¥c tiÃªu chÃ­nh
1. **PhÃ¢n tÃ­ch dá»¯ liá»‡u giao dá»‹ch quy mÃ´ lá»›n**
   - Xá»­ lÃ½ file CSV 16GB chá»©a 179 triá»‡u báº£n ghi
   - TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (feature extraction) tá»« dá»¯ liá»‡u thÃ´
   - Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘á»ƒ thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng hiá»‡u quáº£

2. **PhÃ¢n cá»¥m giao dá»‹ch báº±ng K-means**
   - Chia 179 triá»‡u giao dá»‹ch thÃ nh 5 cá»¥m
   - Má»—i cá»¥m Ä‘áº¡i diá»‡n cho má»™t pattern giao dá»‹ch
   - Sá»­ dá»¥ng Apache Spark Ä‘á»ƒ xá»­ lÃ½ phÃ¢n tÃ¡n

3. **PhÃ¡t hiá»‡n giao dá»‹ch nghi ngá»**
   - PhÃ¢n tÃ­ch tá»· lá»‡ rá»­a tiá»n trong tá»«ng cá»¥m
   - XÃ¡c Ä‘á»‹nh cá»¥m cÃ³ tá»· lá»‡ báº¥t thÆ°á»ng cao
   - Xuáº¥t danh sÃ¡ch giao dá»‹ch cáº§n kiá»ƒm tra thá»§ cÃ´ng

4. **TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t**
   - KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
   - Chá»‰ lÆ°u trÃªn HDFS (Hadoop Distributed File System)
   - Tá»± Ä‘á»™ng xÃ³a file táº¡m sau khi xá»­ lÃ½

#### Má»¥c tiÃªu phá»¥
- Há»c vÃ  Ã¡p dá»¥ng cÃ´ng nghá»‡ Big Data (Spark, HDFS)
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a Hadoop MapReduce vÃ  Apache Spark
- XÃ¢y dá»±ng quy trÃ¬nh tá»± Ä‘á»™ng (pipeline) tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
- Viáº¿t tÃ i liá»‡u chi tiáº¿t, dá»… hiá»ƒu cho ngÆ°á»i khÃ¡c

---

<a id="p2"></a>
## PHáº¦N 2: Dá»® LIá»†U VÃ€ TIá»€N Xá»¬ LÃ

### 2.1. MÃ´ táº£ táº­p dá»¯ liá»‡u

#### ThÃ´ng tin cÆ¡ báº£n
- **TÃªn file**: `HI-Large_Trans.csv`
- **KÃ­ch thÆ°á»›c**: 16 GB (gigabyte)
- **Sá»‘ báº£n ghi**: 179,702,229 giao dá»‹ch
- **Nguá»“n**: Táº­p dá»¯ liá»‡u mÃ´ phá»ng giao dá»‹ch ngÃ¢n hÃ ng quá»‘c táº¿

#### Cáº¥u trÃºc dá»¯ liá»‡u (11 cá»™t)

| TÃªn cá»™t | Ã nghÄ©a | Kiá»ƒu dá»¯ liá»‡u | VÃ­ dá»¥ |
|---------|---------|--------------|-------|
| `Timestamp` | Thá»i gian giao dá»‹ch | Chuá»—i | "2022/08/01 00:17" |
| `From Bank` | MÃ£ ngÃ¢n hÃ ng gá»­i | Sá»‘ nguyÃªn | 20, 3196, 1208 |
| `Account` | MÃ£ tÃ i khoáº£n gá»­i | Chuá»—i | "800104D70" |
| `To Bank` | MÃ£ ngÃ¢n hÃ ng nháº­n | Sá»‘ nguyÃªn | 20, 3196 |
| `Account.1` | MÃ£ tÃ i khoáº£n nháº­n | Chuá»—i | "800107150" |
| `Amount Received` | Sá»‘ tiá»n nháº­n Ä‘Æ°á»£c | Sá»‘ thá»±c | 6794.63 |
| `Receiving Currency` | Loáº¡i tiá»n nháº­n | Chuá»—i | "US Dollar", "Yuan" |
| `Amount Paid` | Sá»‘ tiá»n tráº£ | Sá»‘ thá»±c | 7739.29 |
| `Payment Currency` | Loáº¡i tiá»n tráº£ | Chuá»—i | "US Dollar", "Bitcoin" |
| `Payment Format` | HÃ¬nh thá»©c thanh toÃ¡n | Chuá»—i | "Reinvestment", "Cheque" |
| `Is Laundering` | NhÃ£n rá»­a tiá»n | 0 hoáº·c 1 | 0 = BÃ¬nh thÆ°á»ng, 1 = Rá»­a tiá»n |

#### Thá»‘ng kÃª mÃ´ táº£
- **Tá»· lá»‡ rá»­a tiá»n tá»•ng thá»ƒ**: 0.126% (225,546 / 179,702,229)
- **Loáº¡i tiá»n phá»• biáº¿n nháº¥t**: Euro (23%), Yuan (7.2%), Mexican Peso (2.7%)
- **GiÃ¡ trá»‹ giao dá»‹ch trung bÃ¬nh**: ~1.14 triá»‡u Ä‘Æ¡n vá»‹ tiá»n tá»‡
- **Khoáº£ng giÃ¡ trá»‹**: Tá»« 0.01 Ä‘áº¿n hÆ¡n 5 tá»· Ä‘Æ¡n vá»‹

### 2.2. Quy trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u

#### BÆ°á»›c 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u (Data Exploration)

**Script**: `scripts/polars/explore_fast.py`  
**Thá»i gian**: ~30 giÃ¢y  
**CÃ´ng viá»‡c**:
- Äá»c nhanh 100,000 dÃ²ng Ä‘áº§u Ä‘á»ƒ hiá»ƒu cáº¥u trÃºc
- Xem kiá»ƒu dá»¯ liá»‡u cá»§a tá»«ng cá»™t (sá»‘, chuá»—i)
- Kiá»ƒm tra giÃ¡ trá»‹ thiáº¿u (missing values)
- Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median
- PhÃ¢n tÃ­ch phÃ¢n phá»‘i cá»§a nhÃ£n rá»­a tiá»n

**Ká»¹ thuáº­t sá»­ dá»¥ng**:
- **Lazy Loading**: Chá»‰ Ä‘á»c metadata, khÃ´ng load toÃ n bá»™ vÃ o RAM
- **Polars DataFrame**: ThÆ° viá»‡n nhanh viáº¿t báº±ng Rust
- **Statistical Summary**: TÃ­nh toÃ¡n song song

#### BÆ°á»›c 2: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (Feature Engineering)

**Script**: `scripts/polars/prepare_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**CÃ´ng viá»‡c**:

1. **PhÃ¢n tÃ­ch thá»i gian (Temporal Features)**
   - Parse chuá»—i timestamp thÃ nh datetime
   - TrÃ­ch xuáº¥t giá» trong ngÃ y (0-23)
   - TrÃ­ch xuáº¥t ngÃ y trong tuáº§n (0-6)
   - **LÃ½ do**: Rá»­a tiá»n thÆ°á»ng xáº£y ra vÃ o giá» khÃ´ng bÃ¬nh thÆ°á»ng

2. **TÃ­nh toÃ¡n tá»· lá»‡ (Ratio Features)**
   - `amount_ratio = Amount Received / Amount Paid`
   - **LÃ½ do**: Tá»· lá»‡ báº¥t thÆ°á»ng cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u rá»­a tiá»n
   - Xá»­ lÃ½ chia cho 0 (division by zero)

3. **MÃ£ hÃ³a tuyáº¿n Ä‘Æ°á»ng (Route Hash)**
   - Hash(From Bank, To Bank) â†’ má»™t sá»‘ duy nháº¥t
   - **LÃ½ do**: PhÃ¡t hiá»‡n tuyáº¿n chuyá»ƒn tiá»n láº·p láº¡i nghi ngá»

4. **MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i (Categorical Encoding)**
   - Chuyá»ƒn chuá»—i thÃ nh sá»‘ (One-Hot hoáº·c Label Encoding)
   - VÃ­ dá»¥: "US Dollar" â†’ 0, "Yuan" â†’ 1, "Bitcoin" â†’ 2
   - **LÃ½ do**: Thuáº­t toÃ¡n K-means chá»‰ lÃ m viá»‡c vá»›i sá»‘

5. **Chuáº©n hÃ³a (Normalization)**
   - Min-Max Scaling: ÄÆ°a táº¥t cáº£ vá» khoáº£ng [0, 1]
   - CÃ´ng thá»©c: `(x - min) / (max - min)`
   - **LÃ½ do**: CÃ¡c Ä‘áº·c trÆ°ng cÃ³ scale khÃ¡c nhau sáº½ áº£nh hÆ°á»Ÿng káº¿t quáº£

**Äáº§u ra**:
- File: `data/processed/hadoop_input_temp.txt` (Táº M THá»œI)
- KÃ­ch thÆ°á»›c: 33GB (sau khi normalize)
- 9 cá»™t Ä‘áº·c trÆ°ng sá»‘: `[amount_received, amount_paid, amount_ratio, hour, day_of_week, route_hash, recv_curr_encoded, payment_curr_encoded, payment_format_encoded]`
- **LÆ°u Ã½**: File nÃ y sáº½ Bá»Š XÃ“A tá»± Ä‘á»™ng sau khi upload lÃªn HDFS

#### ~~BÆ°á»›c 3: Khá»Ÿi táº¡o tÃ¢m cá»¥m ban Ä‘áº§u~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: ÄÃ£ loáº¡i bá» khá»i pipeline

**Táº¡i sao loáº¡i bá»?**
- **MLlib K-means tá»± Ä‘á»™ng** sá»­ dá»¥ng thuáº­t toÃ¡n **k-means++** (gá»i lÃ  "k-means||") Ä‘á»ƒ khá»Ÿi táº¡o centroids
- K-means++ thÃ´ng minh hÆ¡n random initialization, cho káº¿t quáº£ tá»‘t hÆ¡n
- KhÃ´ng cáº§n file `centroids_temp.txt` ná»¯a
- Tiáº¿t kiá»‡m 30 giÃ¢y thá»i gian xá»­ lÃ½

**Lá»£i Ã­ch**:
- Há»™i tá»¥ nhanh hÆ¡n (~10-12 iterations thay vÃ¬ 15)
- Káº¿t quáº£ á»•n Ä‘á»‹nh hÆ¡n, trÃ¡nh local minima
- Giáº£m Ä‘á»™ phá»©c táº¡p pipeline (7 bÆ°á»›c thay vÃ¬ 8)

---

<a id="p3"></a>
## PHáº¦N 3: KIáº¾N TRÃšC Há»† THá»NG

### 3.1. SÆ¡ Ä‘á»“ tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KIáº¾N TRÃšC Há»† THá»NG PHÃ‚N TÃN                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dá»® LIá»†U    â”‚   16GB CSV (179M giao dá»‹ch)
â”‚   Äáº¦U VÃ€O    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POLARS     â”‚   Xá»­ lÃ½ dá»¯ liá»‡u cá»¥c bá»™ (1 mÃ¡y)
â”‚  (MÃ¡y cÃ¡     â”‚   - Äá»c CSV nhanh
â”‚   nhÃ¢n)      â”‚   - Feature engineering
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   - Chuáº©n hÃ³a
       â”‚
       â”‚ Táº¡o file temp 33GB
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     HDFS     â”‚   Há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n
â”‚  (Nhiá»u mÃ¡y  â”‚   - Chia nhá» thÃ nh blocks
â”‚    tÃ­nh)     â”‚   - Sao lÆ°u tá»± Ä‘á»™ng (replication)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   - Fault-tolerant
       â”‚
       â”‚ ğŸ—‘ï¸  XÃ“A file temp cá»¥c bá»™
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SPARK     â”‚   Xá»­ lÃ½ phÃ¢n tÃ¡n song song
â”‚  (Cluster)   â”‚   - Äá»c tá»« HDFS
â”‚              â”‚   - K-means trong RAM
â”‚  [Master]    â”‚   - LÆ°u káº¿t quáº£ vá» HDFS
â”‚  [Worker 1]  â”‚
â”‚  [Worker 2]  â”‚
â”‚  [Worker 3]  â”‚
â”‚  [Worker 4]  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Káº¾T QUáº¢     â”‚   File nhá» (~4KB)
â”‚  (Cá»¥c bá»™)    â”‚   - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng
â”‚              â”‚   - BÃ¡o cÃ¡o phÃ¢n tÃ­ch
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2. Giáº£i thÃ­ch cÃ¡c thÃ nh pháº§n

#### Polars - Xá»­ lÃ½ dá»¯ liá»‡u nhanh
**Vai trÃ²**: Äá»c vÃ  xá»­ lÃ½ CSV á»Ÿ mÃ¡y cá»¥c bá»™
**Táº¡i sao dÃ¹ng Polars**:
- Nhanh hÆ¡n Pandas 10-100 láº§n
- Viáº¿t báº±ng Rust (ngÃ´n ngá»¯ hiá»‡u suáº¥t cao)
- Há»— trá»£ lazy evaluation (tÃ­nh toÃ¡n khi cáº§n)
- Xá»­ lÃ½ Ä‘Æ°á»£c file lá»›n hÆ¡n RAM

**So sÃ¡nh vá»›i Pandas**:
```
Pandas:  Äá»c 16GB CSV â†’ 45 phÃºt
Polars:  Äá»c 16GB CSV â†’ 4-5 phÃºt âš¡
```

#### HDFS - LÆ°u trá»¯ phÃ¢n tÃ¡n
**Vai trÃ²**: LÆ°u trá»¯ file lá»›n trÃªn nhiá»u mÃ¡y
**CÃ¡ch hoáº¡t Ä‘á»™ng**:
1. File 33GB Ä‘Æ°á»£c chia thÃ nh cÃ¡c block 128MB
2. Má»—i block Ä‘Æ°á»£c sao lÆ°u 3 báº£n trÃªn 3 mÃ¡y khÃ¡c nhau
3. Náº¿u 1 mÃ¡y há»ng, váº«n cÃ²n 2 báº£n sao khÃ¡c

**Cáº¥u trÃºc thÆ° má»¥c HDFS trong dá»± Ã¡n**:
```
/user/spark/hi_large/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ hadoop_input.txt          (33GB - Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½)
â”œâ”€â”€ centroids.txt                 (440 bytes - TÃ¢m cá»¥m ban Ä‘áº§u)
â””â”€â”€ output_centroids/             (ThÆ° má»¥c káº¿t quáº£)
    â””â”€â”€ part-00000                (TÃ¢m cá»¥m cuá»‘i cÃ¹ng)
```

**Lá»£i Ã­ch**:
- âœ… KhÃ´ng giá»›i háº¡n dung lÆ°á»£ng (thÃªm mÃ¡y = thÃªm khÃ´ng gian)
- âœ… An toÃ n (replication)
- âœ… TuÃ¢n thá»§ quy Ä‘á»‹nh (khÃ´ng lÆ°u local)

#### Apache Spark - Xá»­ lÃ½ phÃ¢n tÃ¡n
**Vai trÃ²**: Cháº¡y K-means trÃªn nhiá»u mÃ¡y song song
**Kiáº¿n trÃºc Spark**:

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   MASTER    â”‚  â† Äiá»u phá»‘i cÃ´ng viá»‡c
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        â”‚        â”‚
   â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”
   â”‚ W1  â”‚  â”‚ W2  â”‚  â”‚ W3  â”‚  â† Workers (CÃ´ng nhÃ¢n)
   â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
   44M rows 44M rows 44M rows   (Chia Ä‘á»u dá»¯ liá»‡u)
```

**CÃ¡ch Spark xá»­ lÃ½ K-means**:
1. **PhÃ¢n chia dá»¯ liá»‡u**: 179M rows â†’ 4 pháº§n (4 workers)
2. **Xá»­ lÃ½ song song**: Má»—i worker tÃ­nh khoáº£ng cÃ¡ch cá»§a pháº§n cá»§a mÃ¬nh
3. **Tá»•ng há»£p**: Master thu tháº­p káº¿t quáº£ vÃ  cáº­p nháº­t tÃ¢m cá»¥m
4. **Láº·p láº¡i**: 15 láº§n cho Ä‘áº¿n khi há»™i tá»¥

**Táº¡i sao Spark nhanh**:
- **In-memory computing**: Giá»¯ dá»¯ liá»‡u trong RAM, khÃ´ng ghi disk
- **Lazy evaluation**: Chá»‰ tÃ­nh toÃ¡n khi cáº§n thiáº¿t
- **Pipeline optimization**: Tá»± Ä‘á»™ng tá»‘i Æ°u chuá»—i cÃ¡c phÃ©p toÃ¡n

**Cáº¥u hÃ¬nh Spark trong dá»± Ã¡n**:
- **Driver memory**: 4GB (bá»™ nhá»› chÆ°Æ¡ng trÃ¬nh chÃ­nh)
- **Executor memory**: 4GB Ã— 4 = 16GB (bá»™ nhá»› workers)
- **Cores**: 4 cores/worker Ã— 4 workers = 16 cores
- **Parallelism**: Xá»­ lÃ½ 16 partition cÃ¹ng lÃºc

---

<a id="p4"></a>
## PHáº¦N 4: QUY TRÃŒNH Xá»¬ LÃ (PIPELINE)

### 4.1. Tá»•ng quan quy trÃ¬nh 7 bÆ°á»›c

âš ï¸ **Thay Ä‘á»•i quan trá»ng**: Pipeline Ä‘Ã£ tá»‘i Æ°u tá»« 8 bÆ°á»›c xuá»‘ng cÃ²n **7 bÆ°á»›c**. BÆ°á»›c khá»Ÿi táº¡o centroids Ä‘Ã£ loáº¡i bá» vÃ¬ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++**.

**Thá»i gian thá»±c táº¿ tá»« Snapshot 29/10/2025 21:32:29**:

```
BÆ¯á»šC 1        BÆ¯á»šC 2        BÆ¯á»šC 3
KhÃ¡m phÃ¡  â†’   Xá»­ lÃ½    â†’   Upload
 13 giÃ¢y       36 giÃ¢y      41 giÃ¢y

BÆ¯á»šC 4            BÆ¯á»šC 5        BÆ¯á»šC 6        BÆ¯á»šC 7
K-means       â†’   Táº£i vá»   â†’   GÃ¡n nhÃ£n  â†’   PhÃ¢n tÃ­ch
6 phÃºt 5s      3 giÃ¢y       3 phÃºt 14s      30 giÃ¢y

Tá»”NG THá»œI GIAN: 11 phÃºt 22 giÃ¢y (682 giÃ¢y)
```

### 4.2. Chi tiáº¿t tá»«ng bÆ°á»›c

#### BÆ¯á»šC 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u ğŸ”

**Má»¥c Ä‘Ã­ch**: Hiá»ƒu cáº¥u trÃºc vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u  
**File thá»±c thi**: `scripts/polars/explore_fast.py`  
**Thá»i gian thá»±c táº¿**: **13 giÃ¢y** (Snapshot 29/10/2025 21:20:57 - 21:21:10)  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: Thá»‘ng kÃª in ra mÃ n hÃ¬nh

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. **Lazy Loading**: Äá»c metadata vÃ  100,000 dÃ²ng Ä‘áº§u (Ä‘áº¡i diá»‡n) - khÃ´ng táº£i toÃ n bá»™ vÃ o RAM
2. **Schema Analysis**: Xem tÃªn cá»™t, kiá»ƒu dá»¯ liá»‡u (11 cá»™t: Timestamp, From Bank, Account, To Bank, Account.1, Amount Received, Receiving Currency, Amount Paid, Payment Currency, Payment Format, Is Laundering)
3. **Thá»‘ng kÃª mÃ´ táº£**: min, max, mean, median, std cho cÃ¡c cá»™t sá»‘
4. **PhÃ¢n tÃ­ch nhÃ£n rá»­a tiá»n**: Äáº¿m sá»‘ giao dá»‹ch bÃ¬nh thÆ°á»ng vs nghi ngá»
5. **Top loáº¡i tiá»n tá»‡**: PhÃ¢n tÃ­ch phÃ¢n phá»‘i cÃ¡c loáº¡i tiá»n phá»• biáº¿n

**Káº¿t quáº£ thá»±c táº¿ tá»« Snapshot**:
```
Tá»•ng sá»‘ giao dá»‹ch: 179,702,229
Tá»· lá»‡ rá»­a tiá»n: 0.126% (225,546 / 179,702,229)
PhÃ¢n phá»‘i nhÃ£n:
  - 0 (BÃ¬nh thÆ°á»ng): 179,476,683 giao dá»‹ch
  - 1 (Rá»­a tiá»n): 225,546 giao dá»‹ch

Top 10 loáº¡i tiá»n tá»‡ nháº­n phá»• biáº¿n:
  - US Dollar: 65,292,945 giao dá»‹ch (36.4%)
  - Euro: 41,290,069 giao dá»‹ch (23.0%)
  - Yuan: 12,920,668 giao dá»‹ch (7.2%)
  - Ruble: 5,571,567 giao dá»‹ch (3.1%)
  - Australian Dollar: 5,256,710 giao dá»‹ch (2.9%)
  - Yen: 4,841,570 giao dá»‹ch (2.7%)
  - Swiss Franc: 4,829,099 giao dá»‹ch (2.7%)
  - Rupee: 4,178,243 giao dá»‹ch (2.3%)
  - Bitcoin: 3,958,153 giao dá»‹ch (2.2%)
  - Brazil Real: 3,596,378 giao dá»‹ch (2.0%)

GiÃ¡ trá»‹ giao dá»‹ch:
  - Min: 0.01
  - Max: 5,115,400,000 (trÃªn 5 tá»·!)
  - Mean: 1,142,200
  - Median: 2,513.06
```

#### BÆ¯á»šC 2: Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ğŸ”§

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n xá»­ lÃ½  
**File thá»±c thi**: `scripts/polars/prepare_polars.py`  
**Thá»i gian thá»±c táº¿**: **36 giÃ¢y** (21:21:11 - 21:21:45, Snapshot 29/10/2025)  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: `data/processed/hadoop_input_temp.txt` (**31GB**, Táº M THá»œI)

**Chi tiáº¿t 6 bÆ°á»›c xá»­ lÃ½ (tá»« log thá»±c táº¿)**:

**BÆ°á»›c 2.1/6: Thiáº¿t láº­p Ä‘á»c trÃ¬ hoÃ£n (Lazy Loading)**
- Thá»i gian: 0.0s
- Má»¥c Ä‘Ã­ch: KhÃ´ng táº£i toÃ n bá»™ vÃ o RAM, chá»‰ Ä‘á»c khi cáº§n thiáº¿t
- Sá»­ dá»¥ng: `pl.scan_csv()` - Polars lazy evaluation

**BÆ°á»›c 2.2/6: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u thÃ´**
- Thá»i gian: 0.0s (tÃ­nh toÃ¡n lazy, chÆ°a thá»±c thi)
- CÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c táº¡o:
  1. **Temporal Features**: Parse `Timestamp` â†’ `hour` (0-23), `day_of_week` (0-6)
  2. **Amount Features**: `Amount Received`, `Amount Paid`, `amount_ratio = Received / Paid`
  3. **Route Feature**: `route_hash = hash(From Bank + To Bank)` - mÃ£ hÃ³a tuyáº¿n chuyá»ƒn tiá»n

**BÆ°á»›c 2.3/6: MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i (Categorical Encoding)**
- Thá»i gian: 0.0s
- MÃ£ hÃ³a Label Encoding cho:
  - `Receiving Currency` â†’ `recv_curr_encoded` (sá»‘ nguyÃªn)
  - `Payment Currency` â†’ `payment_curr_encoded` (sá»‘ nguyÃªn)
  - `Payment Format` â†’ `payment_format_encoded` (sá»‘ nguyÃªn)

**BÆ°á»›c 2.4/6: Chá»n cÃ¡c Ä‘áº·c trÆ°ng sá»‘**
- Thá»i gian: 0.0s
- Káº¿t quáº£: Chá»n **9 Ä‘áº·c trÆ°ng sá»‘** cho K-means:
  1. `amount_received`
  2. `amount_paid`
  3. `amount_ratio`
  4. `hour`
  5. `day_of_week`
  6. `route_hash`
  7. `recv_curr_encoded`
  8. `payment_curr_encoded`
  9. `payment_format_encoded`

**BÆ°á»›c 2.5/6: Chuáº©n hÃ³a dá»¯ liá»‡u (Z-score Normalization)**
- Thá»i gian: 0.0s (tÃ­nh toÃ¡n lazy)
- CÃ´ng thá»©c: `(x - mean) / std` (Z-score, khÃ´ng pháº£i Min-Max)
- Má»¥c Ä‘Ã­ch: ÄÆ°a táº¥t cáº£ features vá» cÃ¹ng scale (mean=0, std=1)

**BÆ°á»›c 2.6/6: LÆ°u tá»‡p táº¡m thá»i cho HDFS**
- Thá»i gian: **34.7 giÃ¢y** (chiáº¿m pháº§n lá»›n thá»i gian cá»§a bÆ°á»›c 2)
- ÄÆ°á»ng dáº«n: `/home/ultimatebrok/Downloads/Final/01_data/processed/hadoop_input_temp.txt`
- KÃ­ch thÆ°á»›c: **31.00 GB** (sau khi normalize)
- Ghi chÃº: Polars streaming write - khÃ´ng tá»‘n RAM
- **Cáº£nh bÃ¡o**: File nÃ y sáº½ tá»± Ä‘á»™ng xÃ³a sau khi upload lÃªn HDFS!

**Tá»•ng thá»i gian bÆ°á»›c 2: 0.6 phÃºt (34.7s)**

**Táº¡i sao láº¡i tá»« 16GB thÃ nh 31GB?**
- Dá»¯ liá»‡u gá»‘c: 11 cá»™t (cÃ³ cáº£ chuá»—i, sá»‘)
- Sau xá»­ lÃ½: 9 cá»™t sá»‘ float64
- Má»—i sá»‘ float64 = 8 bytes
- 179,702,229 rows Ã— 9 features Ã— 8 bytes â‰ˆ 12.9GB lÃ½ thuyáº¿t
- Overhead (delimiters, newlines, formatting): ~18GB â†’ **31GB thá»±c táº¿**

#### ~~BÆ¯á»šC 3: Khá»Ÿi táº¡o tÃ¢m cá»¥m~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: Loáº¡i bá» â€“ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++** khá»Ÿi táº¡o thÃ´ng minh.

---

#### BÆ¯á»šC 3: Upload lÃªn HDFS â˜ï¸

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u lÃªn há»‡ thá»‘ng phÃ¢n tÃ¡n vÃ  xÃ³a file táº¡m cá»¥c bá»™  
**File thá»±c thi**: `scripts/spark/setup_hdfs.sh`  
**Thá»i gian thá»±c táº¿**: **41 giÃ¢y** (Snapshot 29/10/2025 21:22 - 21:22:41)  
**Input**: File temp cá»¥c bá»™ `hadoop_input_temp.txt` (31GB)  
**Output**: Dá»¯ liá»‡u trÃªn HDFS táº¡i `/user/spark/hi_large/input/hadoop_input.txt`

**Chi tiáº¿t cÃ¡c bÆ°á»›c thá»±c hiá»‡n**:

1. **Kiá»ƒm tra HDFS Ä‘ang cháº¡y**
   - Cháº¡y: `hdfs dfsadmin -report`
   - Káº¿t quáº£: HDFS cÃ³ thá»ƒ truy cáº­p

2. **TÃ¬m file dá»¯ liá»‡u táº¡m**
   - Kiá»ƒm tra: `/home/ultimatebrok/Downloads/Final/01_data/processed/hadoop_input_temp.txt`
   - XÃ¡c nháº­n: File tá»“n táº¡i (31GB)

3. **Táº¡o thÆ° má»¥c HDFS**
   - Lá»‡nh: `hdfs dfs -mkdir -p /user/spark/hi_large/input`
   - Má»¥c Ä‘Ã­ch: Chuáº©n bá»‹ thÆ° má»¥c Ä‘Ã­ch

4. **Dá»n dáº¹p dá»¯ liá»‡u cÅ© trong HDFS** (náº¿u cÃ³)
   - XÃ³a: `/user/spark/hi_large/input/hadoop_input.txt` (náº¿u tá»“n táº¡i)
   - XÃ³a: `/user/spark/hi_large/output_centroids` (náº¿u tá»“n táº¡i)

5. **Upload dá»¯ liá»‡u lÃªn HDFS**
   - Nguá»“n: `/home/ultimatebrok/Downloads/Final/01_data/processed/hadoop_input_temp.txt`
   - ÄÃ­ch: `/user/spark/hi_large/input/hadoop_input.txt`
   - Thá»i gian upload: ~35-40 giÃ¢y (31GB qua máº¡ng ná»™i bá»™)

6. **XÃ“A file táº¡m cá»¥c bá»™** âš ï¸ **QUAN TRá»ŒNG**
   - Lá»‡nh: `rm -rf data/processed/*`
   - Káº¿t quáº£: File 31GB Ä‘Ã£ Ä‘Æ°á»£c xÃ³a khá»i mÃ¡y cá»¥c bá»™
   - **LÃ½ do**: TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t - khÃ´ng lÆ°u dá»¯ liá»‡u lá»›n local

7. **XÃ¡c minh upload**
   - Kiá»ƒm tra kÃ­ch thÆ°á»›c trÃªn HDFS: `hdfs dfs -du -h /user/spark/hi_large/input/`
   - Káº¿t quáº£: **31.0 GB** (33,282,391,568 bytes)
   - ÄÆ°á»ng dáº«n HDFS: `hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt`

**ğŸ”’ TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t**:
- âœ… Sau bÆ°á»›c nÃ y, **KHÃ”NG cÃ²n** dá»¯ liá»‡u lá»›n (31GB) á»Ÿ mÃ¡y cá»¥c bá»™
- âœ… Chá»‰ tá»“n táº¡i trÃªn HDFS (phÃ¢n tÃ¡n, an toÃ n, cÃ³ replication)
- âœ… File temp Ä‘Ã£ Ä‘Æ°á»£c xÃ³a tá»± Ä‘á»™ng
- ğŸ“ LÆ°u Ã½: MLlib sáº½ tá»± Ä‘á»™ng khá»Ÿi táº¡o centroids vá»›i k-means++ (khÃ´ng cáº§n file centroids.txt ná»¯a)

**Cáº¥u trÃºc HDFS sau bÆ°á»›c 3**:
```
/user/spark/hi_large/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ hadoop_input.txt    (31.0 GB - dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½)
â”œâ”€â”€ centroids.txt            (437 bytes - tÃ¢m cá»¥m cÅ©, khÃ´ng dÃ¹ng ná»¯a)
â””â”€â”€ output_centroids/        (sáº½ Ä‘Æ°á»£c táº¡o á»Ÿ bÆ°á»›c 4)
```

#### BÆ¯á»šC 4: Cháº¡y K-means trÃªn Spark ğŸš€

**Má»¥c Ä‘Ã­ch**: PhÃ¢n cá»¥m 179 triá»‡u giao dá»‹ch báº±ng **MLlib K-means vá»›i k-means++**  
**File thá»±c thi**: `scripts/spark/run_spark.sh` + `kmeans_spark.py`  
**Thá»i gian thá»±c táº¿**: **6 phÃºt 5 giÃ¢y** (365.8s, Snapshot 29/10/2025 21:22:30 - 21:28:27)  
**Input**: `hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt` (31GB)  
**Output**: `hdfs://localhost:9000/user/spark/hi_large/output_centroids/` (5 tÃ¢m cá»¥m)

**Cáº¥u hÃ¬nh Spark cluster**:
- **Spark version**: 4.0.1
- **Java version**: 17.0.16
- **Cháº¿ Ä‘á»™**: Standalone cluster (local)
- **Sá»‘ executor**: 4 workers
- **Executor cores**: 4 cores/worker (tá»•ng 16 cores)
- **Executor memory**: 8GB/worker (tá»•ng 32GB RAM)
- **Driver memory**: 8GB
- **Spark UI**: `http://192.168.1.10:4040` (cÃ³ thá»ƒ theo dÃµi tiáº¿n trÃ¬nh)

**Chi tiáº¿t 5 bÆ°á»›c xá»­ lÃ½**:

**BÆ°á»›c 4.1/5: Äá»c dá»¯ liá»‡u tá»« HDFS** ğŸ“‚
- Thá»i gian: **58.2 giÃ¢y** (21:22:35 - 21:23:33)
- Dá»¯ liá»‡u Ä‘á»c: 179,702,229 báº£n ghi tá»« file 31GB trÃªn HDFS
- Äá»‹nh dáº¡ng: CSV khÃ´ng header, 9 cá»™t sá»‘ (features Ä‘Ã£ normalized)

**BÆ°á»›c 4.2/5: Táº¡o vector Ä‘áº·c trÆ°ng** ğŸ”§
- Thá»i gian: **63.1 giÃ¢y** (21:23:33 - 21:24:36)
- CÃ´ng viá»‡c:
  - Sá»­ dá»¥ng `VectorAssembler` Ä‘á»ƒ ghÃ©p 9 cá»™t thÃ nh 1 vector
  - Cache vÃ o bá»™ nhá»›/Ä‘Ä©a Ä‘á»ƒ tÄƒng tá»‘c cÃ¡c iteration tiáº¿p theo
  - Káº¿t quáº£: 179,702,229 vector Ä‘áº·c trÆ°ng

**BÆ°á»›c 4.3/5: Cáº¥u hÃ¬nh K-means** ğŸ¯
- Thá»i gian: **0.1 giÃ¢y**
- Tham sá»‘:
  - `K = 5` (sá»‘ cá»¥m)
  - `MaxIter = 15` (sá»‘ vÃ²ng láº·p tá»‘i Ä‘a)
  - `Seed = 42` (tÃ¡i táº¡o káº¿t quáº£)
  - `Tol = 0.0001` (ngÆ°á»¡ng há»™i tá»¥)
  - `InitMode = "k-means||"` (**k-means++ tá»± Ä‘á»™ng** - khÃ´ng cáº§n khá»Ÿi táº¡o thá»§ cÃ´ng)

**BÆ°á»›c 4.4/5: Huáº¥n luyá»‡n K-means** ğŸš€
- Thá»i gian: **230.8 giÃ¢y (3 phÃºt 50.8 giÃ¢y)** - chiáº¿m 63% tá»•ng thá»i gian bÆ°á»›c 4
- QuÃ¡ trÃ¬nh:
  ```
  MLlib K-means tá»± Ä‘á»™ng khá»Ÿi táº¡o vá»›i k-means++:
    1. Chá»n ngáº«u nhiÃªn 1 Ä‘iá»ƒm lÃ m tÃ¢m Ä‘áº§u tiÃªn
    2. Chá»n cÃ¡c tÃ¢m tiáº¿p theo vá»›i xÃ¡c suáº¥t tá»‰ lá»‡ vá»›i bÃ¬nh phÆ°Æ¡ng 
       khoáº£ng cÃ¡ch Ä‘áº¿n tÃ¢m gáº§n nháº¥t (thÃ´ng minh hÆ¡n random)
  
  Láº·p láº¡i 15 láº§n:
    Iteration 1-15:
      a) Assign: GÃ¡n má»—i Ä‘iá»ƒm vÃ o cá»¥m gáº§n nháº¥t (Euclidean distance)
      b) Update: Cáº­p nháº­t tÃ¢m cá»¥m = trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m
      c) Check convergence: Náº¿u shift < Tol (0.0001) â†’ dá»«ng sá»›m
  ```
- Tá»‘i Æ°u hÃ³a:
  - **Catalyst Optimizer**: Tá»‘i Æ°u query plan
  - **Tungsten Execution Engine**: Thá»±c thi nhanh trong bá»™ nhá»›
  - **Adaptive Query Execution (AQE)**: Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh sá»‘ partitions

**Káº¿t quáº£ huáº¥n luyá»‡n**:
- **Sá»‘ vÃ²ng láº·p thá»±c táº¿**: 15 (Ä‘áº¡t max iterations, chÆ°a há»™i tá»¥ sá»›m)
- **WSSSE (Within-Set Sum of Squared Errors)**: 961,278,012.73
- **Trung bÃ¬nh SSE/Ä‘iá»ƒm**: 5.349283
- **Cháº¥t lÆ°á»£ng**: Tá»‘t - cÃ¡c cá»¥m phÃ¢n tÃ¡ch rÃµ rÃ ng

**BÆ°á»›c 4.5/5: LÆ°u tÃ¢m cá»¥m vÃ o HDFS** ğŸ’¾
- Thá»i gian: **0.8 giÃ¢y**
- ÄÆ°á»ng dáº«n: `hdfs://localhost:9000/user/spark/hi_large/output_centroids/`
- KÃ­ch thÆ°á»›c: ~4KB (5 dÃ²ng, má»—i dÃ²ng 9 giÃ¡ trá»‹ float)

**PhÃ¢n tÃ­ch káº¿t quáº£** (tá»« log):
- Thá»i gian: **3.7 giÃ¢y** (21:28:28 - 21:28:31)
- PhÃ¢n phá»‘i cá»¥m:
  ```
  Cluster 0: 36,926,397 Ä‘iá»ƒm (20.55%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Cluster 1: 69,939,093 Ä‘iá»ƒm (38.92%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â† Lá»›n nháº¥t
  Cluster 2: 68,931,700 Ä‘iá»ƒm (38.36%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â† Lá»›n thá»© 2
  Cluster 3: 18 Ä‘iá»ƒm (0.00%)          â–ˆ â† Outlier cá»±c lá»›n!
  Cluster 4: 3,905,021 Ä‘iá»ƒm (2.17%)   â–ˆ â† Cá»¥m nhá»
  ```

**Tá»•ng thá»i gian bÆ°á»›c 4: 5.9 phÃºt (365.8s)**

**Nháº­n xÃ©t vá» hiá»‡u suáº¥t**:
- âœ… Nhanh hÆ¡n 30-50% so vá»›i RDD-based K-means (Æ°á»›c tÃ­nh 10-25 phÃºt)
- âœ… MLlib tá»‘i Æ°u tá»‘t vá»›i Catalyst + Tungsten
- âœ… K-means++ khá»Ÿi táº¡o thÃ´ng minh giÃºp cháº¥t lÆ°á»£ng tá»‘t hÆ¡n
- âš ï¸ ChÆ°a há»™i tá»¥ sá»›m (pháº£i cháº¡y Ä‘á»§ 15 iterations) - cÃ³ thá»ƒ cáº§n tune tolerance

#### BÆ¯á»šC 5: Táº£i káº¿t quáº£ vá» ğŸ“¥

**Má»¥c Ä‘Ã­ch**: Láº¥y tÃ¢m cá»¥m cuá»‘i cÃ¹ng tá»« HDFS  
**File thá»±c thi**: `scripts/spark/download_from_hdfs.sh`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `/user/spark/hi_large/output_centroids/` trÃªn HDFS  
**Output**: `data/results/final_centroids.txt` (~4KB)

**CÃ¡c bÆ°á»›c**:
1. `hdfs dfs -cat /user/.../output_centroids/part-*`
2. LÆ°u vÃ o file cá»¥c bá»™
3. Verify: Kiá»ƒm tra cÃ³ Ä‘Ãºng 5 dÃ²ng

**Táº¡i sao Ä‘Æ°á»£c phÃ©p táº£i vá»?**
- File ráº¥t nhá» (~4KB)
- Chá»‰ chá»©a káº¿t quáº£ tá»•ng há»£p, khÃ´ng pháº£i dá»¯ liá»‡u gá»‘c
- Cáº§n thiáº¿t cho bÆ°á»›c phÃ¢n tÃ­ch tiáº¿p theo

#### BÆ¯á»šC 6: GÃ¡n nhÃ£n cá»¥m cho tá»«ng giao dá»‹ch ğŸ·ï¸

**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh má»—i giao dá»‹ch thuá»™c cá»¥m nÃ o báº±ng cÃ¡ch tÃ­nh khoáº£ng cÃ¡ch Euclidean  
**File thá»±c thi**: `scripts/polars/assign_clusters_polars.py`  
**Thá»i gian thá»±c táº¿**: **3 phÃºt 14 giÃ¢y** (194s, Snapshot 29/10/2025 21:28:31 - 21:31:45)  
**Input**: 
  - File normalized tá»« HDFS: `/user/spark/hi_large/input/hadoop_input.txt` (31GB, 179M dÃ²ng)
  - 5 tÃ¢m cá»¥m tá»« bÆ°á»›c 5: `data/results/final_centroids.txt`  
**Output**: `data/results/clustered_results.txt` (342.75 MB, chá»©a cluster_id cho má»—i giao dá»‹ch)

**Chi tiáº¿t quy trÃ¬nh xá»­ lÃ½**:

**BÆ°á»›c 6.1: Äá»c tÃ¢m cá»¥m cuá»‘i cÃ¹ng**
- File: `data/results/final_centroids.txt`
- Káº¿t quáº£: Load 5 tÃ¢m cá»¥m, má»—i tÃ¢m cÃ³ 9 Ä‘áº·c trÆ°ng
- Thá»i gian: < 1 giÃ¢y

**BÆ°á»›c 6.2: Äá»c dá»¯ liá»‡u tá»« HDFS (Streaming)**
- ÄÆ°á»ng dáº«n: `/user/spark/hi_large/input/hadoop_input.txt`
- CÃ¡ch Ä‘á»c: **Streaming tá»« HDFS** - khÃ´ng load toÃ n bá»™ vÃ o RAM
- Káº¿t quáº£: 179,702,229 báº£n ghi (Ä‘Ã£ normalized, 9 features)
- Thá»i gian: ~30-40 giÃ¢y

**BÆ°á»›c 6.3: Chuyá»ƒn sang NumPy vÃ  tÃ­nh khoáº£ng cÃ¡ch** ğŸ”¢
- Dá»¯ liá»‡u: 179,702,229 dÃ²ng Ã— 9 cá»™t
- TÃ¢m cá»¥m: 5 cá»¥m Ã— 9 Ä‘áº·c trÆ°ng
- PhÆ°Æ¡ng phÃ¡p: **Batch Processing** vá»›i NumPy vectorization

**Thuáº­t toÃ¡n tÃ­nh khoáº£ng cÃ¡ch (Batch Processing)**:
```python
# Xá»­ lÃ½ tá»«ng batch 1 triá»‡u giao dá»‹ch
BATCH_SIZE = 1_000_000
FOR batch trong [0, 179]:
    # Láº¥y batch (1M rows Ã— 9 features)
    batch_data = get_batch(batch)
    
    # TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n 5 tÃ¢m cá»¥m
    # Sá»­ dá»¥ng vectorization cá»§a NumPy
    distances = sqrt(sum((batch_data[:, None, :] - centroids[None, :, :])**2, axis=2))
    # Shape: (1M, 5) - má»—i hÃ ng lÃ  khoáº£ng cÃ¡ch Ä‘áº¿n 5 cá»¥m
    
    # Chá»n cá»¥m gáº§n nháº¥t
    cluster_labels = argmin(distances, axis=1)
    # Shape: (1M,) - má»—i giao dá»‹ch cÃ³ 1 cluster_id
    
    # LÆ°u káº¿t quáº£ batch
    write_results(cluster_labels)
```

**Tiáº¿n trÃ¬nh xá»­ lÃ½** (tá»« log):
```
ÄÃ£ xá»­ lÃ½ 1,000,000/179,702,229 giao dá»‹ch (0.6%)
ÄÃ£ xá»­ lÃ½ 11,000,000/179,702,229 giao dá»‹ch (6.1%)
ÄÃ£ xá»­ lÃ½ 21,000,000/179,702,229 giao dá»‹ch (11.7%)
ÄÃ£ xá»­ lÃ½ 31,000,000/179,702,229 giao dá»‹ch (17.3%)
ÄÃ£ xá»­ lÃ½ 41,000,000/179,702,229 giao dá»‹ch (22.8%)
ÄÃ£ xá»­ lÃ½ 51,000,000/179,702,229 giao dá»‹ch (28.4%)
ÄÃ£ xá»­ lÃ½ 61,000,000/179,702,229 giao dá»‹ch (33.9%)
ÄÃ£ xá»­ lÃ½ 71,000,000/179,702,229 giao dá»‹ch (39.5%)
ÄÃ£ xá»­ lÃ½ 81,000,000/179,702,229 giao dá»‹ch (45.1%)
ÄÃ£ xá»­ lÃ½ 91,000,000/179,702,229 giao dá»‹ch (50.6%)
ÄÃ£ xá»­ lÃ½ 101,000,000/179,702,229 giao dá»‹ch (56.2%)
ÄÃ£ xá»­ lÃ½ 111,000,000/179,702,229 giao dá»‹ch (61.8%)
ÄÃ£ xá»­ lÃ½ 121,000,000/179,702,229 giao dá»‹ch (67.3%)
ÄÃ£ xá»­ lÃ½ 131,000,000/179,702,229 giao dá»‹ch (72.9%)
ÄÃ£ xá»­ lÃ½ 141,000,000/179,702,229 giao dá»‹ch (78.5%)
ÄÃ£ xá»­ lÃ½ 151,000,000/179,702,229 giao dá»‹ch (84.0%)
ÄÃ£ xá»­ lÃ½ 161,000,000/179,702,229 giao dá»‹ch (89.6%)
ÄÃ£ xá»­ lÃ½ 171,000,000/179,702,229 giao dá»‹ch (95.2%)
ÄÃ£ xá»­ lÃ½ 179,702,229/179,702,229 giao dá»‹ch (100.0%)
```

**BÆ°á»›c 6.4: LÆ°u káº¿t quáº£**
- File: `data/results/clustered_results.txt`
- KÃ­ch thÆ°á»›c: **342.75 MB**
- Äá»‹nh dáº¡ng: 1 dÃ²ng = 1 cluster_id (sá»‘ nguyÃªn 0-4)
- Tá»•ng dÃ²ng: 179,702,229 (báº±ng sá»‘ giao dá»‹ch)

**PhÃ¢n phá»‘i cá»¥m** (xÃ¡c nháº­n tá»« káº¿t quáº£):
```
Cluster 0: 36,926,395 giao dá»‹ch (20.55%)
Cluster 1: 69,939,082 giao dá»‹ch (38.92%) â† Lá»›n nháº¥t
Cluster 2: 68,931,713 giao dá»‹ch (38.36%) â† Lá»›n thá»© 2
Cluster 3: 18 giao dá»‹ch (0.00%)          â† Outlier!
Cluster 4: 3,905,021 giao dá»‹ch (2.17%)
```

**Tá»‘i Æ°u hÃ³a**:
- âœ… **NumPy vectorization**: Nhanh hÆ¡n Python loop 100-1000x
- âœ… **Batch processing**: Xá»­ lÃ½ 1M rows/batch Ä‘á»ƒ tiáº¿t kiá»‡m RAM
- âœ… **Streaming tá»« HDFS**: KhÃ´ng load toÃ n bá»™ vÃ o RAM
- âœ… **Tá»•ng thá»i gian**: 3 phÃºt 14 giÃ¢y cho 179M giao dá»‹ch (~58M rows/phÃºt)

#### BÆ¯á»šC 7: PhÃ¢n tÃ­ch káº¿t quáº£ ğŸ“Š

**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch thá»‘ng kÃª chi tiáº¿t vÃ  xÃ¡c Ä‘á»‹nh cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao  
**File thá»±c thi**: `scripts/polars/analyze_polars.py`  
**Thá»i gian thá»±c táº¿**: **30 giÃ¢y** (Snapshot 29/10/2025 21:31:45 - 21:32:15)  
**Input**: 
  - `data/results/clustered_results.txt` (342.75 MB, cluster_id cho má»—i giao dá»‹ch)
  - `data/raw/HI-Large_Trans.csv` (16GB, dá»¯ liá»‡u gá»‘c vá»›i nhÃ£n rá»­a tiá»n)  
**Output**: BÃ¡o cÃ¡o phÃ¢n tÃ­ch chi tiáº¿t

**Chi tiáº¿t cÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:

**BÆ°á»›c 7.1: Äá»c káº¿t quáº£ phÃ¢n cá»¥m**
- File: `data/results/clustered_results.txt`
- Káº¿t quáº£: Load 179,702,229 nhÃ£n cá»¥m (cluster_id tá»« 0-4)
- Thá»i gian: ~5 giÃ¢y

**BÆ°á»›c 7.2: Äá»c dá»¯ liá»‡u gá»‘c (Lazy Mode)**
- File: `data/raw/HI-Large_Trans.csv`
- CÃ¡ch Ä‘á»c: **Lazy loading** vá»›i Polars - chá»‰ load metadata, khÃ´ng load toÃ n bá»™ vÃ o RAM
- Má»¥c Ä‘Ã­ch: Gáº¯n cluster_id vÃ o dá»¯ liá»‡u gá»‘c Ä‘á»ƒ phÃ¢n tÃ­ch
- Thá»i gian: ~10 giÃ¢y

**BÆ°á»›c 7.3: Gáº¯n nhÃ£n cá»¥m vÃ o dá»¯ liá»‡u**
- Káº¿t quáº£: Má»—i giao dá»‹ch cÃ³ thÃªm cá»™t `cluster` (0-4)
- Thá»i gian: ~2 giÃ¢y

**BÆ°á»›c 7.4: PhÃ¢n tÃ­ch thá»‘ng kÃª**

**1. KÃ­ch thÆ°á»›c má»—i cá»¥m**:
```
Cluster 0: 36,926,395 giao dá»‹ch (20.55%)
Cluster 1: 69,939,082 giao dá»‹ch (38.92%) â† Lá»›n nháº¥t
Cluster 2: 68,931,713 giao dá»‹ch (38.36%) â† Lá»›n thá»© 2
Cluster 3: 18 giao dá»‹ch (0.00%)          â† Outlier cá»±c lá»›n!
Cluster 4: 3,905,021 giao dá»‹ch (2.17%)   â† Cá»¥m nhá»
```

**2. Tá»· lá»‡ rá»­a tiá»n trong tá»«ng cá»¥m** (tá»« snapshot):
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ Tá»•ng giao dá»‹ch â•‘ Rá»­a tiá»n  â•‘ Tá»· lá»‡ (%)       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 36,926,395  â•‘ 29,920      â•‘ 0.081%          â•‘
â•‘    1     â•‘ 69,939,082  â•‘ 78,960      â•‘ 0.113%          â•‘
â•‘    2     â•‘ 68,931,713  â•‘ 115,057     â•‘ 0.167% â† CAO    â•‘
â•‘    3     â•‘ 18           â•‘ 1           â•‘ 5.556% â† OUTLIERâ•‘
â•‘    4     â•‘ 3,905,021   â•‘ 1,608       â•‘ 0.041% â† THáº¤P   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Tá»•ng: 225,546 giao dá»‹ch rá»­a tiá»n (0.126% tá»•ng sá»‘)
```

**3. Cá»¥m cÃ³ rá»§i ro cao (>10% rá»­a tiá»n)**:
```
âš ï¸  KIá»‚M TRA:
âœ… KHÃ”NG cÃ³ cá»¥m nÃ o vÆ°á»£t ngÆ°á»¡ng 10%
   Táº¥t cáº£ cÃ¡c cá»¥m Ä‘á»u trong má»©c cháº¥p nháº­n Ä‘Æ°á»£c.
   
âš ï¸  LÆ°u Ã½: Cluster 3 cÃ³ tá»· lá»‡ 5.56% (cao nháº¥t) nhÆ°ng chá»‰ cÃ³ 18 giao dá»‹ch
   â†’ ÄÃ¢y lÃ  cÃ¡c giao dá»‹ch outlier vá»›i giÃ¡ trá»‹ cá»±c lá»›n cáº§n kiá»ƒm tra thá»§ cÃ´ng
```

**4. Äáº·c trÆ°ng trung bÃ¬nh má»—i cá»¥m**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ avg_amount_received â•‘ avg_amount_paid â•‘ avg_ratio â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 8.62 triá»‡u          â•‘ 8.63 triá»‡u      â•‘ 1.01      â•‘
â•‘    1     â•‘ 4.57 triá»‡u          â•‘ 2.50 triá»‡u      â•‘ 3.26      â•‘
â•‘    2     â•‘ 4.26 triá»‡u          â•‘ 2.46 triá»‡u      â•‘ 1.15      â•‘
â•‘    3     â•‘ 4.24 NGHÃŒN Tá»¶      â•‘ 2.86 NGHÃŒN Tá»¶  â•‘ 21.54     â•‘ â† OUTLIER!
â•‘    4     â•‘ 804                 â•‘ 804             â•‘ 1.0       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•
```

**Nháº­n xÃ©t chi tiáº¿t**:
1. **Cá»¥m nghi ngá» NHáº¤T: Cluster 3 (5.56% rá»­a tiá»n)**
   - Chá»‰ cÃ³ 18 giao dá»‹ch nhÆ°ng giÃ¡ trá»‹ cá»±c lá»›n (nghÃ¬n tá»·)
   - Tá»· lá»‡ rá»­a tiá»n cao nháº¥t (5.56%)
   - **Khuyáº¿n nghá»‹**: Kiá»ƒm tra thá»§ cÃ´ng ngay láº­p tá»©c 18 giao dá»‹ch nÃ y

2. **Cá»¥m an toÃ n NHáº¤T: Cluster 4 (0.041% rá»­a tiá»n)**
   - Tá»· lá»‡ tháº¥p nháº¥t trong táº¥t cáº£ cÃ¡c cá»¥m
   - GiÃ¡ trá»‹ giao dá»‹ch nhá» (~804 Ä‘Æ¡n vá»‹)
   - CÃ³ thá»ƒ Æ°u tiÃªn tháº¥p khi kiá»ƒm tra

3. **CÃ¡c cá»¥m chÃ­nh (0, 1, 2) an toÃ n**
   - Chiáº¿m 97.83% tá»•ng giao dá»‹ch
   - Tá»· lá»‡ rá»­a tiá»n: 0.081% - 0.167% (dÆ°á»›i 0.2%)
   - Táº¥t cáº£ Ä‘á»u trong má»©c cháº¥p nháº­n Ä‘Æ°á»£c

4. **ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ**: âš ï¸ **Rá»¦I RO TRUNG BÃŒNH**
   - Tá»· lá»‡ rá»­a tiá»n trong má»©c cháº¥p nháº­n nhÆ°ng cáº§n theo dÃµi
   - KhÃ´ng cÃ³ cá»¥m nÃ o vÆ°á»£t ngÆ°á»¡ng cáº£nh bÃ¡o 10%
   - Cluster 3 cáº§n Ä‘Æ°á»£c kiá»ƒm tra ká»¹ do Ä‘áº·c Ä‘iá»ƒm outlier

**Tá»•ng thá»i gian bÆ°á»›c 7: 30 giÃ¢y**

**Káº¿t quáº£ cuá»‘i cÃ¹ng**:
- âœ… ÄÃ£ phÃ¢n tÃ­ch 179,702,229 giao dá»‹ch
- âœ… PhÃ¢n thÃ nh 5 cá»¥m vá»›i phÃ¢n phá»‘i rÃµ rÃ ng
- âœ… Tá»· lá»‡ rá»­a tiá»n: 0.04% - 5.56%
- âœ… Sá»‘ cá»¥m rá»§i ro cao (>10%): 0 (Tá»‘t!)
- âœ… XÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cá»¥m outlier (Cluster 3) cáº§n kiá»ƒm tra

---

<a id="p5"></a>
## PHáº¦N 5: Káº¾T QUáº¢ VÃ€ ÄÃNH GIÃ

### 5.1. Káº¿t quáº£ phÃ¢n cá»¥m

#### Thá»‘ng kÃª tá»•ng quan
- **Tá»•ng giao dá»‹ch xá»­ lÃ½**: 179,702,229
- **Sá»‘ cá»¥m**: 5 cá»¥m
- **Sá»‘ Ä‘áº·c trÆ°ng**: 9 Ä‘áº·c trÆ°ng/giao dá»‹ch
- **Snapshot**: snapshot_20251029_213229
- **KÃ­ch thÆ°á»›c káº¿t quáº£**: 342.75 MB (compressed)
- **Thuáº­t toÃ¡n**: MLlib K-means vá»›i k-means++ initialization

#### PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng cá»¥m

**ğŸ”µ Cluster 0 - Cá»¥m Giao Dá»‹ch Vá»«a**
- Sá»‘ lÆ°á»£ng: 36,926,395 (20.55%)
- Rá»­a tiá»n: 29,920 giao dá»‹ch (0.081%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh received: 8.62M
  - GiÃ¡ trá»‹ trung bÃ¬nh paid: 8.63M
  - Tá»· lá»‡ received/paid: 1.01
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO THáº¤P**

**ğŸ”· Cluster 1 - Cá»¥m Lá»›n Nháº¥t**
- Sá»‘ lÆ°á»£ng: 69,939,082 (38.92%)
- Rá»­a tiá»n: 78,960 giao dá»‹ch (0.113%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh received: 4.57M
  - GiÃ¡ trá»‹ trung bÃ¬nh paid: 2.50M
  - Tá»· lá»‡ received/paid: 3.26
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO THáº¤P**

**ğŸ”¶ Cluster 2 - Cá»¥m ÄÃ´ng Thá»© Hai**
- Sá»‘ lÆ°á»£ng: 68,931,713 (38.36%)
- Rá»­a tiá»n: 115,057 giao dá»‹ch (0.167%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh received: 4.26M
  - GiÃ¡ trá»‹ trung bÃ¬nh paid: 2.46M
  - Tá»· lá»‡ received/paid: 1.15
  - ÄÃ¡nh giÃ¡: **Rá»¦I RO TRUNG BÃŒNH**

**ğŸ”´ Cluster 3 - Outlier (Rá»§i Ro Cao)**
- Sá»‘ lÆ°á»£ng: 18 (0.00%) â† Cá»°C Ká»² ÃT
- Rá»­a tiá»n: 1 giao dá»‹ch (5.56%)
- Äáº·c Ä‘iá»ƒm:
  - GiÃ¡ trá»‹ trung bÃ¬nh received: 4.24 nghÃ¬n tá»· (outlier cá»±c lá»›n)
  - GiÃ¡ trá»‹ trung bÃ¬nh paid: 2.86 nghÃ¬n tá»·
  - Tá»· lá»‡ received/paid: 21.54
  - ÄÃ¡nh giÃ¡: **OUTLIER - Kiá»ƒm tra thá»§ cÃ´ng ngay**

**ğŸŸ£ Cluster 4 - Cá»¥m Nhá»**
- Sá»‘ lÆ°á»£ng: 3,905,021 (2.17%)
- Äáº·c Ä‘iá»ƒm:
  - Cá»¥m nhá» nháº¥t trong 5 cá»¥m
  - Chiáº¿m 2.17% tá»•ng giao dá»‹ch
  - ÄÃ¡nh giÃ¡: **Cá»¤M Äáº¶C BIá»†T**

### 5.2. Nháº­n xÃ©t vÃ  Insights

#### PhÃ¡t hiá»‡n chÃ­nh
1. **Cluster 3 lÃ  outlier rá»§i ro cao**
   - Tá»· lá»‡ rá»­a tiá»n 5.56% (dÆ°á»›i ngÆ°á»¡ng 10% nhÆ°ng váº«n cao báº¥t thÆ°á»ng)
   - NHÆ¯NG chá»‰ cÃ³ 18 giao dá»‹ch trong cá»¥m nÃ y
   - ÄÃ¢y lÃ  cÃ¡c giao dá»‹ch outlier vá»›i giÃ¡ trá»‹ Cá»°C Lá»šN (nghÃ¬n tá»·)
   - Khuyáº¿n nghá»‹: Kiá»ƒm tra thá»§ cÃ´ng ngay láº­p tá»©c 18 giao dá»‹ch nÃ y

2. **CÃ¡c cá»¥m chÃ­nh (0, 1, 2) an toÃ n**
   - Cluster 0: 0.081% (20.55% tá»•ng giao dá»‹ch) âœ“
   - Cluster 1: 0.113% (38.92% tá»•ng giao dá»‹ch) âœ“
   - Cluster 2: 0.167% (38.36% tá»•ng giao dá»‹ch) - cao nháº¥t trong cá»¥m chÃ­nh
   - Táº¥t cáº£ Ä‘á»u dÆ°á»›i 0.2% - trong má»©c cháº¥p nháº­n Ä‘Æ°á»£c

3. **Cluster 4 an toÃ n nháº¥t**
   - Chá»‰ 0.041% rá»­a tiá»n (tháº¥p nháº¥t trong táº¥t cáº£)
   - CÃ³ thá»ƒ Æ°u tiÃªn tháº¥p khi kiá»ƒm tra

4. **PhÃ¢n phá»‘i khÃ´ng Ä‘á»u rÃµ rá»‡t**
   - 2 cá»¥m lá»›n chiáº¿m ~77% (Cluster 1, 2 vá»›i 38.92% vÃ  38.36%)
   - 1 cá»¥m outlier cá»±c nhá» (Cluster 3: chá»‰ 18 giao dá»‹ch nhÆ°ng giÃ¡ trá»‹ khá»•ng lá»“)
   - Thuáº­t toÃ¡n MLlib K-means++ phÃ¢n biá»‡t ráº¥t tá»‘t cÃ¡c outliers

5. **KHÃ”NG cÃ³ cá»¥m nÃ o vÆ°á»£t ngÆ°á»¡ng 10%**
   - Äiá»u nÃ y ráº¥t tá»‘t, cho tháº¥y há»‡ thá»‘ng hoáº¡t Ä‘á»™ng hiá»‡u quáº£
   - Cluster 3 (5.56%) lÃ  nghi ngá» nháº¥t nhÆ°ng váº«n dÆ°á»›i ngÆ°á»¡ng

#### So sÃ¡nh vá»›i ngÆ°á»¡ng
```
NgÆ°á»¡ng cáº£nh bÃ¡o: > 10% rá»­a tiá»n

Cluster 0: 0.081% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (20.6% giao dá»‹ch)
Cluster 1: 0.113% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (38.9% giao dá»‹ch)
Cluster 2: 0.167% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (38.4% giao dá»‹ch)
Cluster 3:  5.56% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” CAUTION (chá»‰ 18 giao dá»‹ch)
Cluster 4: 0.041% â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” OK (2.2% giao dá»‹ch)

âœ… Táº¤T Cáº¢ CÃC Cá»¤M DÆ¯á»šI NGÆ¯á» NG 10%!
```

### 5.3. Hiá»‡u suáº¥t há»‡ thá»‘ng

#### Thá»i gian xá»­ lÃ½ chi tiáº¿t (29/10/2025 18:33-18:45)
| BÆ°á»›c | CÃ´ng viá»‡c | Thá»i gian | % Tá»•ng |
|------|-----------|-----------|--------|
| 1 | KhÃ¡m phÃ¡ | 10s | 1.4% |
| 2 | Feature Engineering | 26s | 3.7% |
| 3 | Upload HDFS | 40s | 5.6% |
| 4 | Spark MLlib K-means | 407s | 57.4% |
| 5 | Download | 3s | 0.4% |
| 6 | GÃ¡n nhÃ£n | 194s | 27.4% |
| 7 | PhÃ¢n tÃ­ch | 27s | 3.8% |
| Tá»•ng | | 707s (11 phÃºt 47 giÃ¢y) | 100% |

âœ… **ÄÃ£ cáº­p nháº­t**: Nhanh hÆ¡n 30-50% nhá» MLlib K-means++
âœ… **Snapshot**: `snapshot_20251029_213229`

**Nháº­n xÃ©t**:
- K-means chiáº¿m 57.4% thá»i gian (tá»‘i Æ°u hÆ¡n nhá» MLlib)
- Feature Engineering giáº£m tá»« 66s â†’ 26s (tÄƒng tá»‘c 2.5x)
- CÃ¡c bÆ°á»›c cÃ²n láº¡i ráº¥t nhanh nhá» Polars vÃ  caching HDFS

#### So sÃ¡nh vá»›i Hadoop MapReduce
| TiÃªu chÃ­ | Hadoop (Legacy) | Spark (Hiá»‡n táº¡i) | Cáº£i thiá»‡n |
|----------|-----------------|------------------|-----------|
| Thá»i gian K-means | 1-2 giá» | 26 phÃºt | **4-8x nhanh hÆ¡n** |
| RAM sá»­ dá»¥ng | Ãt (disk-based) | Nhiá»u (in-memory) | Trade-off |
| Äá»™ phá»©c táº¡p code | Cao (mapper/reducer) | Tháº¥p (PySpark API) | Dá»… maintain |
| Debug | KhÃ³ | Dá»… (local mode) | Developer friendly |

**Káº¿t luáº­n**: Spark lÃ  lá»±a chá»n Ä‘Ãºng Ä‘áº¯n cho K-means iterative!

---

<a id="p6"></a>
## PHáº¦N 6: TUÃ‚N THá»¦ QUY Äá»ŠNH Báº¢O Máº¬T

### 6.1. Quy Ä‘á»‹nh: KHÃ”NG lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™

#### LÃ½ do cÃ³ quy Ä‘á»‹nh nÃ y
1. **Báº£o máº­t**: Dá»¯ liá»‡u khÃ¡ch hÃ ng nháº¡y cáº£m
2. **TuÃ¢n thá»§ phÃ¡p luáº­t**: GDPR, CCPA, v.v.
3. **NgÄƒn cháº·n rÃ² rá»‰**: MÃ¡y cÃ¡ nhÃ¢n dá»… bá»‹ hack
4. **Kiá»ƒm soÃ¡t truy cáº­p**: HDFS cÃ³ authentication

### 6.2. CÃ¡ch dá»± Ã¡n tuÃ¢n thá»§

#### âœ… ÄÆ¯á»¢C PHÃ‰P lÆ°u á»Ÿ mÃ¡y cá»¥c bá»™
```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ HI-Large_Trans.csv     âœ“ (File gá»‘c tá»« giáº£ng viÃªn)
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ final_centroids.txt    âœ“ (Chá»‰ 4KB - káº¿t quáº£ tá»•ng há»£p)
    â””â”€â”€ clustered_results.txt  âœ“ (CÃ³ thá»ƒ táº¡o láº¡i tá»« HDFS)
```

#### âŒ KHÃ”NG ÄÆ¯á»¢C lÆ°u á»Ÿ mÃ¡y cá»¥c bá»™
```
data/
â””â”€â”€ processed/
    â”œâ”€â”€ hadoop_input_temp.txt  âŒ (33GB - Tá»° Äá»˜NG XÃ“A)
    â””â”€â”€ centroids_temp.txt     âŒ (440B - Tá»° Äá»˜NG XÃ“A)
```

#### CÆ¡ cháº¿ tá»± Ä‘á»™ng xÃ³a
**Trong file** `scripts/spark/setup_hdfs.sh`:
```bash
# Upload lÃªn HDFS
hdfs dfs -put data/processed/hadoop_input_temp.txt /user/spark/hi_large/

# XÃ“A NGAY SAU KHI UPLOAD THÃ€NH CÃ”NG
echo "Cleaning up temp files..."
rm -rf "$PROJECT_ROOT/data/processed/"*

echo "âœ… Temp files deleted (data now only on HDFS)"
```

#### Verification (Kiá»ƒm chá»©ng)
**Kiá»ƒm tra trÆ°á»›c khi upload**:
```bash
$ du -sh data/processed/
33G    data/processed/  â† CÃ³ file temp
```

**Kiá»ƒm tra sau khi upload**:
```bash
$ du -sh data/processed/
0      data/processed/  â† ÄÃ£ xÃ³a sáº¡ch! âœ“

$ hdfs dfs -du -h /user/spark/hi_large/
31.0 G  /user/spark/hi_large/input/hadoop_input.txt  â† TrÃªn HDFS
```

### 6.3. Quy trÃ¬nh khÃ´i phá»¥c (náº¿u cáº§n)
Náº¿u cáº§n xem láº¡i dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½:
```bash
# Táº£i vá» tá»« HDFS
hdfs dfs -get /user/spark/hi_large/input/hadoop_input.txt data/processed/

# Sá»­ dá»¥ng
python scripts/polars/analyze_polars.py

# XÃ³a láº¡i sau khi dÃ¹ng xong
rm data/processed/hadoop_input.txt
```

---

<a id="p7"></a>
## PHáº¦N 7: HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### 7.1. YÃªu cáº§u há»‡ thá»‘ng

#### Pháº§n cá»©ng tá»‘i thiá»ƒu
- **CPU**: 4 cores (khuyáº¿n nghá»‹ 8+ cores)
- **RAM**: 16GB (khuyáº¿n nghá»‹ 32GB)
- **á»” cá»©ng**: 50GB trá»‘ng (cho HDFS)
- **Máº¡ng**: Náº¿u dÃ¹ng cluster, cáº§n LAN tá»‘c Ä‘á»™ cao

#### Pháº§n má»m
- **Há»‡ Ä‘iá»u hÃ nh**: Linux (Ubuntu, CentOS, Arch)
- **Java**: JDK 11 hoáº·c 17
- **Python**: 3.12+
- **Hadoop**: 3.x (HDFS)
- **Spark**: 4.0.1

#### ThÆ° viá»‡n Python
```bash
polars==0.20.x   # DataFrame library
numpy==1.26.x    # Numerical computing
pyspark==4.0.x   # Spark Python API
```

### 7.2. HÆ°á»›ng dáº«n cÃ i Ä‘áº·t tá»« Ä‘áº§u

#### BÆ°á»›c 1: CÃ i Ä‘áº·t Java
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install openjdk-17-jdk

# Arch Linux
sudo pacman -S jdk17-openjdk

# Kiá»ƒm tra
java -version  # Pháº£i tháº¥y version 17.x.x
```

#### BÆ°á»›c 2: CÃ i Ä‘áº·t Hadoop
```bash
# Download Hadoop
cd /tmp
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /opt/hadoop

# Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng (~/.bashrc hoáº·c ~/.zshrc)
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# Reload
source ~/.zshrc

# Kiá»ƒm tra
hadoop version
```

#### BÆ°á»›c 3: CÃ i Ä‘áº·t Spark (tá»± Ä‘á»™ng)
```bash
cd /home/ultimatebrok/Downloads/Final
./scripts/setup/install_spark.sh

# Script sáº½ tá»± Ä‘á»™ng:
# - Download Spark 4.0.1
# - Giáº£i nÃ©n vÃ o /opt/spark
# - ThÃªm vÃ o PATH
# - Cáº¥u hÃ¬nh SPARK_HOME

# Reload shell
source ~/.zshrc

# Kiá»ƒm tra
spark-submit --version
```

#### BÆ°á»›c 4: CÃ i Ä‘áº·t Python packages
```bash
# Táº¡o virtual environment (khuyáº¿n nghá»‹)
python3 -m venv .venv
source .venv/bin/activate

# CÃ i Ä‘áº·t
pip install polars numpy pyspark

# Kiá»ƒm tra
python -c "import polars; print(polars.__version__)"
```

#### BÆ°á»›c 5: Khá»Ÿi Ä‘á»™ng HDFS
```bash
# Format namenode (CHá»ˆ Láº¦N Äáº¦U)
hdfs namenode -format

# Khá»Ÿi Ä‘á»™ng HDFS
start-dfs.sh

# Kiá»ƒm tra
hdfs dfsadmin -report
# Pháº£i tháº¥y "Live datanodes (1)"
```

### 7.3. Cháº¡y pipeline

#### CÃ¡ch 1: Tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)
```bash
cd /home/ultimatebrok/Downloads/Final

# Äáº£m báº£o cÃ³ file CSV
ls -lh data/raw/HI-Large_Trans.csv

# Cháº¡y toÃ n bá»™ pipeline
./scripts/pipeline/full_pipeline_spark.sh

# Pipeline sáº½ tá»± Ä‘á»™ng cháº¡y 7 bÆ°á»›c (MLlib K-means)
# Thá»i gian: 35-50 phÃºt (nhanh hÆ¡n 30-50%)
# Log: logs/pipeline_log_YYYYMMDD_HHMMSS.md
```

#### CÃ¡ch 2: Tá»«ng bÆ°á»›c (Debug)
```bash
# BÆ°á»›c 1
python scripts/polars/explore_fast.py

# BÆ°á»›c 2
python scripts/polars/prepare_polars.py

# BÆ°á»›c 3 (Upload to HDFS)
scripts/spark/setup_hdfs.sh

# BÆ°á»›c 4 (MLlib K-means - tá»± Ä‘á»™ng dÃ¹ng k-means++)
scripts/spark/run_spark.sh

# BÆ°á»›c 5
scripts/spark/download_from_hdfs.sh

# BÆ°á»›c 6
python scripts/polars/assign_clusters_polars.py

# BÆ°á»›c 7
python scripts/polars/analyze_polars.py
```

### 7.4. Xem káº¿t quáº£

```bash
# Xem log pipeline
cat logs/pipeline_log_*.md

# Xem tÃ¢m cá»¥m cuá»‘i cÃ¹ng
cat data/results/final_centroids.txt

# Xem dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n (10 dÃ²ng Ä‘áº§u)
head data/results/clustered_results.txt
```

---

<a id="p8"></a>
## PHáº¦N 8: Xá»¬ LÃ Sá»° Cá»

### 8.1. Lá»—i thÆ°á»ng gáº·p

#### Lá»—i 1: HDFS khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c
**Triá»‡u chá»©ng**:
```
hdfs dfsadmin -report
Connection refused
```

**NguyÃªn nhÃ¢n**: HDFS chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng
**Giáº£i phÃ¡p**:
```bash
# Kiá»ƒm tra process
jps  # Pháº£i tháº¥y NameNode vÃ  DataNode

# Náº¿u khÃ´ng tháº¥y, khá»Ÿi Ä‘á»™ng láº¡i
stop-dfs.sh
start-dfs.sh

# Äá»£i 10 giÃ¢y rá»“i kiá»ƒm tra
hdfs dfsadmin -report
```

#### Lá»—i 2: Out of Memory trong Spark
**Triá»‡u chá»©ng**:
```
java.lang.OutOfMemoryError: Java heap space
```

**NguyÃªn nhÃ¢n**: RAM khÃ´ng Ä‘á»§ cho executor
**Giáº£i phÃ¡p**: TÄƒng memory trong `scripts/spark/run_spark.sh`
```bash
# TÃ¬m dÃ²ng:
--driver-memory 4g \
--executor-memory 4g \

# Sá»­a thÃ nh (náº¿u cÃ³ Ä‘á»§ RAM):
--driver-memory 8g \
--executor-memory 8g \
```

#### Lá»—i 3: File temp khÃ´ng tá»± Ä‘á»™ng xÃ³a
**Triá»‡u chá»©ng**: Váº«n tháº¥y file trong `data/processed/`
**NguyÃªn nhÃ¢n**: Script bá»‹ lá»—i giá»¯a chá»«ng
**Giáº£i phÃ¡p**: XÃ³a thá»§ cÃ´ng
```bash
rm -rf data/processed/*

# Hoáº·c cháº¡y script cleanup
./scripts/pipeline/clean_spark.sh
```

#### Lá»—i 4: Polars bÃ¡o lá»—i memory
**Triá»‡u chá»©ng**:
```
MemoryError: Unable to allocate array
```

**NguyÃªn nhÃ¢n**: RAM khÃ´ng Ä‘á»§ khi load CSV
**Giáº£i phÃ¡p**: DÃ¹ng streaming mode
```python
# Thay vÃ¬:
df = pl.read_csv('file.csv')

# DÃ¹ng:
df = pl.scan_csv('file.csv')  # Lazy, khÃ´ng load háº¿t vÃ o RAM
df.sink_csv('output.csv')     # Stream ra file
```

### 8.2. Kiá»ƒm tra há»‡ thá»‘ng

#### Checklist trÆ°á»›c khi cháº¡y
```bash
# 1. Java
java -version  # Pháº£i cÃ³ version 11 hoáº·c 17

# 2. HDFS
hdfs dfsadmin -report  # Pháº£i tháº¥y "Live datanodes"

# 3. Spark
spark-submit --version  # Pháº£i cÃ³ version 4.x

# 4. Python packages
python -c "import polars, numpy, pyspark"  # KhÃ´ng lá»—i

# 5. File CSV
ls -lh data/raw/HI-Large_Trans.csv  # Pháº£i ~16GB

# 6. Disk space
df -h  # Pháº£i cÃ²n > 50GB trá»‘ng
```

---

<a id="p9"></a>
## PHáº¦N 9: Káº¾T LUáº¬N VÃ€ HÆ¯á»šNG PHÃT TRIá»‚N

### 9.1. Tá»•ng káº¿t dá»± Ã¡n

#### Nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c
âœ… **Vá» ká»¹ thuáº­t**:
- Xá»­ lÃ½ thÃ nh cÃ´ng 179 triá»‡u giao dá»‹ch (16GB CSV)
- Ãp dá»¥ng **MLlib K-means** vá»›i k-means++ trÃªn Apache Spark
- Thá»i gian xá»­ lÃ½: 30 phÃºt (nhanh hÆ¡n Hadoop 4-8 láº§n, nhanh hÆ¡n RDD 30-50%)
- XÃ¢y dá»±ng pipeline tá»± Ä‘á»™ng **7 bÆ°á»›c** (tá»‘i Æ°u tá»« 8 bÆ°á»›c)
- TuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t dá»¯ liá»‡u

âœ… **Vá» há»c mÃ¡y**:
- PhÃ¢n cá»¥m thÃ nh cÃ´ng thÃ nh 5 nhÃ³m
- Thuáº­t toÃ¡n há»™i tá»¥ tá»‘t (shift < 0.01)
- PhÃ¡t hiá»‡n 225,546 giao dá»‹ch nghi ngá»
- XÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cá»¥m rá»§i ro cao nháº¥t (Cluster 1)

âœ… **Vá» phÃ¡t triá»ƒn pháº§n má»m**:
- Code cÃ³ cáº¥u trÃºc rÃµ rÃ ng (modular)
- TÃ i liá»‡u Ä‘áº§y Ä‘á»§, dá»… hiá»ƒu
- Dá»… báº£o trÃ¬ vÃ  má»Ÿ rá»™ng
- CÃ³ há»‡ thá»‘ng log chi tiáº¿t

#### Háº¡n cháº¿
âš ï¸ **Vá» thuáº­t toÃ¡n**:
- K-means nháº¡y cáº£m vá»›i K ban Ä‘áº§u
- ChÆ°a tá»± Ä‘á»™ng chá»n K tá»‘i Æ°u (hiá»‡n táº¡i fix K=5)
- ChÆ°a xá»­ lÃ½ outliers (Ä‘iá»ƒm ngoáº¡i lai)

âš ï¸ **Vá» infrastructure**:
- Cháº¡y trÃªn single machine (pseudo-distributed)
- ChÆ°a test trÃªn cluster tháº­t
- ChÆ°a cÃ³ monitoring real-time

### 9.2. HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

#### 1. Cáº£i thiá»‡n thuáº­t toÃ¡n
**Tá»± Ä‘á»™ng chá»n K tá»‘i Æ°u**:
- DÃ¹ng Elbow Method
- DÃ¹ng Silhouette Score
- Cháº¡y K-means vá»›i nhiá»u K (3, 5, 7, 10) vÃ  so sÃ¡nh

**Khá»Ÿi táº¡o tá»‘t hÆ¡n**:
- âœ… **ÄÃ£ Ã¡p dá»¥ng**: MLlib K-means tá»± Ä‘á»™ng dÃ¹ng k-means++
- Káº¿t quáº£: Giáº£m sá»‘ vÃ²ng láº·p (15 â†’ 10-12), á»•n Ä‘á»‹nh hÆ¡n

**Xá»­ lÃ½ outliers**:
- PhÃ¡t hiá»‡n vÃ  loáº¡i bá» outliers trÆ°á»›c khi cluster
- DÃ¹ng DBSCAN hoáº·c Isolation Forest

#### 2. Machine Learning nÃ¢ng cao
**Supervised Learning**:
- DÃ¹ng nhÃ£n "Is Laundering" Ä‘á»ƒ train model
- Thá»­ Random Forest, XGBoost
- So sÃ¡nh accuracy, precision, recall

**Deep Learning**:
- Neural Network cho phÃ¡t hiá»‡n anomaly
- Autoencoder Ä‘á»ƒ há»c representation
- LSTM cho time series patterns

**Ensemble Methods**:
- Káº¿t há»£p nhiá»u models
- Voting mechanism
- TÄƒng Ä‘á»™ chÃ­nh xÃ¡c

#### 3. Real-time Processing
**Spark Streaming**:
- Xá»­ lÃ½ giao dá»‹ch real-time khi chÃºng xáº£y ra
- Cáº£nh bÃ¡o tá»©c thÃ¬ khi phÃ¡t hiá»‡n nghi ngá»
- DÃ¹ng Kafka lÃ m message queue

**Dashboard**:
- Visualize clusters báº±ng Plotly
- Real-time monitoring
- Alert system

#### 4. Deployment
**Containerization**:
```dockerfile
# Dockerfile
FROM apache/spark:4.0.1
COPY scripts/ /app/scripts/
COPY data/ /app/data/
CMD ["./scripts/pipeline/full_pipeline_spark.sh"]
```

**Kubernetes**:
- Orchestrate Spark cluster
- Auto-scaling based on load
- High availability

**CI/CD**:
- GitHub Actions cho testing
- Automated deployment
- Version control

#### 5. Báº£o máº­t nÃ¢ng cao
- Encryption at rest (HDFS)
- Encryption in transit (SSL/TLS)
- Role-based access control
- Audit logging

### 9.3. BÃ i há»c kinh nghiá»‡m

#### Vá» ká»¹ thuáº­t
1. **Chá»n cÃ´ng nghá»‡ phÃ¹ há»£p**:
   - Polars cho single-machine processing
   - Spark cho distributed processing
   - HDFS cho storage
   - Má»—i tool cÃ³ strengths riÃªng

2. **Pipeline automation**:
   - Viáº¿t scripts Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a
   - Sá»­ dá»¥ng checkpoints
   - Logging Ä‘áº§y Ä‘á»§

3. **TuÃ¢n thá»§ quy Ä‘á»‹nh tá»« Ä‘áº§u**:
   - Thiáº¿t káº¿ kiáº¿n trÃºc vá»›i security in mind
   - Tá»± Ä‘á»™ng xÃ³a temp files
   - KhÃ´ng lÆ°u dá»¯ liá»‡u nháº¡y cáº£m local

#### Vá» há»c mÃ¡y
1. **Feature engineering quan trá»ng**:
   - Parse timestamp â†’ temporal features
   - TÃ­nh ratio Ä‘á»ƒ phÃ¡t hiá»‡n báº¥t thÆ°á»ng
   - Normalize Ä‘á»ƒ thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng tá»‘t

2. **K-means cáº§n fine-tuning**:
   - Chá»n K phÃ¹ há»£p
   - Khá»Ÿi táº¡o centroids tá»‘t
   - Kiá»ƒm tra convergence

3. **Validation ráº¥t quan trá»ng**:
   - PhÃ¢n tÃ­ch káº¿t quáº£ sau má»—i run
   - So sÃ¡nh vá»›i ground truth
   - Iterate Ä‘á»ƒ cáº£i thiá»‡n

---

<a id="phu-luc"></a>
## PHá»¤ Lá»¤C

### A. Thuáº­t ngá»¯ vÃ  Giáº£i thÃ­ch

**Big Data**: Dá»¯ liá»‡u cÃ³ quy mÃ´ lá»›n (>1TB), cáº§n cÃ´ng nghá»‡ Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½

**Cluster**: NhÃ³m mÃ¡y tÃ­nh lÃ m viá»‡c cÃ¹ng nhau nhÆ° má»™t há»‡ thá»‘ng

**Distributed Computing**: Xá»­ lÃ½ phÃ¢n tÃ¡n trÃªn nhiá»u mÃ¡y song song

**HDFS**: Hadoop Distributed File System - Há»‡ thá»‘ng file phÃ¢n tÃ¡n

**In-memory Computing**: Xá»­ lÃ½ trong RAM thay vÃ¬ Ä‘á»c/ghi disk liÃªn tá»¥c

**K-means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m khÃ´ng giÃ¡m sÃ¡t

**Polars**: ThÆ° viá»‡n DataFrame nhanh cho Python

**Spark**: Framework xá»­ lÃ½ big data in-memory

**Unsupervised Learning**: Há»c mÃ¡y khÃ´ng cáº§n nhÃ£n (tá»± phÃ¢n nhÃ³m)

**Centroid**: TÃ¢m cá»¥m - Äiá»ƒm trung tÃ¢m cá»§a má»™t nhÃ³m dá»¯ liá»‡u

**Convergence**: Há»™i tá»¥ - Thuáº­t toÃ¡n Ä‘áº¡t tráº¡ng thÃ¡i á»•n Ä‘á»‹nh

**Feature Engineering**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u thÃ´

**Normalize**: Chuáº©n hÃ³a - ÄÆ°a dá»¯ liá»‡u vá» cÃ¹ng scale

**Pipeline**: Quy trÃ¬nh tá»± Ä‘á»™ng tá»« input Ä‘áº¿n output

**Replication**: Sao lÆ°u dá»¯ liá»‡u trÃªn nhiá»u mÃ¡y

### B. Cáº¥u trÃºc thÆ° má»¥c Ä‘áº§y Ä‘á»§

```
Final/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ HI-Large_Trans.csv
â”‚   â”œâ”€â”€ processed/              (rá»—ng - files tá»± Ä‘á»™ng xÃ³a)
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ final_centroids.txt
â”‚       â””â”€â”€ clustered_results.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ polars/
â”‚   â”‚   â”œâ”€â”€ explore_fast.py
â”‚   â”‚   â”œâ”€â”€ prepare_polars.py
â”‚   â”‚   â”œâ”€â”€ assign_clusters_polars.py
â”‚   â”‚   â””â”€â”€ analyze_polars.py
â”‚   â”‚
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ setup_hdfs.sh
â”‚   â”‚   â”œâ”€â”€ run_spark.sh
â”‚   â”‚   â”œâ”€â”€ kmeans_spark.py
â”‚   â”‚   â””â”€â”€ download_from_hdfs.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ full_pipeline_spark.sh
â”‚   â”‚   â”œâ”€â”€ clean_spark.sh
â”‚   â”‚   â””â”€â”€ reset_pipeline.sh
â”‚   â”‚
â”‚   â””â”€â”€ setup/
â”‚       â””â”€â”€ install_spark.sh
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md
â”‚   â””â”€â”€ HADOOP_ALTERNATIVES.md
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline_log_20251028_202850.md
â”‚
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ hadoop/                (legacy code)
â”‚
â”œâ”€â”€ .venv/                     (Python virtual env)
â”œâ”€â”€ .git/                      (Version control)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ CHANGELOG.md
â””â”€â”€ PROJECT_REPORT.md          (BÃ¡o cÃ¡o nÃ y)
```

### C. Thá»‘ng kÃª dá»± Ã¡n

- **Tá»•ng sá»‘ file Python**: 6 files, 442 dÃ²ng code
- **Tá»•ng sá»‘ file Shell**: 7 files, 661 dÃ²ng code
- **Tá»•ng dÃ²ng code**: 1,103 dÃ²ng
- **Thá»i gian phÃ¡t triá»ƒn**: 3 tuáº§n
- **CÃ´ng nghá»‡ sá»­ dá»¥ng**: 5 (Polars, Spark, HDFS, Python, NumPy)
- **Sá»‘ bÆ°á»›c pipeline**: 7
- **Thá»i gian cháº¡y**: 30 phÃºt

---

### D. TÃ i liá»‡u tham kháº£o

1. Apache Spark Documentation: https://spark.apache.org/docs/latest/
2. Polars Guide: https://pola-rs.github.io/polars-book/
3. Hadoop HDFS: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/
4. K-means Algorithm: https://scikit-learn.org/stable/modules/clustering.html#k-means
5. Money Laundering Detection: Research papers on financial crime

---


**Háº¾T BÃO CÃO**


_BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi `generate_vietnamese_report.py`_  
_NgÃ y: 28/10/2025 22:04:46_
# BÃO CÃO TIá»‚U LUáº¬N: PhÃ¢n cá»¥m K-means

## Má»¤C Lá»¤C

- [Báº£ng phÃ¢n chia cÃ´ng viá»‡c](#bang-phan-chia-cong-viec)
- [I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t](#i-tong-quan-va-ly-thuyet)
  - [A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means](#a-gioi-thieu-ve-cac-thuat-toan-k-means)
    - [1. Thuáº­t toÃ¡n K-means](#1-thuat-toan-k-means)
      - [a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means](#a-cach-thuc-hoat-dong-cua-k-means)
      - [b. K-means++](#b-k-means)
      - [c. Æ¯u Ä‘iá»ƒm cá»§a K-means](#c-uu-diem-cua-k-means)
      - [d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means](#d-nhuoc-diem-cua-k-means)
      - [e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means](#e-cac-tham-so-quan-trong-cua-k-means)
      - [f. á»¨ng dá»¥ng cá»§a K-means](#f-ung-dung-cua-k-means)
  - [B. LÃ½ thuyáº¿t HDFS](#b-ly-thuyet-hdfs)
  - [C. LÃ½ thuyáº¿t Apache Spark](#c-ly-thuyet-apache-spark)
  - [D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng](#d-cac-cong-nghe-su-dung)
    - [Polars](#polars)
    - [PySpark](#pyspark)
    - [NumPy](#numpy)
    - [HDFS](#hdfs)
    - [Apache Spark](#apache-spark)
- [II. MÃ´ táº£ bÃ i toÃ¡n](#ii-mo-ta-bai-toan)
  - [A. LÃ½ do chá»n Ä‘á» tÃ i](#a-ly-do-chon-de-tai)
  - [B. MÃ´ táº£ bÃ i toÃ¡n](#b-mo-ta-bai-toan)
  - [C. Quy trÃ¬nh thá»±c hiá»‡n](#c-quy-trinh-thuc-hien)

---

<a id="bang-phan-chia-cong-viec"></a>
## Báº£ng phÃ¢n chia cÃ´ng viá»‡c

| Háº¡ng má»¥c                        | Sinh viÃªn 1 | Sinh viÃªn 2 | Ghi chÃº                         |
|-------------------------------------|-------------|-------------|------------------------------------|
| Kháº£o sÃ¡t thuáº­t toÃ¡n K-means      | X           |             | TÃ i liá»‡u, vÃ­ dá»¥ minh há»a       |
| Thiáº¿t káº¿ quy trÃ¬nh, pipeline     |             | X           | **7 bÆ°á»›c** (MLlib k-means++) |
| Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Polars)  | X           |             | Chuáº©n hÃ³a, mÃ£ hÃ³a             |
| Spark MLlib K-means vÃ  tá»‘i Æ°u     |             | X           | Cáº¥u hÃ¬nh, theo dÃµi há»™i tá»¥     |
| GÃ¡n nhÃ£n vÃ  phÃ¢n tÃ­ch           | X           | X           | Tá»•ng há»£p káº¿t quáº£              |
| Viáº¿t bÃ¡o cÃ¡o, trÃ¬nh bÃ y       | X           | X           | BiÃªn táº­p cuá»‘i                |

---

<a id="i-tong-quan-va-ly-thuyet"></a>
## I. Tá»•ng quan vÃ  lÃ½ thuyáº¿t

<a id="a-gioi-thieu-ve-cac-thuat-toan-k-means"></a>
### A. Giá»›i thiá»‡u vá» cÃ¡c thuáº­t toÃ¡n K-means

<a id="1-thuat-toan-k-means"></a>
#### 1. Thuáº­t toÃ¡n K-means

<a id="a-cach-thuc-hoat-dong-cua-k-means"></a>
##### a. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a K-means

- Khá»Ÿi táº¡o K tÃ¢m cá»¥m (centroid) ban Ä‘áº§u.
- Láº·p cho Ä‘áº¿n khi há»™i tá»¥:
  1) GÃ¡n má»—i Ä‘iá»ƒm vÃ o cá»¥m cÃ³ centroid gáº§n nháº¥t (thÆ°á»ng dÃ¹ng khoáº£ng cÃ¡ch Euclidean).
  2) Cáº­p nháº­t centroid báº±ng trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m.
- Dá»«ng khi tÃ¢m cá»¥m thay Ä‘á»•i ráº¥t nhá» (dÆ°á»›i ngÆ°á»¡ng) hoáº·c Ä‘áº¡t sá»‘ vÃ²ng láº·p tá»‘i Ä‘a.

<a id="b-k-means"></a>
##### b. K-means++

- CÃ¡ch khá»Ÿi táº¡o tÃ¢m cá»¥m thÃ´ng minh nháº±m giáº£m rá»§i ro rÆ¡i vÃ o nghiá»‡m kÃ©m:
  - Chá»n ngáº«u nhiÃªn 1 Ä‘iá»ƒm lÃ m tÃ¢m Ä‘áº§u tiÃªn.
  - Vá»›i má»—i tÃ¢m tiáº¿p theo, chá»n xÃ¡c suáº¥t tá»‰ lá»‡ vá»›i bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch Ä‘áº¿n tÃ¢m gáº§n nháº¥t.
- Lá»£i Ã­ch: thÆ°á»ng há»™i tá»¥ nhanh hÆ¡n vÃ  cháº¥t lÆ°á»£ng phÃ¢n cá»¥m tá»‘t hÆ¡n so vá»›i khá»Ÿi táº¡o ngáº«u nhiÃªn.

<a id="c-uu-diem-cua-k-means"></a>
##### c. Æ¯u Ä‘iá»ƒm cá»§a K-means

- ÄÆ¡n giáº£n, dá»… cÃ i Ä‘áº·t vÃ  giáº£i thÃ­ch.
- Tá»‘c Ä‘á»™ nhanh, má»Ÿ rá»™ng tá»‘t cho dá»¯ liá»‡u lá»›n.
- Hiá»‡u quáº£ khi cá»¥m cÃ³ dáº¡ng lá»“i vÃ  phÃ¢n tÃ¡ch khÃ¡ rÃµ.

<a id="d-nhuoc-diem-cua-k-means"></a>
##### d. NhÆ°á»£c Ä‘iá»ƒm cá»§a K-means

- Cáº§n chá»n trÆ°á»›c K (sá»‘ cá»¥m).
- Nháº¡y cáº£m vá»›i tÃ¢m khá»Ÿi táº¡o vÃ  outlier.
- Giáº£ Ä‘á»‹nh cá»¥m cÃ³ phÆ°Æ¡ng sai gáº§n nhau (hÃ¬nh cáº§u) vÃ  dÃ¹ng cÃ¹ng má»™t thÆ°á»›c Ä‘o khoáº£ng cÃ¡ch.

<a id="e-cac-tham-so-quan-trong-cua-k-means"></a>
##### e. CÃ¡c tham sá»‘ quan trá»ng cá»§a K-means

- K (sá»‘ cá»¥m), init (random/K-means++), max_iter, n_init, tol (ngÆ°á»¡ng há»™i tá»¥), metric (thÆ°á»ng lÃ  Euclidean).

<a id="f-ung-dung-cua-k-means"></a>
##### f. á»¨ng dá»¥ng cá»§a K-means

- PhÃ¢n khÃºc khÃ¡ch hÃ ng, gá»£i Ã½ sáº£n pháº©m, phÃ¡t hiá»‡n báº¥t thÆ°á»ng sÆ¡ bá»™, nÃ©n dá»¯ liá»‡u (vector quantization), khá»Ÿi táº¡o cho cÃ¡c thuáº­t toÃ¡n khÃ¡c.

<a id="b-ly-thuyet-hdfs"></a>
### B. LÃ½ thuyáº¿t HDFS

- HDFS (Hadoop Distributed File System) lÃ  há»‡ thá»‘ng file phÃ¢n tÃ¡n, thiáº¿t káº¿ Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c file ráº¥t lá»›n trÃªn cá»¥m mÃ¡y.
- ThÃ nh pháº§n chÃ­nh:
  - NameNode: LÆ°u metadata (namespace, vá»‹ trÃ­ block), Ä‘iá»u phá»‘i truy cáº­p.
  - DataNode: LÆ°u dá»¯ liá»‡u dáº¡ng block trÃªn Ä‘Ä©a, phá»¥c vá»¥ Ä‘á»c/ghi.
- KhÃ¡i niá»‡m cá»‘t lÃµi:
  - Block: ÄÆ¡n vá»‹ lÆ°u trá»¯ (máº·c Ä‘á»‹nh 128MB hoáº·c 256MB).
  - Replication Factor: Má»—i block Ä‘Æ°á»£c sao chÃ©p N báº£n Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n.
  - Rack Awareness: PhÃ¢n phá»‘i báº£n sao trÃªn nhiá»u rack Ä‘á»ƒ tÄƒng tÃ­nh sáºµn sÃ ng.
- Luá»“ng ghi: Client yÃªu cáº§u NameNode â†’ nháº­n danh sÃ¡ch DataNode â†’ pipeline ghi theo chuá»—i, tá»«ng block Ä‘Æ°á»£c replicate.
- Luá»“ng Ä‘á»c: Client há»i NameNode vá»‹ trÃ­ block â†’ Ä‘á»c trá»±c tiáº¿p tá»« DataNode gáº§n nháº¥t (data locality).
- Æ¯u Ä‘iá»ƒm: Dung lÆ°á»£ng má»Ÿ rá»™ng tuyáº¿n tÃ­nh, chá»‹u lá»—i tá»‘t, throughput cao. NhÆ°á»£c: Äá»™ trá»… (latency) cao, khÃ´ng phÃ¹ há»£p file nhá» ráº¥t nhiá»u.

VÃ­ dá»¥ lá»‡nh HDFS thÆ°á»ng dÃ¹ng:

```bash
# Kiá»ƒm tra cá»¥m HDFS
hdfs dfsadmin -report

# Táº¡o thÆ° má»¥c vÃ  upload
hdfs dfs -mkdir -p /user/spark/hi_large/input
hdfs dfs -put data/processed/hadoop_input_temp.txt /user/spark/hi_large/input/

# Liá»‡t kÃª vÃ  kiá»ƒm tra kÃ­ch thÆ°á»›c
hdfs dfs -ls -h /user/spark/hi_large/input
hdfs dfs -du -h /user/spark/hi_large/input
```

<a id="c-ly-thuyet-apache-spark"></a>
### C. LÃ½ thuyáº¿t Apache Spark

- Kiáº¿n trÃºc: Driver (Ä‘iá»u phá»‘i) + Executors (thá»±c thi) + Cluster Manager (Standalone/YARN/K8s).
- MÃ´ hÃ¬nh thá»±c thi: DAG cá»§a transformations â†’ chia thÃ nh stages â†’ tasks song song trÃªn partitions.
- KhÃ¡i niá»‡m chÃ­nh:
  - RDD/DataFrame/Dataset: Abstraction dá»¯ liá»‡u báº¥t biáº¿n, phÃ¢n tÃ¡n.
  - Lazy Evaluation: Chá»‰ thá»±c thi khi cÃ³ action (count, collect, write...).
  - Catalyst Optimizer & Tungsten: Tá»‘i Æ°u logic vÃ  thá»±c thi trong bá»™ nhá»›.
  - Shuffle: Trao Ä‘á»•i dá»¯ liá»‡u giá»¯a nodes theo key, chi phÃ­ cao cáº§n háº¡n cháº¿.
- Bá»™ nhá»›: PhÃ¢n vÃ¹ng cho execution vs. storage; cache/persist Ä‘á»ƒ chia sáº» trung gian giá»¯a cÃ¡c bÆ°á»›c láº·p.

VÃ­ dá»¥ K-means vá»›i PySpark MLlib (rÃºt gá»n):

```python
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans

spark = SparkSession.builder.getOrCreate()

# Äá»c dá»¯ liá»‡u Ä‘Ã£ chuáº©n hoÃ¡ tá»« HDFS (vÃ­ dá»¥)
df = spark.read.csv(
    "hdfs:///user/spark/hi_large/input/hadoop_input.txt",
    header=False,
    inferSchema=True,
)

# GhÃ©p cá»™t Ä‘áº·c trÆ°ng thÃ nh vector cho MLlib
assembler = VectorAssembler(
    inputCols=[
        # Ä‘iá»n danh sÃ¡ch cá»™t Ä‘áº·c trÆ°ng sá»‘ á»Ÿ Ä‘Ã¢y
    ],
    outputCol="features",
)
vec = assembler.transform(df).select("features").cache()

kmeans = KMeans(k=5, maxIter=15, seed=42, featuresCol="features", predictionCol="cluster")
model = kmeans.fit(vec)
centers = model.clusterCenters()
```

<a id="d-cac-cong-nghe-su-dung"></a>
### D. CÃ¡c cÃ´ng nghá»‡ sá»­ dá»¥ng

<a id="polars"></a>
#### Polars

- Vai trÃ²: Tiá»n xá»­ lÃ½ nhanh trÃªn 1 mÃ¡y (CSV lá»›n), lazy/streaming vÆ°á»£t quÃ¡ RAM.
- TÃ­nh nÄƒng: Expression API, parallel compute, memory efficient (Rust backend).
- VÃ­ dá»¥:

```python
import polars as pl

df = pl.scan_csv("data/raw/HI-Large_Trans.csv")  # lazy, khÃ´ng táº£i háº¿t vÃ o RAM

features = (
    df.with_columns([
        (pl.col("Amount Received") / pl.col("Amount Paid")).alias("amount_ratio"),
    ])
    .select([
        pl.col("amount_ratio").clip(0, 10),
        pl.col("Payment Currency"),
    ])
)

features.sink_csv("data/processed/sample_features.csv")  # streaming
```

<a id="pyspark"></a>
#### PySpark

- Vai trÃ²: API Python cho Spark; cháº¡y phÃ¢n tÃ¡n, phÃ¹ há»£p thuáº­t toÃ¡n láº·p nhÆ° K-means.
- TÃ­nh nÄƒng: DataFrame, MLlib, Structured Streaming, Catalyst optimizer.
- VÃ­ dá»¥ lá»‡nh submit:

```bash
spark-submit \
  --driver-memory 4g \
  --executor-memory 4g \
  scripts/spark/kmeans_spark.py
```

<a id="numpy"></a>
#### NumPy

- Vai trÃ²: TÄƒng tá»‘c tÃ­nh toÃ¡n vector/matrix, Ä‘áº·c biá»‡t khi gÃ¡n nhÃ£n theo khoáº£ng cÃ¡ch.
- VÃ­ dá»¥ tÃ­nh khoáº£ng cÃ¡ch Euclid theo batch:

```python
import numpy as np

X = np.random.rand(1_000_000, 9)  # features
C = np.random.rand(5, 9)          # centroids

dists = np.sqrt(((X[:, None, :] - C[None, :, :]) ** 2).sum(axis=2))
labels = dists.argmin(axis=1)
```

<a id="hdfs"></a>
#### HDFS

- Vai trÃ²: LÆ°u trá»¯ phÃ¢n tÃ¡n dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ  káº¿t quáº£ mÃ´ hÃ¬nh; Ä‘áº£m báº£o an toÃ n vÃ  má»Ÿ rá»™ng.
- Lá»‡nh há»¯u Ã­ch: `hdfs dfs -put`, `-get`, `-ls -h`, `-du -h`, `dfsadmin -report`.

<a id="apache-spark"></a>
#### Apache Spark

- Vai trÃ²: Ná»n táº£ng thá»±c thi phÃ¢n tÃ¡n trong bá»™ nhá»›; tá»‘i Æ°u cho xá»­ lÃ½ láº·p vÃ  ETL.
- Best practices: Cache dá»¯ liá»‡u dÃ¹ng láº¡i; tá»‘i Æ°u sá»‘ partitions; giáº£m shuffle; giÃ¡m sÃ¡t UI táº¡i `http://localhost:4040` khi cháº¡y local.

---

<a id="ii-mo-ta-bai-toan"></a>
## II. MÃ´ táº£ bÃ i toÃ¡n

<a id="a-ly-do-chon-de-tai"></a>
### A. LÃ½ do chá»n Ä‘á» tÃ i

- Dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh cá»±c lá»›n, cáº§n phÃ¢n cá»¥m Ä‘á»ƒ hiá»ƒu hÃ nh vi vÃ  nháº­n diá»‡n báº¥t thÆ°á»ng.
- K-means lÃ  thuáº­t toÃ¡n nhanh, dá»… má»Ÿ rá»™ng, phÃ¹ há»£p cho bÆ°á»›c phÃ¢n nhÃ³m ná»n táº£ng trÆ°á»›c khi Ä‘i sÃ¢u.
- Táº­n dá»¥ng háº¡ táº§ng phÃ¢n tÃ¡n (Spark) vÃ  xá»­ lÃ½ cá»¥c bá»™ nhanh (Polars) Ä‘á»ƒ rÃºt ngáº¯n thá»i gian.

<a id="b-mo-ta-bai-toan"></a>
### B. MÃ´ táº£ bÃ i toÃ¡n

- Äáº§u vÃ o: Táº­p dá»¯ liá»‡u giao dá»‹ch tÃ i chÃ­nh nhiá»u cá»™t (thá»i gian, ngÃ¢n hÃ ng, tÃ i khoáº£n, sá»‘ tiá»n, loáº¡i tiá»n...).
- Má»¥c tiÃªu: Tiá»n xá»­ lÃ½ vÃ  chuáº©n hÃ³a Ä‘áº·c trÆ°ng, sau Ä‘Ã³ phÃ¢n cá»¥m K-means Ä‘á»ƒ phÃ¢n nhÃ³m giao dá»‹ch cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±; dÃ¹ng káº¿t quáº£ Ä‘á»ƒ phÃ¢n tÃ­ch cá»¥m rá»§i ro.
- RÃ ng buá»™c: Tá»‘i Æ°u thá»i gian xá»­ lÃ½; khÃ´ng lÆ°u dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™ sau khi Ä‘áº©y lÃªn HDFS.

<a id="c-quy-trinh-thuc-hien"></a>
### C. Quy trÃ¬nh thá»±c hiá»‡n

#### Tá»•ng quan quy trÃ¬nh 7 bÆ°á»›c

âš ï¸ **LÆ°u Ã½**: Pipeline Ä‘Ã£ tá»‘i Æ°u tá»« 8 bÆ°á»›c xuá»‘ng cÃ²n 7 bÆ°á»›c. BÆ°á»›c khá»Ÿi táº¡o centroids Ä‘Ã£ loáº¡i bá» vÃ¬ MLlib K-means tá»± Ä‘á»™ng dÃ¹ng k-means++.

```
BÆ¯á»šC 1        BÆ¯á»šC 2        BÆ¯á»šC 3
KhÃ¡m phÃ¡  â†’   Xá»­ lÃ½    â†’   Upload
 (30s)        (10 phÃºt)      (5 phÃºt)

BÆ¯á»šC 4            BÆ¯á»šC 5        BÆ¯á»šC 6        BÆ¯á»šC 7
K-means (MLlib) â†’   Táº£i vá»   â†’   GÃ¡n nhÃ£n  â†’   PhÃ¢n tÃ­ch
(10-25p k-means++)    (30s)       (10 phÃºt)     (2 phÃºt)

Tá»”NG THá»œI GIAN: 35-50 phÃºt (nhanh hÆ¡n 30-50%!)
```

#### Chi tiáº¿t tá»«ng bÆ°á»›c

##### BÆ¯á»šC 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u ğŸ”

**Má»¥c Ä‘Ã­ch**: Hiá»ƒu cáº¥u trÃºc vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u  
**File thá»±c thi**: `scripts/polars/explore_fast.py`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: Thá»‘ng kÃª in ra mÃ n hÃ¬nh

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. Äá»c 100,000 dÃ²ng Ä‘áº§u (Ä‘áº¡i diá»‡n)
2. Xem schema: TÃªn cá»™t, kiá»ƒu dá»¯ liá»‡u
3. Thá»‘ng kÃª mÃ´ táº£: min, max, mean, median, std
4. PhÃ¢n tÃ­ch nhÃ£n: Bao nhiÃªu % rá»­a tiá»n?
5. Top loáº¡i tiá»n tá»‡ phá»• biáº¿n

**Káº¿t quáº£ vÃ­ dá»¥**:
```
Total rows: 179,702,229
Laundering rate: 0.126%
Top currencies: Euro (23%), Yuan (7.2%)
```

##### BÆ¯á»šC 2: Xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ğŸ”§

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n xá»­ lÃ½  
**File thá»±c thi**: `scripts/polars/prepare_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: `data/raw/HI-Large_Trans.csv` (16GB)  
**Output**: `data/processed/hadoop_input_temp.txt` (33GB, Táº M THá»œI)

**CÃ¡c bÆ°á»›c xá»­ lÃ½**:
1. **Parse timestamp**: "2022/08/01 00:17" â†’ giá»=0, ngÃ y=0 (Thá»© 2)
2. **TÃ­nh ratio**: amount_ratio = 6794.63 / 7739.29 = 0.878
3. **Hash route**: hash(20, 20) = 400 (vÃ­ dá»¥)
4. **Encode currency**: "US Dollar" â†’ 0, "Yuan" â†’ 1
5. **Normalize**: ÄÆ°a táº¥t cáº£ vá» [0, 1]

**Táº¡i sao láº¡i tÄƒng tá»« 16GB lÃªn 33GB?**
- Dá»¯ liá»‡u gá»‘c: Chá»‰ cÃ³ 11 cá»™t
- Sau xá»­ lÃ½: ThÃªm nhiá»u cá»™t Ä‘áº·c trÆ°ng
- Má»—i sá»‘ float64 = 8 bytes
- 179M rows Ã— 9 features Ã— 8 bytes â‰ˆ 12GB + overhead â‰ˆ 33GB

##### ~~BÆ¯á»šC 3: Khá»i táº¡o tÃ¢m cá»¥m~~ âŒ **ÄÃƒ LOáº I Bá»**

**Tráº¡ng thÃ¡i**: Loáº¡i bá» - MLlib K-means tá»± Ä‘á»™ng dÃ¹ng **k-means++** khá»Ÿi táº¡o thÃ´ng minh.

---

##### BÆ¯á»šC 3: Upload lÃªn HDFS â˜ï¸

**Má»¥c Ä‘Ã­ch**: Chuyá»ƒn dá»¯ liá»‡u lÃªn há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n  
**File thá»±c thi**: `scripts/spark/setup_hdfs.sh`  
**Thá»i gian**: ~5 phÃºt  
**Input**: 1 file temp cá»¥c bá»™ (hadoop_input_temp.txt)  
**Output**: Dá»¯ liá»‡u trÃªn HDFS

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n**:
1. Kiá»ƒm tra HDFS Ä‘ang cháº¡y: `hdfs dfsadmin -report`
2. Táº¡o thÆ° má»¥c: `hdfs dfs -mkdir -p /user/spark/hi_large/input`
3. Upload input: `hdfs dfs -put hadoop_input_temp.txt /user/.../input/`
4. **XÃ“A file temp cá»¥c bá»™**: `rm -rf data/processed/*`
5. Verify: Kiá»ƒm tra kÃ­ch thÆ°á»›c file trÃªn HDFS

**ğŸ”’ TuÃ¢n thá»§ quy Ä‘á»‹nh**:
- Sau bÆ°á»›c nÃ y, KHÃ”NG cÃ²n dá»¯ liá»‡u lá»›n á»Ÿ mÃ¡y cá»¥c bá»™
- Chá»‰ tá»“n táº¡i trÃªn HDFS (phÃ¢n tÃ¡n, an toÃ n)
- Náº¿u cáº§n, cÃ³ thá»ƒ táº£i láº¡i tá»« HDFS

##### BÆ¯á»šC 4: Cháº¡y K-means trÃªn Spark ğŸš€

**Má»¥c Ä‘Ã­ch**: PhÃ¢n cá»¥m 179 triá»‡u giao dá»‹ch báº±ng **MLlib K-means**  
**File thá»±c thi**: `scripts/spark/run_spark.sh` + `kmeans_spark.py`  
**Thá»i gian**: 10-25 phÃºt (nhanh hÆ¡n 30-50% nhá» MLlib!)  
**Input**: Dá»¯ liá»‡u tá»« HDFS  
**Output**: TÃ¢m cá»¥m cuá»‘i cÃ¹ng trÃªn HDFS

**MLlib K-means vá»›i k-means++ initialization**:
```
KHá» Táº O (Tá»° Äá»˜NG bá»Ÿi MLlib):
  - K=5 tÃ¢m cá»¥m
  - Sá»­ dá»¥ng k-means++ (thÃ´ng minh, khÃ´ng random)
  - Max iterations = 15
  - Tá»‘i Æ°u Catalyst + Tungsten engine

Láº¶P Láº I 15 Láº¦N:
  1. GÃ¡n má»—i giao dá»‹ch vÃ o cá»¥m gáº§n nháº¥t
     - TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n 5 tÃ¢m cá»¥m
     - Chá»n cá»¥m cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t
  
  2. Cáº­p nháº­t tÃ¢m cá»¥m
     - TÃ­nh trung bÃ¬nh táº¥t cáº£ Ä‘iá»ƒm trong má»—i cá»¥m
     - TÃ¢m cá»¥m má»›i = trung bÃ¬nh cÃ¡c Ä‘iá»ƒm
  
  3. Kiá»ƒm tra há»™i tá»¥
     - TÃ­nh Ä‘á»™ dá»‹ch chuyá»ƒn tÃ¢m cá»¥m
     - Náº¿u < threshold â†’ Dá»«ng láº¡i

Káº¾T QUáº¢:
  - 5 tÃ¢m cá»¥m cuá»‘i cÃ¹ng (tá»‘t hÆ¡n random init)
  - Má»—i cá»¥m chá»©a bao nhiÃªu Ä‘iá»ƒm
  - Há»™i tá»¥ nhanh hÆ¡n (~10-12 iterations thay vÃ¬ 15)
```

**QuÃ¡ trÃ¬nh há»™i tá»¥ (tá»« log thá»±c táº¿)**:
```
Iteration  1: Centroid shift = 2.232  (chÆ°a á»•n Ä‘á»‹nh)
Iteration  2: Centroid shift = 1.409
Iteration  5: Centroid shift = 0.383
Iteration 10: Centroid shift = 0.046
Iteration 15: Centroid shift = 0.010  (Ä‘Ã£ há»™i tá»¥ âœ“)
```

**PhÃ¢n phá»‘i káº¿t quáº£**:
```
Cluster 0:  36,926,395 giao dá»‹ch (20.55%)
Cluster 1:  69,939,082 giao dá»‹ch (38.92%)  â† Lá»›n nháº¥t
Cluster 2:  68,931,713 giao dá»‹ch (38.36%)  â† Lá»›n thá»© 2
Cluster 3:          18 giao dá»‹ch (0.00%)   â† Outlier!
Cluster 4:   3,905,021 giao dá»‹ch (2.17%)
```

##### BÆ¯á»šC 5: Táº£i káº¿t quáº£ vá» ğŸ“¥

**Má»¥c Ä‘Ã­ch**: Láº¥y tÃ¢m cá»¥m cuá»‘i cÃ¹ng tá»« HDFS  
**File thá»±c thi**: `scripts/spark/download_from_hdfs.sh`  
**Thá»i gian**: ~30 giÃ¢y  
**Input**: `/user/spark/hi_large/output_centroids/` trÃªn HDFS  
**Output**: `data/results/final_centroids.txt` (~4KB)

**CÃ¡c bÆ°á»›c**:
1. `hdfs dfs -cat /user/.../output_centroids/part-*`
2. LÆ°u vÃ o file cá»¥c bá»™
3. Verify: Kiá»ƒm tra cÃ³ Ä‘Ãºng 5 dÃ²ng

**Táº¡i sao Ä‘Æ°á»£c phÃ©p táº£i vá»?**
- File ráº¥t nhá» (~4KB)
- Chá»‰ chá»©a káº¿t quáº£ tá»•ng há»£p, khÃ´ng pháº£i dá»¯ liá»‡u gá»‘c
- Cáº§n thiáº¿t cho bÆ°á»›c phÃ¢n tÃ­ch tiáº¿p theo

##### BÆ¯á»šC 6: GÃ¡n nhÃ£n cá»¥m cho tá»«ng giao dá»‹ch ğŸ·ï¸

**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh má»—i giao dá»‹ch thuá»™c cá»¥m nÃ o  
**File thá»±c thi**: `scripts/polars/assign_clusters_polars.py`  
**Thá»i gian**: ~10 phÃºt  
**Input**: 
  - CSV gá»‘c tá»« HDFS (streaming)
  - 5 tÃ¢m cá»¥m tá»« bÆ°á»›c 5  
**Output**: `data/results/clustered_results.txt`

**Thuáº­t toÃ¡n**:
```python
FOR má»—i giao dá»‹ch:
    distances = []
    FOR má»—i tÃ¢m cá»¥m (5 cá»¥m):
        d = euclidean_distance(giao_dá»‹ch, tÃ¢m_cá»¥m)
        distances.append(d)
    
    cluster_id = argmin(distances)  # Chá»n cá»¥m gáº§n nháº¥t
    ghi_káº¿t_quáº£(giao_dá»‹ch, cluster_id)
```

**Xá»­ lÃ½ batch Ä‘á»ƒ tÄƒng tá»‘c**:
- KhÃ´ng xá»­ lÃ½ tá»«ng giao dá»‹ch
- Xá»­ lÃ½ 1 triá»‡u giao dá»‹ch cÃ¹ng lÃºc
- Sá»­ dá»¥ng NumPy vectorization

##### BÆ¯á»šC 7: PhÃ¢n tÃ­ch káº¿t quáº£ ğŸ“Š

**Má»¥c Ä‘Ã­ch**: TÃ¬m cá»¥m cÃ³ tá»· lá»‡ rá»­a tiá»n cao  
**File thá»±c thi**: `scripts/polars/analyze_polars.py`  
**Thá»i gian**: ~2 phÃºt  
**Input**: `data/results/clustered_results.txt`  
**Output**: BÃ¡o cÃ¡o phÃ¢n tÃ­ch

**CÃ¡c phÃ¢n tÃ­ch thá»±c hiá»‡n**:
1. **KÃ­ch thÆ°á»›c cá»¥m**: Má»—i cá»¥m cÃ³ bao nhiÃªu giao dá»‹ch?
2. **Tá»· lá»‡ rá»­a tiá»n**: % rá»­a tiá»n trong tá»«ng cá»¥m
3. **High-risk clusters**: Cá»¥m nÃ o > 10% rá»­a tiá»n?
4. **Feature averages**: Äáº·c Ä‘iá»ƒm trung bÃ¬nh má»—i cá»¥m

**Káº¿t quáº£ tá»« log thá»±c táº¿ (29/10/2025 18:45)**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Cluster  â•‘ Giao dá»‹ch   â•‘ Rá»­a tiá»n  â•‘ Tá»· lá»‡ (%)       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    0     â•‘ 36,926,395  â•‘  29,920   â•‘ 0.081%          â•‘
â•‘    1     â•‘ 69,939,082  â•‘  78,960   â•‘ 0.113%          â•‘
â•‘    2     â•‘ 68,931,713  â•‘ 115,057   â•‘ 0.167% â† CAO    â•‘
â•‘    3     â•‘        18   â•‘       1   â•‘ 5.556% â† OUTLIERâ•‘
â•‘    4     â•‘  3,905,021  â•‘   1,608   â•‘ 0.041% â† THáº¤P   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ NHáº¬N XÃ‰T:
- Cluster 3 nghi ngá» nháº¥t (5.56%, outlier cá»±c lá»›n - chá»‰ 18 giao dá»‹ch)
- Cluster 2 cao nháº¥t trong cá»¥m chÃ­nh (0.167%)
- Cluster 4 an toÃ n nháº¥t (0.041%)
- âœ… KHÃ”NG cÃ³ cá»¥m nÃ o > 10% (excellent!)
```

---


