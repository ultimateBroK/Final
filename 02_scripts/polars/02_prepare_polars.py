#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BÆ¯á»šC 2: Xá»¬ LÃ VÃ€ TRÃCH XUáº¤T Äáº¶C TRÆ¯NG (FEATURE ENGINEERING)

Má»¥c Ä‘Ã­ch:
- Chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ thuáº­t toÃ¡n K-means xá»­ lÃ½
- TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« timestamp (giá», ngÃ y trong tuáº§n)
- TÃ­nh toÃ¡n cÃ¡c tá»· lá»‡ (amount_ratio)
- MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i (categorical encoding)
- Chuáº©n hÃ³a táº¥t cáº£ features vá» [0, 1]

Thá»i gian cháº¡y: ~10 phÃºt
Input: 01_data/raw/HI-Large_Trans.csv (16GB, 179M dÃ²ng)
Output: 01_data/processed/hadoop_input_temp.txt (33GB, Táº M THá»œI)

âš ï¸  LÆ¯U Ã: File output sáº½ Bá»Š XÃ“A Tá»° Äá»˜NG sau khi upload lÃªn HDFS!
Tham sá»‘ CLI:
- --raw <path>: ÄÆ°á»ng dáº«n CSV Ä‘áº§u vÃ o
- --out-dir <dir>: ThÆ° má»¥c output processed (máº·c Ä‘á»‹nh 01_data/processed)
"""

import polars as pl
import numpy as np
import os
import time
from datetime import datetime
import argparse

# ==================== Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ====================
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))

def parse_args():
    parser = argparse.ArgumentParser(description="Chuáº©n bá»‹ dá»¯ liá»‡u cho K-means (Polars)")
    parser.add_argument("--raw", type=str, default=None, help="ÄÆ°á»ng dáº«n CSV Ä‘áº§u vÃ o")
    parser.add_argument("--out-dir", type=str, default=None, help="ThÆ° má»¥c output processed")
    return parser.parse_args()

args = parse_args()

DATA_RAW = args.raw or os.path.join(ROOT_DIR, '01_data', 'raw', 'HI-Large_Trans.csv')
DATA_PROCESSED = args.out_dir or os.path.join(ROOT_DIR, '01_data', 'processed')

# Táº¡o thÆ° má»¥c processed náº¿u chÆ°a cÃ³ vÃ  kiá»ƒm tra input
os.makedirs(DATA_PROCESSED, exist_ok=True)
if not os.path.isfile(DATA_RAW):
    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file: {DATA_RAW}")

def log_with_time(msg, step_start=None):
    """In message vá»›i timestamp vÃ  thá»i gian elapsed náº¿u cÃ³"""
    current_time = datetime.now().strftime("%H:%M:%S")
    if step_start:
        elapsed = time.time() - step_start
        print(f"[{current_time}] {msg} (máº¥t {elapsed:.1f}s)")
    else:
        print(f"[{current_time}] {msg}")

PIPELINE_START = time.time()

print("="*70)
print("BÆ¯á»šC 2: Xá»¬ LÃ VÃ€ TRÃCH XUáº¤T Äáº¶C TRÆ¯NG ğŸ”§")
print("="*70)
log_with_time(f"Äá»c tá»‡p: {DATA_RAW}")
log_with_time("Vui lÃ²ng Ä‘á»£i (cÃ³ thá»ƒ máº¥t 5-10 phÃºt)...")
print()

# ==================== Äá»ŒC Dá»® LIá»†U ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.1/6: Äang thiáº¿t láº­p Ä‘á»c trÃ¬ hoÃ£n (khÃ´ng táº£i toÃ n bá»™)...")
# Scan_csv = Lazy loading (khÃ´ng load háº¿t vÃ o RAM)
# Polars sáº½ xá»­ lÃ½ tá»«ng batch vÃ  streaming ra disk
df = pl.scan_csv(DATA_RAW)

log_with_time("ÄÃ£ thiáº¿t láº­p Ä‘á»c trÃ¬ hoÃ£n (khÃ´ng tá»‘n RAM)", step_start)
print()

# ==================== TRÃCH XUáº¤T Äáº¶C TRÆ¯NG ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.2/6: Äang trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u thÃ´...")
log_with_time("   â”œâ”€ Timestamp â†’ Giá», NgÃ y trong tuáº§n")
log_with_time("   â”œâ”€ Amount â†’ Received, Paid, Ratio")
log_with_time("   â”œâ”€ Route â†’ Hash(From Bank âŠ• To Bank)")
log_with_time("   â””â”€ Currencies â†’ Label encoding")

# Chá»n vÃ  táº¡o cÃ¡c Ä‘áº·c trÆ°ng má»›i
df_features = df.select([
    # === Äáº¶c trÆ°ng thá»i gian ===
    # Parse timestamp tá»« chuá»—i sang datetime
    pl.col('Timestamp').str.strptime(pl.Datetime, format='%Y/%m/%d %H:%M').alias('datetime'),
    
    # === Äáº·c trÆ°ng cÆ¡ báº£n ===
    # Sá»‘ tiá»n nháº­n Ä‘Æ°á»£c
    pl.col('Amount Received').alias('amount_received'),
    # Sá»‘ tiá»n tráº£
    pl.col('Amount Paid').alias('amount_paid'),
    
    # === Äáº·c trÆ°ng tÃ­nh toÃ¡n ===
    # Tá»· lá»‡ tiá»n nháº­n / tiá»n tráº£ (+ 1e-6 Ä‘á»ƒ trÃ¡nh chia cho 0)
    # Náº¿u ratio báº¥t thÆ°á»ng (vÃ­ dá»¥ >>1) cÃ³ thá»ƒ lÃ  rá»­a tiá»n
    (pl.col('Amount Received') / (pl.col('Amount Paid') + 1e-6)).alias('amount_ratio'),
    
    # === Äáº·c trÆ°ng thá»i gian chi tiáº¿t ===
    # Giá» trong ngÃ y (0-23)
    # Rá»­a tiá»n thÆ°á»ng xáº£y ra vÃ o giá» khÃ´ng bÃ¬nh thÆ°á»ng
    pl.col('Timestamp').str.strptime(pl.Datetime, format='%Y/%m/%d %H:%M').dt.hour().alias('hour'),
    # NgÃ y trong tuáº§n (0=Thá»© 2, 6=Chá»§ nháº­t)
    pl.col('Timestamp').str.strptime(pl.Datetime, format='%Y/%m/%d %H:%M').dt.weekday().alias('day_of_week'),
    
    # === Äáº·c trÆ°ng tuyáº¿n Ä‘Æ°á»ng ===
    # Hash(From Bank XOR To Bank) = mÃ£ hÃ³a tuyáº¿n chuyá»ƒn tiá»n
    # PhÃ¡t hiá»‡n cÃ¡c tuyáº¿n láº·p láº¡i nghi ngá»
    (pl.col('From Bank').hash() ^ pl.col('To Bank').hash()).alias('route_hash'),
    
    # === Biáº¿n phÃ¢n loáº¡i (chÆ°a mÃ£ hÃ³a) ===
    pl.col('Receiving Currency').alias('recv_curr'),
    pl.col('Payment Currency').alias('payment_curr'),
    pl.col('Payment Format').alias('payment_format'),
])

log_with_time(f"ÄÃ£ trÃ­ch xuáº¥t {len(df_features.collect_schema().names())} Ä‘áº·c trÆ°ng", step_start)
print()

# ==================== MÃƒ HÃ“A BIáº¾N PHÃ‚N LOáº I ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.3/6: Äang mÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i...")
log_with_time("   â”œâ”€ Receiving Currency â†’ Sá»‘")
log_with_time("   â”œâ”€ Payment Currency â†’ Sá»‘")
log_with_time("   â””â”€ Payment Format â†’ Sá»‘")

# Label Encoding: Chuyá»ƒn chuá»—i thÃ nh sá»‘
# VÃ­ dá»¥: "US Dollar" -> 0, "Yuan" -> 1, "Euro" -> 2, ...
df_features = df_features.with_columns([
    pl.col('recv_curr').cast(pl.Categorical).to_physical().alias('recv_curr_encoded'),
    pl.col('payment_curr').cast(pl.Categorical).to_physical().alias('payment_curr_encoded'),
    pl.col('payment_format').cast(pl.Categorical).to_physical().alias('payment_format_encoded'),
])

log_with_time("ÄÃ£ mÃ£ hÃ³a thÃ nh sá»‘", step_start)
print()

# ==================== CHá»ŒN Äáº¶C TRÆ¯NG Sá» ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.4/6: Äang chá»n cÃ¡c Ä‘áº·c trÆ°ng sá»‘...")
# Chá»‰ giá»¯ láº¡i 9 Ä‘áº·c trÆ°ng sá»‘ (loáº¡i bá» chuá»—i)
df_numeric = df_features.select([
    'amount_received',      # Sá»‘ tiá»n nháº­n
    'amount_paid',          # Sá»‘ tiá»n tráº£
    'amount_ratio',         # Tá»· lá»‡
    'hour',                 # Giá»
    'day_of_week',          # NgÃ y trong tuáº§n
    'route_hash',           # MÃ£ tuyáº¿n
    'recv_curr_encoded',    # Loáº¡i tiá»n nháº­n (sá»‘)
    'payment_curr_encoded', # Loáº¡i tiá»n tráº£ (sá»‘)
    'payment_format_encoded', # HÃ¬nh thá»©c thanh toÃ¡n (sá»‘)
])

log_with_time(f"âœ… ÄÃ£ chá»n {len(df_numeric.collect_schema().names())} Ä‘áº·c trÆ°ng sá»‘ cho K-means", step_start)
feature_list = df_numeric.collect_schema().names()
for i, feat in enumerate(feature_list, 1):
    print(f"   {i}. {feat}")
print()

# ==================== CHUáº¨N HÃ“A (NORMALIZATION) ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.5/6: Äang chuáº©n hÃ³a dá»¯ liá»‡u (chuáº©n Z-score)...")
log_with_time("   CÃ´ng thá»©c: (x - mean) / std")
log_with_time("   Má»¥c Ä‘Ã­ch: ÄÆ°a táº¥t cáº£ features vá» cÃ¹ng scale")

# Chuáº©n hÃ³a: ÄÆ°a táº¥t cáº£ vá» khoáº£ng [0, 1]
# CÃ´ng thá»©c: (x - mean) / std
# LÃ½ do: CÃ¡c Ä‘áº·c trÆ°ng cÃ³ scale khÃ¡c nhau (tiá»n cÃ³ thá»ƒ hÃ ng triá»‡u, giá» chá»‰ 0-23)
# Náº¿u khÃ´ng chuáº©n hÃ³a, K-means sáº½ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi Ä‘áº·c trÆ°ng cÃ³ giÃ¡ trá»‹ lá»›n
df_normalized = df_numeric.select([
    ((pl.col(c) - pl.col(c).mean()) / pl.col(c).std()).alias(c)
    for c in df_numeric.collect_schema().names()
])

log_with_time(f"ÄÃ£ chuáº©n hÃ³a {len(df_normalized.collect_schema().names())} Ä‘áº·c trÆ°ng", step_start)
print()

# ==================== LÆ¯U FILE Táº M THá»œI ====================
step_start = time.time()
log_with_time("BÆ¯á»šC 2.6/6: Äang lÆ°u tá»‡p táº¡m thá»i cho HDFS...")
log_with_time("LÆ°u Ã½: Tá»‡p nÃ y sáº½ tá»± Ä‘á»™ng xÃ³a sau khi táº£i lÃªn HDFS!")

temp_output = os.path.join(DATA_PROCESSED, 'hadoop_input_temp.txt')
log_with_time(f"   Äang ghi: {temp_output}")
log_with_time("   Vui lÃ²ng Ä‘á»£i (cÃ³ thá»ƒ máº¥t 3-5 phÃºt)...")
log_with_time("   Polars Ä‘ang ghi luá»“ng dá»¯ liá»‡u xuá»‘ng Ä‘Ä©a (khÃ´ng tá»‘n RAM)")
print()

# Ghi file khÃ´ng cÃ³ header (chá»‰ cÃ³ sá»‘)
# Sink = streaming write (khÃ´ng tá»‘n RAM)
df_normalized.sink_csv(temp_output, include_header=False)

log_with_time("ÄÃ£ ghi xong tá»‡p", step_start)

file_size_mb = os.path.getsize(temp_output) / (1024 * 1024 * 1024)

total_time = time.time() - PIPELINE_START

print()
print("="*70)
log_with_time("HOÃ€N Táº¤T Xá»¬ LÃ Dá»® LIá»†U!")
print("="*70)
print()
print("THá»NG KÃŠ Káº¾T QUáº¢:")
print(f"   Tá»‡p táº¡m: {temp_output}")
print(f"   KÃ­ch thÆ°á»›c: {file_size_mb:.2f} GB")
print(f"   Sá»‘ dÃ²ng: [ghi luá»“ng - khÃ´ng Ä‘áº¿m]")
print(f"   Sá»‘ Ä‘áº·c trÆ°ng: {len(df_normalized.collect_schema().names())}")
print(f"   Danh sÃ¡ch Ä‘áº·c trÆ°ng:")
for i, feat in enumerate(df_normalized.collect_schema().names(), 1):
    print(f"      {i}. {feat}")
print()
log_with_time(f"Tá»•ng thá»i gian bÆ°á»›c 2: {total_time/60:.1f} phÃºt ({total_time:.1f}s)")
print()
print("LÆ¯U Ã QUAN TRá»ŒNG:")
print("   â”œâ”€ File nÃ y chá»‰ tá»“n táº¡i Táº M THá»œI!")
print("   â”œâ”€ NÃ³ sáº½ Bá»Š XÃ“A sau khi upload lÃªn HDFS (BÆ°á»›c 3)")
print("   â””â”€ Dá»¯ liá»‡u chá»‰ lÆ°u trÃªn HDFS Ä‘á»ƒ tuÃ¢n thá»§ quy Ä‘á»‹nh báº£o máº­t")
print()
print("Gá»¢I Ã TIáº¾P THEO:")
print("   Cháº¡y bÆ°á»›c 3: bash 02_scripts/spark/setup_hdfs.sh")
print("   (MLlib sáº½ tá»± Ä‘á»™ng dÃ¹ng k-means++ initialization)")
print()
