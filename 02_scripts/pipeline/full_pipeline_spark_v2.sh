#!/bin/bash
#
# üöÄ POLARS + PYSPARK K-MEANS PIPELINE - SI√äU VI·ªÜT EDITION
#
# M√¥ t·∫£: Pipeline t·ª± ƒë·ªông 7 b∆∞·ªõc x·ª≠ l√Ω 179 tri·ªáu giao d·ªãch (MLlib k-means++)
# T√°c gi·∫£: D·ª± √Ån Ph√¢n T√≠ch R·ª≠a Ti·ªÅn
# Version: 2.0 (Si√™u Vi·ªát Edition)
# Ng√†y: 2025-10-29
#
# S·ª≠ d·ª•ng:
#   ./02_scripts/pipeline/full_pipeline_spark_v2.sh [OPTIONS]
#
# OPTIONS:
#   --reset        Reset t·∫•t c·∫£ checkpoints v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu
#   --from-step N  B·∫Øt ƒë·∫ßu t·ª´ b∆∞·ªõc N
#   --skip-step N  B·ªè qua b∆∞·ªõc N
#   --dry-run      Ch·ªâ hi·ªÉn th·ªã k·∫ø ho·∫°ch, kh√¥ng ch·∫°y
#   --help         Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n
#

set -euo pipefail  # Exit on error, undefined vars, pipe failures

# ==================== C·∫§U H√åNH ====================
ROOT_DIR="$(cd "$(dirname "$0")/../.."; pwd)"
SCRIPTS_DIR="$ROOT_DIR/02_scripts"
LOGS_DIR="$ROOT_DIR/04_logs"
DATA_DIR="$ROOT_DIR/01_data"
SNAPSHOTS_DIR="$ROOT_DIR/05_snapshots"
VIZ_DIR="$ROOT_DIR/06_visualizations"
TOTAL_STEPS=7

# Flags
RESET_MODE=false
DRY_RUN=false
FROM_STEP=1
SKIP_STEPS=()
VERBOSE=true
SEED=""
K_OVERRIDE=""
MAX_ITER_OVERRIDE=""
z_OVERRIDE=""

# ==================== PARSE ARGUMENTS ====================
while [[ $# -gt 0 ]]; do
    case $1 in
        --reset)
            RESET_MODE=true
            shift
            ;;
        --from-step)
            FROM_STEP="$2"
            shift 2
            ;;
        --skip-step)
            SKIP_STEPS+=("$2")
            shift 2
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --seed)
            SEED="$2"
            shift 2
            ;;
        --k)
            K_OVERRIDE="$2"
            shift 2
            ;;
        --max-iter)
            MAX_ITER_OVERRIDE="$2"
            shift 2
            ;;
        --tol)
            TOL_OVERRIDE="$2"
            shift 2
            ;;
        --help|-h)
            cat << EOF
üöÄ POLARS + PYSPARK K-MEANS PIPELINE - SI√äU VI·ªÜT EDITION

S·ª≠ d·ª•ng: $0 [OPTIONS]

OPTIONS:
  --reset           Reset checkpoints v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu
  --from-step N     B·∫Øt ƒë·∫ßu t·ª´ b∆∞·ªõc N (1-7)
  --skip-step N     B·ªè qua b∆∞·ªõc N
  --dry-run         Ch·ªâ hi·ªÉn th·ªã k·∫ø ho·∫°ch
  --seed N          Thi·∫øt l·∫≠p seed cho KMeans (v√≠ d·ª• 42)
  --k N             S·ªë c·ª•m K cho KMeans (v√≠ d·ª• 5)
  --max-iter N      S·ªë v√≤ng l·∫∑p t·ªëi ƒëa KMeans (v√≠ d·ª• 15)
  --tol FLOAT       Ng∆∞·ª°ng h·ªôi t·ª• (v√≠ d·ª• 1e-4)
  --help, -h        Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n n√†y

V√ç D·ª§:
  $0                    # Ch·∫°y b√¨nh th∆∞·ªùng
  $0 --reset            # Reset v√† ch·∫°y l·∫°i
  $0 --from-step 5      # Ch·∫°y t·ª´ b∆∞·ªõc 5
  $0 --skip-step 1      # B·ªè qua b∆∞·ªõc 1
  $0 --dry-run          # Xem tr∆∞·ªõc k·∫ø ho·∫°ch

C·∫§U TR√öC PIPELINE (7 B∆Ø·ªöC):
  1. Kh√°m ph√° d·ªØ li·ªáu           (~30s)
  2. X·ª≠ l√Ω ƒë·∫∑c tr∆∞ng         (~10 ph√∫t)
  3. Upload l√™n HDFS          (~5 ph√∫t)
  4. Ch·∫°y K-means MLlib      (~10-15 ph√∫t) ‚≠ê N√ìNG!
  5. T·∫£i k·∫øt qu·∫£ v·ªÅ           (~30s)
  6. G√°n nh√£n c·ª•m             (~10 ph√∫t)
  7. Ph√¢n t√≠ch k·∫øt qu·∫£         (~2 ph√∫t)

T·ªîNG TH·ªúI GIAN ∆Ø·ªöC T√çNH: 30-40 ph√∫t (‚ö° Nhanh h∆°n 30-50%!)

EOF
            exit 0
            ;;
        *)
            echo "‚ùå L·ªói: Tham s·ªë kh√¥ng h·ª£p l·ªá: $1"
            echo "S·ª≠ d·ª•ng --help ƒë·ªÉ xem h∆∞·ªõng d·∫´n"
            exit 1
            ;;
    esac
done

# ==================== KH·ªûI T·∫†O ====================
mkdir -p "$LOGS_DIR" "$SNAPSHOTS_DIR"
LOG_FILE="$LOGS_DIR/pipeline_log_$(date +%Y%m%d_%H%M%S).md"
CHECKPOINT_DIR="$ROOT_DIR/.pipeline_checkpoints"
mkdir -p "$CHECKPOINT_DIR"

# H√†m ghi log ra c·∫£ terminal v√† file
log() {
    echo "$1" | tee -a "$LOG_FILE"
}

# In ra terminal c√≥ m√†u (kh√¥ng ghi v√†o log)
term() {
    # ƒêi·ªÅu khi·ªÉn m√†u: ch·ªâ in ra terminal ƒë·ªÉ tr√°nh escape v√†o log
    # S·ª≠ d·ª•ng >&2 ƒë·ªÉ t√°ch kh·ªèi tee c·ªßa log()
    echo -e "$1" >&2
}

# M√†u c∆° b·∫£n cho terminal
COLOR_RESET='\033[0m'
COLOR_BOLD='\033[1m'
COLOR_BLUE='\033[34m'
COLOR_GREEN='\033[32m'
COLOR_YELLOW='\033[33m'
COLOR_RED='\033[31m'

# H√†m ki·ªÉm tra xem b∆∞·ªõc ƒë√£ ho√†n th√†nh ch∆∞a
is_step_completed() {
    [ -f "$CHECKPOINT_DIR/step_$1.done" ]
}

# H√†m ƒë√°nh d·∫•u b∆∞·ªõc ƒë√£ ho√†n th√†nh
mark_step_completed() {
    touch "$CHECKPOINT_DIR/step_$1.done"
    echo "$(date '+%Y-%m-%d %H:%M:%S')" > "$CHECKPOINT_DIR/step_$1.done"
}

# H√†m ki·ªÉm tra xem c√≥ b·ªè qua b∆∞·ªõc n√†y kh√¥ng
is_step_skipped() {
    for skip in "${SKIP_STEPS[@]-}"; do
        if [[ "$skip" == "$1" ]]; then
            return 0
        fi
    done
    return 1
}

# H√†m reset t·∫•t c·∫£ c√°c checkpoint
reset_checkpoints() {
    rm -rf "$CHECKPOINT_DIR"
    mkdir -p "$CHECKPOINT_DIR"
    log "üîÑ ƒê√£ reset t·∫•t c·∫£ checkpoints"
}

# H√†m ki·ªÉm tra ƒëi·ªÅu ki·ªán tr∆∞·ªõc khi ch·∫°y
check_prerequisites() {
    local errors=0
    
    log "üîç KI·ªÇM TRA ƒêI·ªÄU KI·ªÜN..."
    
    # Ki·ªÉm tra Python
    if ! command -v python &> /dev/null; then
        log "   ‚ùå Python kh√¥ng t√¨m th·∫•y"
        ((errors++))
    else
        log "   ‚úÖ Python: $(python --version)"
    fi
    
    # Ki·ªÉm tra HDFS
    if ! command -v hdfs &> /dev/null; then
        log "   ‚ö†Ô∏è  HDFS command kh√¥ng t√¨m th·∫•y (s·∫Ω c·∫ßn cho b∆∞·ªõc 4-6)"
    elif hdfs dfs -test -e / 2>/dev/null; then
        log "   ‚úÖ HDFS ƒëang ch·∫°y"
    else
        log "   ‚ö†Ô∏è  HDFS ch∆∞a kh·ªüi ƒë·ªông (s·∫Ω c·∫ßn cho b∆∞·ªõc 4-6)"
    fi
    
    # Ki·ªÉm tra file CSV
    if [[ ! -f "$DATA_DIR/raw/HI-Large_Trans.csv" ]]; then
        log "   ‚ùå File CSV kh√¥ng t√¨m th·∫•y: $DATA_DIR/raw/HI-Large_Trans.csv"
        ((errors++))
    else
        local size=$(du -h "$DATA_DIR/raw/HI-Large_Trans.csv" | cut -f1)
        log "   ‚úÖ File CSV: $size"
    fi
    
    # Ki·ªÉm tra RAM kh·∫£ d·ª•ng
    local available_ram=$(free -g | awk '/^Mem:/{print $7}')
    if [[ $available_ram -lt 8 ]]; then
        log "   ‚ö†Ô∏è  RAM kh·∫£ d·ª•ng: ${available_ram}GB (khuy·∫øn ngh·ªã ‚â• 8GB)"
    else
        log "   ‚úÖ RAM kh·∫£ d·ª•ng: ${available_ram}GB"
    fi
    
    # Ki·ªÉm tra disk space
    local available_disk=$(df -h "$ROOT_DIR" | awk 'NR==2 {print $4}')
    log "   üíæ Disk kh·∫£ d·ª•ng: $available_disk"
    
    log ""
    
    if [[ $errors -gt 0 ]]; then
        log "‚ùå C√≥ $errors l·ªói ph·∫£i s·ª≠a tr∆∞·ªõc khi ch·∫°y!"
        exit 1
    fi
}

# H√†m th·ªëng k√™ ti·∫øn ƒë·ªô
show_progress() {
    local completed=0
    for i in 1 2 3 4 5 6 7; do
        if is_step_completed $i; then
            ((completed++)) || true
        fi
    done
    
    local percent=$((completed * 100 / TOTAL_STEPS))
    local bar_length=20
    local filled=$((completed * bar_length / TOTAL_STEPS))
    local empty=$((bar_length - filled))
    
    printf "${COLOR_BOLD}${COLOR_BLUE}   Ti·∫øn ƒë·ªô:${COLOR_RESET} [" >&2
    printf "%${filled}s" | tr ' ' '‚ñà' >&2
    printf "%${empty}s" | tr ' ' '‚ñë' >&2
    printf "] %d/%d (%d%%)\n" $completed $TOTAL_STEPS $percent >&2
}

# H√†m ƒë·ªãnh d·∫°ng th·ªùi gian
format_time() {
    local seconds=$1
    local hours=$((seconds / 3600))
    local minutes=$(((seconds % 3600) / 60))
    local secs=$((seconds % 60))
    
    if [ $hours -gt 0 ]; then
        printf "%dh %dm %ds" $hours $minutes $secs
    elif [ $minutes -gt 0 ]; then
        printf "%dm %ds" $minutes $secs
    else
        printf "%ds" $secs
    fi
}

# H√†m ch·∫°y m·ªôt b∆∞·ªõc pipeline
run_step() {
    local step_num=$1
    local step_name="$2"
    local step_desc="$3"
    local step_time="$4"
    local command="$5"
    
    term "${COLOR_BOLD}${COLOR_BLUE}\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${COLOR_RESET}"
    term "${COLOR_BOLD}${COLOR_BLUE}üî¢ B∆∞·ªõc $step_num/${TOTAL_STEPS}:${COLOR_RESET} ${COLOR_BOLD}$step_name${COLOR_RESET}"
    log "### üî¢ B∆∞·ªõc $step_num/${TOTAL_STEPS}: $step_name"
    log ""
    log "**M·ª•c ƒë√≠ch:** $step_desc"
    log "**Th·ªùi gian ∆∞·ªõc t√≠nh:** $step_time"
    log ""
    
    if [[ $FROM_STEP -gt $step_num ]] || is_step_skipped $step_num; then
        log "‚è© B·ªè qua b∆∞·ªõc $step_num"
    elif is_step_completed $step_num; then
        log "‚úÖ B∆∞·ªõc $step_num ƒë√£ ho√†n th√†nh tr∆∞·ªõc ƒë√≥"
    elif [[ "$DRY_RUN" == "true" ]]; then
        log "üìñ [Dry Run] S·∫Ω ch·∫°y: $command"
    else
        STEP_START=$(date +%s)
        term "${COLOR_YELLOW}üõ†Ô∏è  ƒêang ch·∫°y...${COLOR_RESET}"
        log "üõ†Ô∏è  ƒêang ch·∫°y..."
        
        if eval "$command" 2>&1 | tee -a "$LOG_FILE"; then
            mark_step_completed $step_num
            STEP_END=$(date +%s)
            STEP_TIME_ACTUAL=$((STEP_END - STEP_START))
            log ""
            term "${COLOR_GREEN}‚úÖ Ho√†n th√†nh: ${COLOR_BOLD}B∆∞·ªõc $step_num${COLOR_RESET}${COLOR_GREEN} trong $(format_time $STEP_TIME_ACTUAL)${COLOR_RESET}"
            log "‚úÖ **B∆∞·ªõc $step_num ho√†n th√†nh trong $(format_time $STEP_TIME_ACTUAL)**"
        else
            log ""
            term "${COLOR_RED}‚ùå Th·∫•t b·∫°i: ${COLOR_BOLD}B∆∞·ªõc $step_num${COLOR_RESET}${COLOR_RED}. Ki·ªÉm tra log ·ªü tr√™n.${COLOR_RESET}"
            log "‚ùå **B∆∞·ªõc $step_num th·∫•t b·∫°i! Ki·ªÉm tra log ·ªü tr√™n.**"
            exit 1
        fi
    fi
    log ""
    log "---"
    log ""
}

# ==================== RESET N·∫æU C·∫¶N ====================
if [[ "$RESET_MODE" == "true" ]]; then
    reset_checkpoints
    log "üîÑ Ch·∫ø ƒë·ªô reset: X√≥a t·∫•t c·∫£ checkpoints"
fi

# ==================== KI·ªÇM TRA ƒêI·ªÄU KI·ªÜN ====================
if [[ "$DRY_RUN" == "false" ]]; then
    check_prerequisites
fi

# ==================== B·∫ÆT ƒê·∫¶U PIPELINE ====================
TOTAL_START=$(date +%s)

# Kh·ªüi t·∫°o file markdown + banner terminal
term "${COLOR_BOLD}${COLOR_BLUE}===============================================================${COLOR_RESET}"
term "${COLOR_BOLD}${COLOR_BLUE}üöÄ Polars + PySpark Pipeline - Si√™u Vi·ªát Edition${COLOR_RESET}"
term "${COLOR_BOLD}${COLOR_BLUE}===============================================================${COLOR_RESET}"
log "# üöÄ Polars + PySpark Pipeline - Si√™u Vi·ªát Edition"
log ""
log "**Th·ªùi gian b·∫Øt ƒë·∫ßu:** $(date '+%Y-%m-%d %H:%M:%S')"
log "**File log:** \`$LOG_FILE\`"
log "**Ch·∫ø ƒë·ªô:** $([ "$DRY_RUN" == "true" ] && echo "Dry Run" || echo "Th·ª±c thi")"
if [[ $FROM_STEP -gt 1 ]]; then
    log "**B·∫Øt ƒë·∫ßu t·ª´:** B∆∞·ªõc $FROM_STEP"
fi
if [[ ${#SKIP_STEPS[@]} -gt 0 ]]; then
    log "**B·ªè qua:** B∆∞·ªõc ${SKIP_STEPS[*]}"
fi
if [[ -n "$SEED" ]]; then
    log "**Seed:** $SEED"
    term "${COLOR_BOLD}${COLOR_BLUE}Seed:${COLOR_RESET} $SEED"
fi
if [[ -n "$K_OVERRIDE" ]]; then
    log "**K (override):** $K_OVERRIDE"
    term "${COLOR_BOLD}${COLOR_BLUE}K:${COLOR_RESET} $K_OVERRIDE"
fi
if [[ -n "$MAX_ITER_OVERRIDE" ]]; then
    log "**Max Iter (override):** $MAX_ITER_OVERRIDE"
    term "${COLOR_BOLD}${COLOR_BLUE}Max Iter:${COLOR_RESET} $MAX_ITER_OVERRIDE"
fi
if [[ -n "$TOL_OVERRIDE" ]]; then
    log "**Tol (override):** $TOL_OVERRIDE"
    term "${COLOR_BOLD}${COLOR_BLUE}Tol:${COLOR_RESET} $TOL_OVERRIDE"
fi
log ""
log "---"
log ""

# Hi·ªÉn th·ªã ti·∫øn ƒë·ªô hi·ªán t·∫°i
log "## Ti·∫øn ƒë·ªô Hi·ªán T·∫°i"
log ""
if [[ "$DRY_RUN" == "false" ]]; then
    show_progress
fi
log ""
log "---"
log ""

log "## Th·ª±c Thi Pipeline"
log ""

# ==================== C√ÅC B∆Ø·ªöC PIPELINE ====================

run_step 1 "Kh√°m Ph√° D·ªØ Li·ªáu" \
    "Ph√¢n t√≠ch th·ªëng k√™ s∆° b·ªô CSV, hi·ªÉu c·∫•u tr√∫c d·ªØ li·ªáu" \
    "~30 gi√¢y" \
    "python \"$SCRIPTS_DIR/polars/01_explore_fast.py\""

run_step 2 "X·ª≠ L√Ω ƒê·∫∑c Tr∆∞ng" \
    "Feature engineering, normalization, t·∫°o file temp" \
    "~10 ph√∫t" \
    "python \"$SCRIPTS_DIR/polars/02_prepare_polars.py\""

run_step 3 "Upload L√™n HDFS" \
    "Upload d·ªØ li·ªáu l√™n HDFS, x√≥a temp files local" \
    "~5 ph√∫t" \
    "bash \"$SCRIPTS_DIR/spark/setup_hdfs.sh\""

run_step 4 "K-means MLlib (T·ªëi ∆Øu)" \
    "K-means v·ªõi MLlib: k-means++, Catalyst optimizer, Tungsten" \
    "~10-15 ph√∫t (‚ö° Nhanh h∆°n 30-50%)" \
    "bash \"$SCRIPTS_DIR/spark/run_spark.sh\" ${SEED:+$SEED} ${K_OVERRIDE:+$K_OVERRIDE} ${MAX_ITER_OVERRIDE:+$MAX_ITER_OVERRIDE} ${TOL_OVERRIDE:+$TOL_OVERRIDE}"

run_step 5 "T·∫£i K·∫øt Qu·∫£ V·ªÅ" \
    "Download final centroids t·ª´ HDFS v·ªÅ local" \
    "~30 gi√¢y" \
    "bash \"$SCRIPTS_DIR/spark/download_from_hdfs.sh\""

run_step 6 "G√°n Nh√£n C·ª•m" \
    "Assign cluster labels cho t·ª´ng giao d·ªãch" \
    "~10 ph√∫t" \
    "python \"$SCRIPTS_DIR/polars/04_assign_clusters.py\""

run_step 7 "Ph√¢n T√≠ch K·∫øt Qu·∫£" \
    "Statistical analysis v√† t√¨m high-risk clusters" \
    "~2 ph√∫t" \
    "python \"$SCRIPTS_DIR/polars/05_analyze.py\""

# ==================== T·ªîNG K·∫æT ====================
TOTAL_END=$(date +%s)
TOTAL_TIME=$((TOTAL_END - TOTAL_START))
log ""
log "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
log ""
log "## üéâ T·ªïng K·∫øt Pipeline"
log ""
log "‚úÖ **Pipeline ho√†n th√†nh th√†nh c√¥ng!**"
log ""
log "**Th·ªùi gian k·∫øt th√∫c:** $(date '+%Y-%m-%d %H:%M:%S')"
log "**T·ªïng th·ªùi gian ch·∫°y:** $(format_time $TOTAL_TIME)"
log ""
log "---"
log ""
log "### üìä Th·ªëng K√™ K·∫øt Qu·∫£"
log ""

# Th·ªëng k√™ k·∫øt qu·∫£
if [[ -f "$DATA_DIR/results/clustered_results.txt" ]]; then
    total_transactions=$(wc -l < "$DATA_DIR/results/clustered_results.txt")
    log "- üìä T·ªïng giao d·ªãch ƒë√£ ph√¢n c·ª•m: **$(printf "%'d" $total_transactions)**"
fi

if [[ -f "$DATA_DIR/results/final_centroids.txt" ]]; then
    num_clusters=$(wc -l < "$DATA_DIR/results/final_centroids.txt")
    log "- üéØ S·ªë c·ª•m: **$num_clusters**"
fi

log_size=$(du -h "$LOG_FILE" | cut -f1)
log "- üìù K√≠ch th∆∞·ªõc log: **$log_size**"

log ""
log "---"
log ""
log "### üöÄ B∆∞·ªõc Ti·∫øp Theo"
log ""
log "#### 1Ô∏è‚É£ **T·∫°o Snapshot K·∫øt Qu·∫£**"
log "   L∆∞u l·∫°i k·∫øt qu·∫£ n√†y ƒë·ªÉ so s√°nh sau n√†y:"
log "   \`\`\`bash"
log "   python 02_scripts/data/snapshot_results.py"
log "   \`\`\`"
log ""
log "#### 2Ô∏è‚É£ **Tr·ª±c Quan H√≥a K·∫øt Qu·∫£**"
log "   T·∫°o bi·ªÉu ƒë·ªì ASCII ho·∫∑c ch·∫°y Jupyter notebook:"
log "   \`\`\`bash"
log "   # Bi·ªÉu ƒë·ªì ASCII"
log "   python 02_scripts/data/visualize_results.py"
log "   "
log "   # Ho·∫∑c Jupyter notebook"
log "   cd 06_visualizations"
log "   jupyter lab phan-tich.ipynb"
log "   \`\`\`"
log ""
log "#### 3Ô∏è‚É£ **Ki·ªÉm Tra K·∫øt Qu·∫£ HDFS**"
log "   Xem d·ªØ li·ªáu tr√™n HDFS:"
log "   \`\`\`bash"
log "   hdfs dfs -ls -h /user/spark/hi_large/"
log "   hdfs dfs -du -h /user/spark/hi_large/"
log "   \`\`\`"
log ""
log "#### 4Ô∏è‚É£ **ƒê·ªçc B√°o C√°o Chi Ti·∫øt**"
log "   \`\`\`bash"
log "   cat BAO_CAO_DU_AN.md"
log "   \`\`\`"
log ""
log "#### 5Ô∏è‚É£ **Ch·∫°y L·∫°i V·ªõi Tham S·ªë Kh√°c**"
log "   \`\`\`bash"
log "   # Reset v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --reset"
log "   "
log "   # Ch·∫°y l·∫°i t·ª´ b∆∞·ªõc 5 (Spark)"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --from-step 5"
log "   "
log "   # Dry run ƒë·ªÉ xem k·∫ø ho·∫°ch"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --dry-run"
log "   \`\`\`"
log ""
log "#### 6Ô∏è‚É£ **T·ªëi ∆Øu V√† Th·ª≠ Nghi·ªám**"
log "   \`\`\`bash"
log "   # Th·ª≠ K kh√°c nhau (s·ª≠a trong scripts)"
log "   # Th·ª≠ feature engineering kh√°c"
log "   # Th·ª≠ parameter tuning cho Spark"
log "   # So s√°nh v·ªõi supervised learning"
log "   \`\`\`"
log ""
log "---"
log ""
log "### üíæ Files Quan Tr·ªçng"
log ""
log "| File | V·ªã Tr√≠ | M√¥ T·∫£ |"
log "|------|----------|--------|"
log "| Log n√†y | \`$LOG_FILE\` | Chi ti·∫øt th·ª±c thi |"
log "| K·∫øt qu·∫£ | \`01_data/results/clustered_results.txt\` | Nh√£n c·ª•m |"
log "| T√¢m c·ª•m | \`01_data/results/final_centroids.txt\` | 5 t√¢m c·ª•m (MLlib) |"
log "| B√°o c√°o | \`BAO_CAO_DU_AN.md\` | B√°o c√°o ƒë·∫ßy ƒë·ªß |"
log "| Notebook | \`06_visualizations/phan-tich.ipynb\` | Ph√¢n t√≠ch visual |"
log ""
log "---"
log ""
log "### üéØ G·ª£i √ù Nghi√™n C·ª©u Ti·∫øp"
log ""
log "1. **Model Comparison**: So s√°nh K-means vs. DBSCAN, vs. Isolation Forest"
log "2. **Supervised Learning**: D√πng labels ƒë·ªÉ train Random Forest/XGBoost"
log "3. **Feature Engineering**: Th√™m graph features, temporal patterns"
log "4. **Real-time**: Implement streaming v·ªõi Spark Streaming + Kafka"
log "5. **Deployment**: Containerize v·ªõi Docker + Kubernetes"
log "6. **Monitoring**: Th√™m metrics v·ªõi Prometheus + Grafana"
log ""
log "üëç **Ch√∫c m·ª´ng! Pipeline ƒë√£ ch·∫°y th√†nh c√¥ng.**"
log ""
log "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

if [[ "$DRY_RUN" == "false" ]]; then
    echo ""
    echo "üéâ PIPELINE HO√ÄN TH√ÄNH SI√äU VI·ªÜT!"
    echo ""
    echo "üìù Log chi ti·∫øt: $LOG_FILE"
    echo "üìä Xem k·∫øt qu·∫£: cat 01_data/results/clustered_results.txt | head"
    echo "üöÄ B∆∞·ªõc ti·∫øp theo: python 02_scripts/data/snapshot_results.py"
    echo "üìà Visualization: cd 06_visualizations && jupyter lab phan-tich.ipynb"
    echo "üéØ Ch·∫°y v·ªõi options: $0 --help"
    echo ""
    echo "üåü C√°c t√≠nh nƒÉng m·ªõi trong v2.0:"
    echo "   ‚úÖ Command line arguments (--reset, --from-step, --skip-step, --dry-run)"
    echo "   ‚úÖ Comprehensive prerequisite checking"
    echo "   ‚úÖ Visual progress bar"
    echo "   ‚úÖ Detailed step descriptions"
    echo "   ‚úÖ Rich suggestions for next steps"
    echo "   ‚úÖ Better error handling v√† logging"
    echo "   ‚úÖ Research suggestions"
    echo ""
fi