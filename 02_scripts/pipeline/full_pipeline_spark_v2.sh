#!/bin/bash
#
# ğŸš€ POLARS + PYSPARK K-MEANS PIPELINE - SIÃŠU VIá»†T EDITION
#
# MÃ´ táº£: Pipeline tá»± Ä‘á»™ng 7 bÆ°á»›c xá»­ lÃ½ 179 triá»‡u giao dá»‹ch (MLlib k-means++)
# TÃ¡c giáº£: Dá»± Ãn PhÃ¢n TÃ­ch Rá»­a Tiá»n
# Version: 2.0 (SiÃªu Viá»‡t Edition)
# NgÃ y: 2025-10-29
#
# Sá»­ dá»¥ng:
#   ./02_scripts/pipeline/full_pipeline_spark_v2.sh [OPTIONS]
#
# OPTIONS:
#   --reset        Reset táº¥t cáº£ checkpoints vÃ  cháº¡y láº¡i tá»« Ä‘áº§u
#   --from-step N  Báº¯t Ä‘áº§u tá»« bÆ°á»›c N
#   --skip-step N  Bá» qua bÆ°á»›c N
#   --dry-run      Chá»‰ hiá»ƒn thá»‹ káº¿ hoáº¡ch, khÃ´ng cháº¡y
#   --help         Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n
#

set -euo pipefail  # Exit on error, undefined vars, pipe failures

# ==================== Cáº¤U HÃŒNH ====================
ROOT_DIR="$(cd "$(dirname "$0")/../.."; pwd)"
SCRIPTS_DIR="$ROOT_DIR/02_scripts"
LOGS_DIR="$ROOT_DIR/04_logs"
DATA_DIR="$ROOT_DIR/01_data"
SNAPSHOTS_DIR="$ROOT_DIR/05_snapshots"
VIZ_DIR="$ROOT_DIR/06_visualizations"

# Flags
RESET_MODE=false
DRY_RUN=false
FROM_STEP=1
SKIP_STEPS=()
VERBOSE=true

# ==================== PARSE ARGUMENTS ====================
while [[ $# -gt 0 ]]; do
    case $1 in
        --reset)
            RESET_MODE=true
            shift
            ;;
        --from-step)
            FROM_STEP="$2"
            shift 2
            ;;
        --skip-step)
            SKIP_STEPS+=("$2")
            shift 2
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --help|-h)
            cat << EOF
ğŸš€ POLARS + PYSPARK K-MEANS PIPELINE - SIÃŠU VIá»†T EDITION

Sá»­ dá»¥ng: $0 [OPTIONS]

OPTIONS:
  --reset           Reset checkpoints vÃ  cháº¡y láº¡i tá»« Ä‘áº§u
  --from-step N     Báº¯t Ä‘áº§u tá»« bÆ°á»›c N (1-7)
  --skip-step N     Bá» qua bÆ°á»›c N
  --dry-run         Chá»‰ hiá»ƒn thá»‹ káº¿ hoáº¡ch
  --help, -h        Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n nÃ y

VÃ Dá»¤:
  $0                    # Cháº¡y bÃ¬nh thÆ°á»ng
  $0 --reset            # Reset vÃ  cháº¡y láº¡i
  $0 --from-step 5      # Cháº¡y tá»« bÆ°á»›c 5
  $0 --skip-step 1      # Bá» qua bÆ°á»›c 1
  $0 --dry-run          # Xem trÆ°á»›c káº¿ hoáº¡ch

Cáº¤U TRÃšC PIPELINE (7 BÆ¯á»šC):
  1. KhÃ¡m phÃ¡ dá»¯ liá»‡u           (~30s)
  2. Xá»­ lÃ½ Ä‘áº·c trÆ°ng         (~10 phÃºt)
  3. Upload lÃªn HDFS          (~5 phÃºt)
  4. Cháº¡y K-means MLlib      (~10-15 phÃºt) â­ NÃ“NG!
  5. Táº£i káº¿t quáº£ vá»           (~30s)
  6. GÃ¡n nhÃ£n cá»¥m             (~10 phÃºt)
  7. PhÃ¢n tÃ­ch káº¿t quáº£         (~2 phÃºt)

Tá»”NG THá»œI GIAN Æ¯á»šC TÃNH: 30-40 phÃºt (âš¡ Nhanh hÆ¡n 30-50%!)

EOF
            exit 0
            ;;
        *)
            echo "âŒ Lá»—i: Tham sá»‘ khÃ´ng há»£p lá»‡: $1"
            echo "Sá»­ dá»¥ng --help Ä‘á»ƒ xem hÆ°á»›ng dáº«n"
            exit 1
            ;;
    esac
done

# ==================== KHá»I Táº O ====================
mkdir -p "$LOGS_DIR" "$SNAPSHOTS_DIR"
LOG_FILE="$LOGS_DIR/pipeline_log_$(date +%Y%m%d_%H%M%S).md"
CHECKPOINT_DIR="$ROOT_DIR/.pipeline_checkpoints"
mkdir -p "$CHECKPOINT_DIR"

# HÃ m ghi log ra cáº£ terminal vÃ  file
log() {
    echo "$1" | tee -a "$LOG_FILE"
}

# HÃ m kiá»ƒm tra xem bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh chÆ°a
is_step_completed() {
    [ -f "$CHECKPOINT_DIR/step_$1.done" ]
}

# HÃ m Ä‘Ã¡nh dáº¥u bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh
mark_step_completed() {
    touch "$CHECKPOINT_DIR/step_$1.done"
    echo "$(date '+%Y-%m-%d %H:%M:%S')" > "$CHECKPOINT_DIR/step_$1.done"
}

# HÃ m kiá»ƒm tra xem cÃ³ bá» qua bÆ°á»›c nÃ y khÃ´ng
is_step_skipped() {
    for skip in "${SKIP_STEPS[@]-}"; do
        if [[ "$skip" == "$1" ]]; then
            return 0
        fi
    done
    return 1
}

# HÃ m reset táº¥t cáº£ cÃ¡c checkpoint
reset_checkpoints() {
    rm -rf "$CHECKPOINT_DIR"
    mkdir -p "$CHECKPOINT_DIR"
    log "ğŸ”„ ÄÃ£ reset táº¥t cáº£ checkpoints"
}

# HÃ m kiá»ƒm tra Ä‘iá»u kiá»‡n trÆ°á»›c khi cháº¡y
check_prerequisites() {
    local errors=0
    
    log "ğŸ” KIá»‚M TRA ÄIá»€U KIá»†N..."
    
    # Kiá»ƒm tra Python
    if ! command -v python &> /dev/null; then
        log "   âŒ Python khÃ´ng tÃ¬m tháº¥y"
        ((errors++))
    else
        log "   âœ… Python: $(python --version)"
    fi
    
    # Kiá»ƒm tra HDFS
    if ! command -v hdfs &> /dev/null; then
        log "   âš ï¸  HDFS command khÃ´ng tÃ¬m tháº¥y (sáº½ cáº§n cho bÆ°á»›c 4-6)"
    elif hdfs dfs -test -e / 2>/dev/null; then
        log "   âœ… HDFS Ä‘ang cháº¡y"
    else
        log "   âš ï¸  HDFS chÆ°a khá»Ÿi Ä‘á»™ng (sáº½ cáº§n cho bÆ°á»›c 4-6)"
    fi
    
    # Kiá»ƒm tra file CSV
    if [[ ! -f "$DATA_DIR/raw/HI-Large_Trans.csv" ]]; then
        log "   âŒ File CSV khÃ´ng tÃ¬m tháº¥y: $DATA_DIR/raw/HI-Large_Trans.csv"
        ((errors++))
    else
        local size=$(du -h "$DATA_DIR/raw/HI-Large_Trans.csv" | cut -f1)
        log "   âœ… File CSV: $size"
    fi
    
    # Kiá»ƒm tra RAM kháº£ dá»¥ng
    local available_ram=$(free -g | awk '/^Mem:/{print $7}')
    if [[ $available_ram -lt 8 ]]; then
        log "   âš ï¸  RAM kháº£ dá»¥ng: ${available_ram}GB (khuyáº¿n nghá»‹ â‰¥ 8GB)"
    else
        log "   âœ… RAM kháº£ dá»¥ng: ${available_ram}GB"
    fi
    
    # Kiá»ƒm tra disk space
    local available_disk=$(df -h "$ROOT_DIR" | awk 'NR==2 {print $4}')
    log "   ğŸ’¾ Disk kháº£ dá»¥ng: $available_disk"
    
    log ""
    
    if [[ $errors -gt 0 ]]; then
        log "âŒ CÃ³ $errors lá»—i pháº£i sá»­a trÆ°á»›c khi cháº¡y!"
        exit 1
    fi
}

# HÃ m thá»‘ng kÃª tiáº¿n Ä‘á»™
show_progress() {
    local completed=0
    for i in 1 2 3 4 5 6 7; do
        if is_step_completed $i; then
            ((completed++)) || true
        fi
    done
    
    local percent=$((completed * 100 / 7))
    local bar_length=20
    local filled=$((completed * bar_length / 7))
    local empty=$((bar_length - filled))
    
    printf "   Tiáº¿n Ä‘á»™: [" >&2
    printf "%${filled}s" | tr ' ' 'â–ˆ' >&2
    printf "%${empty}s" | tr ' ' 'â–‘' >&2
    printf "] %d/8 (%d%%)\n" $completed $percent >&2
}

# HÃ m Ä‘á»‹nh dáº¡ng thá»i gian
format_time() {
    local seconds=$1
    local hours=$((seconds / 3600))
    local minutes=$(((seconds % 3600) / 60))
    local secs=$((seconds % 60))
    
    if [ $hours -gt 0 ]; then
        printf "%dh %dm %ds" $hours $minutes $secs
    elif [ $minutes -gt 0 ]; then
        printf "%dm %ds" $minutes $secs
    else
        printf "%ds" $secs
    fi
}

# HÃ m cháº¡y má»™t bÆ°á»›c pipeline
run_step() {
    local step_num=$1
    local step_name="$2"
    local step_desc="$3"
    local step_time="$4"
    local command="$5"
    
    log "### ğŸ”¢ BÆ°á»›c $step_num/8: $step_name"
    log ""
    log "**Má»¥c Ä‘Ã­ch:** $step_desc"
    log "**Thá»i gian Æ°á»›c tÃ­nh:** $step_time"
    log ""
    
    if [[ $FROM_STEP -gt $step_num ]] || is_step_skipped $step_num; then
        log "â© Bá» qua bÆ°á»›c $step_num"
    elif is_step_completed $step_num; then
        log "âœ… BÆ°á»›c $step_num Ä‘Ã£ hoÃ n thÃ nh trÆ°á»›c Ä‘Ã³"
    elif [[ "$DRY_RUN" == "true" ]]; then
        log "ğŸ“– [Dry Run] Sáº½ cháº¡y: $command"
    else
        STEP_START=$(date +%s)
        log "ğŸ› ï¸  Äang cháº¡y..."
        
        if eval "$command" 2>&1 | tee -a "$LOG_FILE"; then
            mark_step_completed $step_num
            STEP_END=$(date +%s)
            STEP_TIME_ACTUAL=$((STEP_END - STEP_START))
            log ""
            log "âœ… **BÆ°á»›c $step_num hoÃ n thÃ nh trong $(format_time $STEP_TIME_ACTUAL)**"
        else
            log ""
            log "âŒ **BÆ°á»›c $step_num tháº¥t báº¡i! Kiá»ƒm tra log á»Ÿ trÃªn.**"
            exit 1
        fi
    fi
    log ""
    log "---"
    log ""
}

# ==================== RESET Náº¾U Cáº¦N ====================
if [[ "$RESET_MODE" == "true" ]]; then
    reset_checkpoints
    log "ğŸ”„ Cháº¿ Ä‘á»™ reset: XÃ³a táº¥t cáº£ checkpoints"
fi

# ==================== KIá»‚M TRA ÄIá»€U KIá»†N ====================
if [[ "$DRY_RUN" == "false" ]]; then
    check_prerequisites
fi

# ==================== Báº®T Äáº¦U PIPELINE ====================
TOTAL_START=$(date +%s)

# Khá»Ÿi táº¡o file markdown
log "# ğŸš€ Polars + PySpark Pipeline - SiÃªu Viá»‡t Edition"
log ""
log "**Thá»i gian báº¯t Ä‘áº§u:** $(date '+%Y-%m-%d %H:%M:%S')"
log "**File log:** \`$LOG_FILE\`"
log "**Cháº¿ Ä‘á»™:** $([ "$DRY_RUN" == "true" ] && echo "Dry Run" || echo "Thá»±c thi")"
if [[ $FROM_STEP -gt 1 ]]; then
    log "**Báº¯t Ä‘áº§u tá»«:** BÆ°á»›c $FROM_STEP"
fi
if [[ ${#SKIP_STEPS[@]} -gt 0 ]]; then
    log "**Bá» qua:** BÆ°á»›c ${SKIP_STEPS[*]}"
fi
log ""
log "---"
log ""

# Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™ hiá»‡n táº¡i
log "## Tiáº¿n Ä‘á»™ Hiá»‡n Táº¡i"
log ""
if [[ "$DRY_RUN" == "false" ]]; then
    show_progress
fi
log ""
log "---"
log ""

log "## Thá»±c Thi Pipeline"
log ""

# ==================== CÃC BÆ¯á»šC PIPELINE ====================

run_step 1 "KhÃ¡m PhÃ¡ Dá»¯ Liá»‡u" \
    "PhÃ¢n tÃ­ch thá»‘ng kÃª sÆ¡ bá»™ CSV, hiá»ƒu cáº¥u trÃºc dá»¯ liá»‡u" \
    "~30 giÃ¢y" \
    "python \"$SCRIPTS_DIR/polars/01_explore_fast.py\""

run_step 2 "Xá»­ LÃ½ Äáº·c TrÆ°ng" \
    "Feature engineering, normalization, táº¡o file temp" \
    "~10 phÃºt" \
    "python \"$SCRIPTS_DIR/polars/02_prepare_polars.py\""

run_step 3 "Upload LÃªn HDFS" \
    "Upload dá»¯ liá»‡u lÃªn HDFS, xÃ³a temp files local" \
    "~5 phÃºt" \
    "bash \"$SCRIPTS_DIR/spark/setup_hdfs.sh\""

run_step 4 "K-means MLlib (Tá»‘i Æ¯u)" \
    "K-means vá»›i MLlib: k-means++, Catalyst optimizer, Tungsten" \
    "~10-15 phÃºt (âš¡ Nhanh hÆ¡n 30-50%)" \
    "bash \"$SCRIPTS_DIR/spark/run_spark.sh\""

run_step 5 "Táº£i Káº¿t Quáº£ Vá»" \
    "Download final centroids tá»« HDFS vá» local" \
    "~30 giÃ¢y" \
    "bash \"$SCRIPTS_DIR/spark/download_from_hdfs.sh\""

run_step 6 "GÃ¡n NhÃ£n Cá»¥m" \
    "Assign cluster labels cho tá»«ng giao dá»‹ch" \
    "~10 phÃºt" \
    "python \"$SCRIPTS_DIR/polars/04_assign_clusters.py\""

run_step 7 "PhÃ¢n TÃ­ch Káº¿t Quáº£" \
    "Statistical analysis vÃ  tÃ¬m high-risk clusters" \
    "~2 phÃºt" \
    "python \"$SCRIPTS_DIR/polars/05_analyze.py\""

# ==================== Tá»”NG Káº¾T ====================
TOTAL_END=$(date +%s)
TOTAL_TIME=$((TOTAL_END - TOTAL_START))
log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log ""
log "## ğŸ‰ Tá»•ng Káº¿t Pipeline"
log ""
log "âœ… **Pipeline hoÃ n thÃ nh thÃ nh cÃ´ng!**"
log ""
log "**Thá»i gian káº¿t thÃºc:** $(date '+%Y-%m-%d %H:%M:%S')"
log "**Tá»•ng thá»i gian cháº¡y:** $(format_time $TOTAL_TIME)"
log ""
log "---"
log ""
log "### ğŸ“Š Thá»‘ng KÃª Káº¿t Quáº£"
log ""

# Thá»‘ng kÃª káº¿t quáº£
if [[ -f "$DATA_DIR/results/clustered_results.txt" ]]; then
    total_transactions=$(wc -l < "$DATA_DIR/results/clustered_results.txt")
    log "- ğŸ“Š Tá»•ng giao dá»‹ch Ä‘Ã£ phÃ¢n cá»¥m: **$(printf "%'d" $total_transactions)**"
fi

if [[ -f "$DATA_DIR/results/final_centroids.txt" ]]; then
    num_clusters=$(wc -l < "$DATA_DIR/results/final_centroids.txt")
    log "- ğŸ¯ Sá»‘ cá»¥m: **$num_clusters**"
fi

log_size=$(du -h "$LOG_FILE" | cut -f1)
log "- ğŸ“ KÃ­ch thÆ°á»›c log: **$log_size**"

log ""
log "---"
log ""
log "### ğŸš€ BÆ°á»›c Tiáº¿p Theo"
log ""
log "#### 1ï¸âƒ£ **Táº¡o Snapshot Káº¿t Quáº£**"
log "   LÆ°u láº¡i káº¿t quáº£ nÃ y Ä‘á»ƒ so sÃ¡nh sau nÃ y:"
log "   \`\`\`bash"
log "   python 02_scripts/data/snapshot_results.py"
log "   \`\`\`"
log ""
log "#### 2ï¸âƒ£ **Trá»±c Quan HÃ³a Káº¿t Quáº£**"
log "   Táº¡o biá»ƒu Ä‘á»“ ASCII hoáº·c cháº¡y Jupyter notebook:"
log "   \`\`\`bash"
log "   # Biá»ƒu Ä‘á»“ ASCII"
log "   python 02_scripts/data/visualize_results.py"
log "   "
log "   # Hoáº·c Jupyter notebook"
log "   cd 06_visualizations"
log "   jupyter lab phan-tich.ipynb"
log "   \`\`\`"
log ""
log "#### 3ï¸âƒ£ **Kiá»ƒm Tra Káº¿t Quáº£ HDFS**"
log "   Xem dá»¯ liá»‡u trÃªn HDFS:"
log "   \`\`\`bash"
log "   hdfs dfs -ls -h /user/spark/hi_large/"
log "   hdfs dfs -du -h /user/spark/hi_large/"
log "   \`\`\`"
log ""
log "#### 4ï¸âƒ£ **Äá»c BÃ¡o CÃ¡o Chi Tiáº¿t**"
log "   \`\`\`bash"
log "   cat BAO_CAO_DU_AN.md"
log "   \`\`\`"
log ""
log "#### 5ï¸âƒ£ **Cháº¡y Láº¡i Vá»›i Tham Sá»‘ KhÃ¡c**"
log "   \`\`\`bash"
log "   # Reset vÃ  cháº¡y láº¡i tá»« Ä‘áº§u"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --reset"
log "   "
log "   # Cháº¡y láº¡i tá»« bÆ°á»›c 5 (Spark)"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --from-step 5"
log "   "
log "   # Dry run Ä‘á»ƒ xem káº¿ hoáº¡ch"
log "   ./02_scripts/pipeline/full_pipeline_spark_v2.sh --dry-run"
log "   \`\`\`"
log ""
log "#### 6ï¸âƒ£ **Tá»‘i Æ¯u VÃ  Thá»­ Nghiá»‡m**"
log "   \`\`\`bash"
log "   # Thá»­ K khÃ¡c nhau (sá»­a trong scripts)"
log "   # Thá»­ feature engineering khÃ¡c"
log "   # Thá»­ parameter tuning cho Spark"
log "   # So sÃ¡nh vá»›i supervised learning"
log "   \`\`\`"
log ""
log "---"
log ""
log "### ğŸ’¾ Files Quan Trá»ng"
log ""
log "| File | Vá»‹ TrÃ­ | MÃ´ Táº£ |"
log "|------|----------|--------|"
log "| Log nÃ y | \`$LOG_FILE\` | Chi tiáº¿t thá»±c thi |"
log "| Káº¿t quáº£ | \`01_data/results/clustered_results.txt\` | NhÃ£n cá»¥m |"
log "| TÃ¢m cá»¥m | \`01_data/results/final_centroids.txt\` | 5 tÃ¢m cá»¥m (MLlib) |"
log "| BÃ¡o cÃ¡o | \`BAO_CAO_DU_AN.md\` | BÃ¡o cÃ¡o Ä‘áº§y Ä‘á»§ |"
log "| Notebook | \`06_visualizations/phan-tich.ipynb\` | PhÃ¢n tÃ­ch visual |"
log ""
log "---"
log ""
log "### ğŸ¯ Gá»£i Ã NghiÃªn Cá»©u Tiáº¿p"
log ""
log "1. **Model Comparison**: So sÃ¡nh K-means vs. DBSCAN, vs. Isolation Forest"
log "2. **Supervised Learning**: DÃ¹ng labels Ä‘á»ƒ train Random Forest/XGBoost"
log "3. **Feature Engineering**: ThÃªm graph features, temporal patterns"
log "4. **Real-time**: Implement streaming vá»›i Spark Streaming + Kafka"
log "5. **Deployment**: Containerize vá»›i Docker + Kubernetes"
log "6. **Monitoring**: ThÃªm metrics vá»›i Prometheus + Grafana"
log ""
log "ğŸ‘ **ChÃºc má»«ng! Pipeline Ä‘Ã£ cháº¡y thÃ nh cÃ´ng.**"
log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

if [[ "$DRY_RUN" == "false" ]]; then
    echo ""
    echo "ğŸ‰ PIPELINE HOÃ€N THÃ€NH SIÃŠU VIá»†T!"
    echo ""
    echo "ğŸ“ Log chi tiáº¿t: $LOG_FILE"
    echo "ğŸ“Š Xem káº¿t quáº£: cat 01_data/results/clustered_results.txt | head"
    echo "ğŸš€ BÆ°á»›c tiáº¿p theo: python 02_scripts/data/snapshot_results.py"
    echo "ğŸ“ˆ Visualization: cd 06_visualizations && jupyter lab phan-tich.ipynb"
    echo "ğŸ¯ Cháº¡y vá»›i options: $0 --help"
    echo ""
    echo "ğŸŒŸ CÃ¡c tÃ­nh nÄƒng má»›i trong v2.0:"
    echo "   âœ… Command line arguments (--reset, --from-step, --skip-step, --dry-run)"
    echo "   âœ… Comprehensive prerequisite checking"
    echo "   âœ… Visual progress bar"
    echo "   âœ… Detailed step descriptions"
    echo "   âœ… Rich suggestions for next steps"
    echo "   âœ… Better error handling vÃ  logging"
    echo "   âœ… Research suggestions"
    echo ""
fi