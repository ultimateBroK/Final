#!/bin/bash
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üìä D·ª∞ √ÅN: Ph√¢n T√≠ch R·ª≠a Ti·ªÅn ‚Äî K-means (Polars + Spark)
# B∆Ø·ªöC 5/7: T·∫¢I K·∫æT QU·∫¢ T·ª™ HDFS V·ªÄ LOCAL
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# M·ª•c ti√™u: G·ªôp (getmerge) centroids t·ª´ HDFS v·ªÅ 01_data/results/final_centroids.txt
# I/O:
#   - Input (HDFS): /user/spark/hi_large/output_centroids/
#   - Output(local): 01_data/results/final_centroids.txt
# C√°ch ch·∫°y nhanh:
#   bash 02_scripts/spark/download_from_hdfs.sh
# Ghi ch√∫: Y√™u c·∫ßu b∆∞·ªõc 4 ƒë√£ ch·∫°y xong v√† c√≥ th∆∞ m·ª•c output tr√™n HDFS.

set -euo pipefail

echo "=== T·∫¢I K·∫æT QU·∫¢ T·ª™ HDFS ==="

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
ROOT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"
DATA_RESULTS="$ROOT_DIR/01_data/results"

# C·∫•u h√¨nh HDFS
HDFS_BASE="/user/spark/hi_large"
HDFS_OUTPUT="$HDFS_BASE/output_centroids"

# Ki·ªÉm tra HDFS c√≥ ƒëang ch·∫°y kh√¥ng
if ! hdfs dfs -test -e / 2>/dev/null; then
    echo "HDFS kh√¥ng th·ªÉ truy c·∫≠p."
    exit 1
fi

# Ki·ªÉm tra k·∫øt qu·∫£ c√≥ t·ªìn t·∫°i trong HDFS kh√¥ng
if ! hdfs dfs -test -e "$HDFS_OUTPUT" 2>/dev/null; then
    echo "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ trong HDFS: $HDFS_OUTPUT"
    echo "   Vui l√≤ng ch·∫°y PySpark job tr∆∞·ªõc: ./02_scripts/spark/run_spark.sh"
    exit 1
fi

echo "ƒê√£ t√¨m th·∫•y k·∫øt qu·∫£ trong HDFS"
echo ""

# T·∫°o th∆∞ m·ª•c results n·∫øu ch∆∞a c√≥
mkdir -p "$DATA_RESULTS"

# T·∫£i t√¢m c·ª•m cu·ªëi c√πng
echo "ƒêang t·∫£i t√¢m c·ª•m cu·ªëi c√πng..."
echo "  T·ª´: $HDFS_OUTPUT"
echo "  ƒê·∫øn: $DATA_RESULTS/final_centroids.txt"

# X√≥a file local c≈©
rm -f "$DATA_RESULTS/final_centroids.txt"

# G·ªôp t·∫•t c·∫£ c√°c ph·∫ßn t·ª´ HDFS
hdfs dfs -getmerge "$HDFS_OUTPUT" "$DATA_RESULTS/final_centroids.txt"

if [ $? -ne 0 ]; then
    echo "Th·∫•t b·∫°i khi t·∫£i t√¢m c·ª•m"
    exit 1
fi

echo "ƒê√£ t·∫£i t√¢m c·ª•m cu·ªëi c√πng"
echo ""

# Hi·ªÉn th·ªã th√¥ng tin file
if [ -f "$DATA_RESULTS/final_centroids.txt" ]; then
    FILE_SIZE=$(du -h "$DATA_RESULTS/final_centroids.txt" | cut -f1)
    LINE_COUNT=$(wc -l < "$DATA_RESULTS/final_centroids.txt")
    echo "Th√¥ng tin file local:"
    echo "  K√≠ch th∆∞·ªõc: $FILE_SIZE"
    echo "  S·ªë d√≤ng (c·ª•m): $LINE_COUNT"
    echo ""
    echo "Xem tr∆∞·ªõc:"
    head -n 5 "$DATA_RESULTS/final_centroids.txt"
fi

echo ""
echo "Ho√†n th√†nh t·∫£i xu·ªëng!"
echo ""
echo "B∆∞·ªõc ti·∫øp theo:"
echo "  1. G√°n c·ª•m: python $ROOT_DIR/02_scripts/polars/assign_clusters.py"
echo "  2. Ph√¢n t√≠ch k·∫øt qu·∫£: python $ROOT_DIR/02_scripts/polars/analyze.py"
