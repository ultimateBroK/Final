# Polars + PySpark Pipeline Execution Log

**Start Time:** 2025-10-28 20:28:50
**Log File:** /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251028_202850.md

---

## Pipeline Execution

=== POLARS + PYSPARK PIPELINE ===
Start time: 2025-10-28 20:28:50

### Step 1: Explore data

<bound method LazyFrame.collect_schema of <LazyFrame at 0x7F2A52992F00>>
shape: (100_000, 11)
┌────────────┬───────────┬───────────┬─────────┬───┬───────────┬───────────┬───────────┬───────────┐
│ Timestamp  ┆ From Bank ┆ Account   ┆ To Bank ┆ … ┆ Amount    ┆ Payment   ┆ Payment   ┆ Is Launde │
│ ---        ┆ ---       ┆ ---       ┆ ---     ┆   ┆ Paid      ┆ Currency  ┆ Format    ┆ ring      │
│ str        ┆ i64       ┆ str       ┆ i64     ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │
│            ┆           ┆           ┆         ┆   ┆ f64       ┆ str       ┆ str       ┆ i64       │
╞════════════╪═══════════╪═══════════╪═════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡
│ 2022/08/01 ┆ 20        ┆ 800104D70 ┆ 20      ┆ … ┆ 6794.63   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:17      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 3196      ┆ 800107150 ┆ 3196    ┆ … ┆ 7739.29   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:02      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E430 ┆ 1208    ┆ … ┆ 1880.23   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:17      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E650 ┆ 20      ┆ … ┆ 7.3966883 ┆ US Dollar ┆ Cheque    ┆ 0         │
│ 00:03      ┆           ┆           ┆         ┆   ┆ e7        ┆           ┆           ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E650 ┆ 20      ┆ … ┆ 4.5868454 ┆ US Dollar ┆ Cheque    ┆ 0         │
│ 00:02      ┆           ┆           ┆         ┆   ┆ e7        ┆           ┆           ┆           │
│ …          ┆ …         ┆ …         ┆ …       ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │
│ 2022/08/01 ┆ 111667    ┆ 80E5D9320 ┆ 111667  ┆ … ┆ 23.93     ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:06      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 25994     ┆ 80E5DBF50 ┆ 25994   ┆ … ┆ 23.41     ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:18      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 310328    ┆ 80E5ED350 ┆ 310328  ┆ … ┆ 3297.82   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:04      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 5838      ┆ 80E5ED580 ┆ 5838    ┆ … ┆ 3032.53   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:19      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 339249    ┆ 80E5ED620 ┆ 339249  ┆ … ┆ 13043.39  ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:26      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
└────────────┴───────────┴───────────┴─────────┴───┴───────────┴───────────┴───────────┴───────────┘
shape: (9, 12)
┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐
│ statistic ┆ Timestamp ┆ From Bank ┆ Account   ┆ … ┆ Amount    ┆ Payment   ┆ Payment   ┆ Is Laund │
│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ Paid      ┆ Currency  ┆ Format    ┆ ering    │
│ str       ┆ str       ┆ f64       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │
│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆ str       ┆ f64      │
╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡
│ count     ┆ 100000    ┆ 100000.0  ┆ 100000    ┆ … ┆ 100000.0  ┆ 100000    ┆ 100000    ┆ 100000.0 │
│ null_coun ┆ 0         ┆ 0.0       ┆ 0         ┆ … ┆ 0.0       ┆ 0         ┆ 0         ┆ 0.0      │
│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │
│ mean      ┆ null      ┆ 49669.967 ┆ null      ┆ … ┆ 1.1422e6  ┆ null      ┆ null      ┆ 0.00001  │
│           ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │
│ std       ┆ null      ┆ 80891.260 ┆ null      ┆ … ┆ 2.9890e7  ┆ null      ┆ null      ┆ 0.003162 │
│           ┆           ┆ 568       ┆           ┆   ┆           ┆           ┆           ┆          │
│ min       ┆ 2022/08/0 ┆ 0.0       ┆ 100428660 ┆ … ┆ 0.01      ┆ Australia ┆ ACH       ┆ 0.0      │
│           ┆ 1 00:00   ┆           ┆           ┆   ┆           ┆ n Dollar  ┆           ┆          │
│ 25%       ┆ null      ┆ 4214.0    ┆ null      ┆ … ┆ 20.53     ┆ null      ┆ null      ┆ 0.0      │
│ 50%       ┆ null      ┆ 15240.0   ┆ null      ┆ … ┆ 2513.06   ┆ null      ┆ null      ┆ 0.0      │
│ 75%       ┆ null      ┆ 31996.0   ┆ null      ┆ … ┆ 28769.41  ┆ null      ┆ null      ┆ 0.0      │
│ max       ┆ 2022/08/0 ┆ 339249.0  ┆ 80E5ED620 ┆ … ┆ 5.1154e9  ┆ Yuan      ┆ Wire      ┆ 1.0      │
│           ┆ 1 00:29   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │
└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘

Laundering distribution:
shape: (2, 1)
┌───────────────┐
│ Is Laundering │
│ ---           │
│ struct[2]     │
╞═══════════════╡
│ {0,179476683} │
│ {1,225546}    │
└───────────────┘

Top currencies:
shape: (10, 1)
┌───────────────────────────────┐
│ Receiving Currency            │
│ ---                           │
│ struct[2]                     │
╞═══════════════════════════════╡
│ {"Mexican Peso",4801493}      │
│ {"Yuan",12920668}             │
│ {"Australian Dollar",5256710} │
│ {"Canadian Dollar",6140322}   │
│ {"UK Pound",5748874}          │
│ {"Ruble",5571567}             │
│ {"Bitcoin",3958153}           │
│ {"Saudi Riyal",3228262}       │
│ {"Euro",41290069}             │
│ {"Yen",4841570}               │
└───────────────────────────────┘
⏱️  **Step 1 completed in 12s**

### Step 2: Prepare features with Polars

Loading with Polars...
Feature engineering...
Encoding categoricals...
Normalizing...
Writing temp file for HDFS upload: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
✅ Created temp file with 179702229 rows (will be uploaded to HDFS)
   Features: ['amount_received', 'amount_paid', 'amount_ratio', 'hour', 'day_of_week', 'route_hash', 'recv_curr_encoded', 'payment_curr_encoded', 'payment_format_encoded']
⚠️  Remember: This temp file will be deleted after HDFS upload
⏱️  **Step 2 completed in 1m 4s**

### Step 3: Initialize centroids

Sampling for centroid initialization...
Initializing 5 centroids from 100000 samples...
✅ Saved 5 centroids to temp file (will be uploaded to HDFS)
⚠️  Remember: Temp files will be deleted after HDFS upload
⏱️  **Step 3 completed in 23s**

### Step 4: Upload data to HDFS

=== Setting up HDFS for PySpark K-means ===
✅ HDFS is accessible

✅ Temp data files found

Creating HDFS directories...
Cleaning old data in HDFS...
Deleted /user/spark/hi_large/input/hadoop_input.txt
Deleted /user/spark/hi_large/centroids.txt
Deleted /user/spark/hi_large/output_centroids

Uploading input data to HDFS...
  Source: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
  Destination: /user/spark/hi_large/input/hadoop_input.txt

Uploading centroids to HDFS...
  Source: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
  Destination: /user/spark/hi_large/centroids.txt

Cleaning up temp files...
✅ Temp files deleted (data now only on HDFS)

Verifying uploads...
  ✅ Input data: 31.0 G
  ✅ Centroids: 440 440

HDFS directory structure:
-rw-r--r--   1 ultimatebrok supergroup        440 2025-10-28 20:31 /user/spark/hi_large/centroids.txt
drwxr-xr-x   - ultimatebrok supergroup          0 2025-10-28 20:31 /user/spark/hi_large/input
-rw-r--r--   1 ultimatebrok supergroup 33273091481 2025-10-28 20:31 /user/spark/hi_large/input/hadoop_input.txt
drwxr-xr-x   - ultimatebrok supergroup           0 2025-10-28 16:52 /user/spark/hi_large/output

===================================
✅ HDFS setup completed successfully!
===================================

HDFS paths:
  Input: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  Centroids: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  Output: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Next step: Run PySpark job
  ./scripts/spark/run_spark.sh
⏱️  **Step 4 completed in 42s**

### Step 5: Run PySpark K-means on HDFS

=== PySpark K-means with HDFS ===
Configuration:
  CPU cores: 24
  Executor instances: 4
  Executor cores: 4
  Executor memory: 4g
  Driver memory: 4g

HDFS paths:
  Input: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  Centroids: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  Output: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Cleaning old output...
Running PySpark K-means clustering on HDFS...
Max iterations: 15

WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/28 20:31:15 WARN Utils: Your hostname, brokie-hx370, resolves to a loopback address: 127.0.1.1; using 192.168.31.34 instead (on interface wlan0)
25/10/28 20:31:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
HDFS Input: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
HDFS Centroids: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
HDFS Output: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/28 20:31:16 INFO SparkContext: Running Spark version 4.0.1
25/10/28 20:31:16 INFO SparkContext: OS info Linux, 6.17.5-2-cachyos, amd64
25/10/28 20:31:16 INFO SparkContext: Java version 17.0.16
25/10/28 20:31:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/28 20:31:16 INFO ResourceUtils: ==============================================================
25/10/28 20:31:16 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/28 20:31:16 INFO ResourceUtils: ==============================================================
25/10/28 20:31:16 INFO SparkContext: Submitted application: K-means Clustering - HDFS
25/10/28 20:31:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/28 20:31:16 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
25/10/28 20:31:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/28 20:31:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkDriver' on port 46823.
25/10/28 20:31:17 INFO SparkEnv: Registering MapOutputTracker
25/10/28 20:31:17 INFO SparkEnv: Registering BlockManagerMaster
25/10/28 20:31:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/28 20:31:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/28 20:31:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/28 20:31:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f4c9df0b-b0e5-4ca2-8bc8-dcb47c7ce2bd
25/10/28 20:31:17 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/28 20:31:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO LocalSparkCluster: Starting a local Spark cluster with 4 workers.
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkMaster' on port 41637.
25/10/28 20:31:17 INFO Master: Starting Spark master at spark://192.168.31.34:41637
25/10/28 20:31:17 INFO Master: Running Spark version 4.0.1
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:0 for MasterUI
25/10/28 20:31:17 INFO Utils: Successfully started service 'MasterUI' on port 45985.
25/10/28 20:31:17 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://192.168.31.34:45985
25/10/28 20:31:17 INFO Master: I have been elected leader! New state: ALIVE
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkWorker1' on port 38575.
25/10/28 20:31:17 INFO Worker: Worker decommissioning not enabled.
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO Worker: Starting Spark worker 192.168.31.34:38575 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Worker: Running Spark version 4.0.1
25/10/28 20:31:17 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkWorker2' on port 35703.
25/10/28 20:31:17 INFO Worker: Worker decommissioning not enabled.
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO Worker: Starting Spark worker 192.168.31.34:35703 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Worker: Running Spark version 4.0.1
25/10/28 20:31:17 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/28 20:31:17 INFO Utils: Successfully started service 'WorkerUI' on port 38995.
25/10/28 20:31:17 INFO Utils: Successfully started service 'WorkerUI' on port 46149.
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkWorker3' on port 38649.
25/10/28 20:31:17 INFO Worker: Worker decommissioning not enabled.
25/10/28 20:31:17 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.31.34:46149
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO Worker: Starting Spark worker 192.168.31.34:38649 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Worker: Running Spark version 4.0.1
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.31.34:38995
25/10/28 20:31:17 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO Worker: Connecting to master 192.168.31.34:41637...
25/10/28 20:31:17 INFO Worker: Connecting to master 192.168.31.34:41637...
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/28 20:31:17 INFO Utils: Successfully started service 'WorkerUI' on port 46405.
25/10/28 20:31:17 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.31.34:46405
25/10/28 20:31:17 INFO Worker: Connecting to master 192.168.31.34:41637...
25/10/28 20:31:17 INFO Utils: Successfully started service 'sparkWorker4' on port 34507.
25/10/28 20:31:17 INFO Worker: Worker decommissioning not enabled.
25/10/28 20:31:17 INFO Worker: Starting Spark worker 192.168.31.34:34507 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Worker: Running Spark version 4.0.1
25/10/28 20:31:17 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/28 20:31:17 INFO ResourceUtils: ==============================================================
25/10/28 20:31:17 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/28 20:31:17 INFO Utils: Successfully started service 'WorkerUI' on port 43531.
25/10/28 20:31:17 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.31.34:43531
25/10/28 20:31:17 INFO Worker: Connecting to master 192.168.31.34:41637...
25/10/28 20:31:17 INFO TransportClientFactory: Successfully created connection to /192.168.31.34:41637 after 24 ms (0 ms spent in bootstraps)
25/10/28 20:31:17 INFO TransportClientFactory: Successfully created connection to /192.168.31.34:41637 after 9 ms (0 ms spent in bootstraps)
25/10/28 20:31:17 INFO TransportClientFactory: Successfully created connection to /192.168.31.34:41637 after 24 ms (0 ms spent in bootstraps)
25/10/28 20:31:17 INFO TransportClientFactory: Successfully created connection to /192.168.31.34:41637 after 24 ms (0 ms spent in bootstraps)
25/10/28 20:31:17 INFO Master: Registering worker 192.168.31.34:38649 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Master: Registering worker 192.168.31.34:35703 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Master: Registering worker 192.168.31.34:34507 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Master: Registering worker 192.168.31.34:38575 with 4 cores, 4.0 GiB RAM
25/10/28 20:31:17 INFO Worker: Successfully registered with master spark://192.168.31.34:41637
25/10/28 20:31:17 INFO Worker: Successfully registered with master spark://192.168.31.34:41637
25/10/28 20:31:17 INFO Worker: Successfully registered with master spark://192.168.31.34:41637
25/10/28 20:31:17 INFO Worker: Successfully registered with master spark://192.168.31.34:41637
25/10/28 20:31:17 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/28 20:31:17 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/28 20:31:17 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/28 20:31:17 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://192.168.31.34:41637...
25/10/28 20:31:17 INFO TransportClientFactory: Successfully created connection to /192.168.31.34:41637 after 1 ms (0 ms spent in bootstraps)
25/10/28 20:31:17 INFO Master: Registering app K-means Clustering - HDFS
25/10/28 20:31:17 INFO Master: Registered app K-means Clustering - HDFS with ID app-20251028203117-0000
25/10/28 20:31:17 INFO Master: Start scheduling for app app-20251028203117-0000 with rpId: 0
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251028203117-0000
25/10/28 20:31:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37397.
25/10/28 20:31:17 INFO NettyBlockTransferService: Server created on 192.168.31.34:37397
25/10/28 20:31:17 INFO Master: Launching executor app-20251028203117-0000/0 on worker worker-20251028203117-192.168.31.34-38649
25/10/28 20:31:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/28 20:31:17 INFO Master: Launching executor app-20251028203117-0000/1 on worker worker-20251028203117-192.168.31.34-38575
25/10/28 20:31:17 INFO Master: Launching executor app-20251028203117-0000/2 on worker worker-20251028203117-192.168.31.34-35703
25/10/28 20:31:17 INFO Master: Launching executor app-20251028203117-0000/3 on worker worker-20251028203117-192.168.31.34-34507
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251028203117-0000/0 on worker-20251028203117-192.168.31.34-38649 (192.168.31.34:38649) with 4 core(s)
25/10/28 20:31:17 INFO Worker: Asked to launch executor app-20251028203117-0000/3 for K-means Clustering - HDFS
25/10/28 20:31:17 INFO Worker: Asked to launch executor app-20251028203117-0000/2 for K-means Clustering - HDFS
25/10/28 20:31:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.31.34, 37397, None)
25/10/28 20:31:17 INFO Worker: Asked to launch executor app-20251028203117-0000/0 for K-means Clustering - HDFS
25/10/28 20:31:17 INFO Worker: Asked to launch executor app-20251028203117-0000/1 for K-means Clustering - HDFS
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251028203117-0000/0 on hostPort 192.168.31.34:38649 with 4 core(s), 4.0 GiB RAM
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251028203117-0000/1 on worker-20251028203117-192.168.31.34-38575 (192.168.31.34:38575) with 4 core(s)
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251028203117-0000/1 on hostPort 192.168.31.34:38575 with 4 core(s), 4.0 GiB RAM
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251028203117-0000/2 on worker-20251028203117-192.168.31.34-35703 (192.168.31.34:35703) with 4 core(s)
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251028203117-0000/2 on hostPort 192.168.31.34:35703 with 4 core(s), 4.0 GiB RAM
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251028203117-0000/3 on worker-20251028203117-192.168.31.34-34507 (192.168.31.34:34507) with 4 core(s)
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251028203117-0000/3 on hostPort 192.168.31.34:34507 with 4 core(s), 4.0 GiB RAM
25/10/28 20:31:17 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.31.34:37397 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.31.34, 37397, None)
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.31.34, 37397, None)
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/28 20:31:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.31.34, 37397, None)
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/28 20:31:17 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46823" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.31.34:46823" "--executor-id" "2" "--hostname" "192.168.31.34" "--cores" "4" "--app-id" "app-20251028203117-0000" "--worker-url" "spark://Worker@192.168.31.34:35703" "--resourceProfileId" "0"
25/10/28 20:31:17 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46823" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.31.34:46823" "--executor-id" "3" "--hostname" "192.168.31.34" "--cores" "4" "--app-id" "app-20251028203117-0000" "--worker-url" "spark://Worker@192.168.31.34:34507" "--resourceProfileId" "0"
25/10/28 20:31:17 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46823" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.31.34:46823" "--executor-id" "0" "--hostname" "192.168.31.34" "--cores" "4" "--app-id" "app-20251028203117-0000" "--worker-url" "spark://Worker@192.168.31.34:38649" "--resourceProfileId" "0"
25/10/28 20:31:17 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46823" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.31.34:46823" "--executor-id" "1" "--hostname" "192.168.31.34" "--cores" "4" "--app-id" "app-20251028203117-0000" "--worker-url" "spark://Worker@192.168.31.34:38575" "--resourceProfileId" "0"
25/10/28 20:31:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/10/28 20:31:17 INFO Master: Start scheduling for app app-20251028203117-0000 with rpId: 0
25/10/28 20:31:17 INFO Master: Start scheduling for app app-20251028203117-0000 with rpId: 0
25/10/28 20:31:17 INFO Master: Start scheduling for app app-20251028203117-0000 with rpId: 0
25/10/28 20:31:17 INFO Master: Start scheduling for app app-20251028203117-0000 with rpId: 0
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251028203117-0000/0 is now RUNNING
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251028203117-0000/2 is now RUNNING
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251028203117-0000/3 is now RUNNING
25/10/28 20:31:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251028203117-0000/1 is now RUNNING
=== PySpark K-means Clustering ===
Input: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
Centroids: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
Max iterations: 15

Loading data from HDFS...
Loaded 179,702,229 points from hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
Loading centroids from hdfs://localhost:9000/user/spark/hi_large/centroids.txt
Initialized 5 centroids

=== Iteration 1/15 ===
Centroid shift: 2.231971

=== Iteration 2/15 ===
Centroid shift: 1.409451

=== Iteration 3/15 ===
Centroid shift: 0.781125

=== Iteration 4/15 ===
Centroid shift: 0.477194

=== Iteration 5/15 ===
Centroid shift: 0.383205

=== Iteration 6/15 ===
Centroid shift: 0.250659

=== Iteration 7/15 ===
Centroid shift: 0.109785

=== Iteration 8/15 ===
Centroid shift: 0.072628

=== Iteration 9/15 ===
Centroid shift: 0.058987

=== Iteration 10/15 ===
Centroid shift: 0.046157

=== Iteration 11/15 ===
Centroid shift: 0.034819

=== Iteration 12/15 ===
Centroid shift: 0.025653

=== Iteration 13/15 ===
Centroid shift: 0.018624

=== Iteration 14/15 ===
Centroid shift: 0.013372

=== Iteration 15/15 ===
Centroid shift: 0.009548


Saving final centroids to HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Cluster sizes:
  Cluster 0: 40,034,828 points (22.28%)
  Cluster 1: 42,665,741 points (23.74%)
  Cluster 2: 24,884,738 points (13.85%)
  Cluster 3: 50,933,660 points (28.34%)
  Cluster 4: 21,183,262 points (11.79%)

✅ K-means clustering completed!

✅ PySpark K-means completed!
Final centroids saved to HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

To view results:
  hdfs dfs -cat /user/spark/hi_large/output_centroids/part-*
⏱️  **Step 5 completed in 26m 30s**

### Step 6: Download results from HDFS

=== Downloading results from HDFS ===
✅ Output found in HDFS

Downloading final centroids...
  From: /user/spark/hi_large/output_centroids
  To: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt
✅ Downloaded final centroids

Local file info:
  Size: 4,0K
  Lines (clusters): 5

Preview:
-0.000065,-0.001084,-0.000558,-0.124230,-0.954360,-0.660282,-0.343976,-0.352701,-0.360205
0.000284,-0.000705,-0.000417,-0.095008,0.922878,-0.675150,-0.343973,-0.351605,-0.333198
0.000016,0.001177,-0.001091,0.002257,-0.003407,0.017059,2.201610,2.213011,0.071471
-0.002015,-0.001458,-0.001119,0.138498,-0.007095,1.033729,-0.364854,-0.359327,-0.278313
0.004378,0.005593,0.005866,0.090843,-0.026721,0.103768,-0.366150,-0.360953,1.937270

✅ Download completed!

Next steps:
  1. Assign clusters: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python assign_clusters_polars.py
  2. Analyze results: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python analyze_polars.py
⏱️  **Step 6 completed in 3s**

### Step 7: Assign clusters with Polars

Loading centroids...
✅ Loaded 5 centroids with 9 features
Loading data from HDFS ...
Streaming from HDFS (this may take a while)...
Reading CSV from HDFS stream...
✅ Loaded 179,702,229 records from HDFS
Converting to numpy and computing distances...
  Data shape: (179702229, 9)
  Centroids shape: (5, 9)
  Calculating distances to centroids (batch processing)...
    Processed 100,000/179,702,229 records...
    Processed 1,100,000/179,702,229 records...
    Processed 2,100,000/179,702,229 records...
    Processed 3,100,000/179,702,229 records...
    Processed 4,100,000/179,702,229 records...
    Processed 5,100,000/179,702,229 records...
    Processed 6,100,000/179,702,229 records...
    Processed 7,100,000/179,702,229 records...
    Processed 8,100,000/179,702,229 records...
    Processed 9,100,000/179,702,229 records...
    Processed 10,100,000/179,702,229 records...
    Processed 11,100,000/179,702,229 records...
    Processed 12,100,000/179,702,229 records...
    Processed 13,100,000/179,702,229 records...
    Processed 14,100,000/179,702,229 records...
    Processed 15,100,000/179,702,229 records...
    Processed 16,100,000/179,702,229 records...
    Processed 17,100,000/179,702,229 records...
    Processed 18,100,000/179,702,229 records...
    Processed 19,100,000/179,702,229 records...
    Processed 20,100,000/179,702,229 records...
    Processed 21,100,000/179,702,229 records...
    Processed 22,100,000/179,702,229 records...
    Processed 23,100,000/179,702,229 records...
    Processed 24,100,000/179,702,229 records...
    Processed 25,100,000/179,702,229 records...
    Processed 26,100,000/179,702,229 records...
    Processed 27,100,000/179,702,229 records...
    Processed 28,100,000/179,702,229 records...
    Processed 29,100,000/179,702,229 records...
    Processed 30,100,000/179,702,229 records...
    Processed 31,100,000/179,702,229 records...
    Processed 32,100,000/179,702,229 records...
    Processed 33,100,000/179,702,229 records...
    Processed 34,100,000/179,702,229 records...
    Processed 35,100,000/179,702,229 records...
    Processed 36,100,000/179,702,229 records...
    Processed 37,100,000/179,702,229 records...
    Processed 38,100,000/179,702,229 records...
    Processed 39,100,000/179,702,229 records...
    Processed 40,100,000/179,702,229 records...
    Processed 41,100,000/179,702,229 records...
    Processed 42,100,000/179,702,229 records...
    Processed 43,100,000/179,702,229 records...
    Processed 44,100,000/179,702,229 records...
    Processed 45,100,000/179,702,229 records...
    Processed 46,100,000/179,702,229 records...
    Processed 47,100,000/179,702,229 records...
    Processed 48,100,000/179,702,229 records...
    Processed 49,100,000/179,702,229 records...
    Processed 50,100,000/179,702,229 records...
    Processed 51,100,000/179,702,229 records...
    Processed 52,100,000/179,702,229 records...
    Processed 53,100,000/179,702,229 records...
    Processed 54,100,000/179,702,229 records...
    Processed 55,100,000/179,702,229 records...
    Processed 56,100,000/179,702,229 records...
    Processed 57,100,000/179,702,229 records...
    Processed 58,100,000/179,702,229 records...
    Processed 59,100,000/179,702,229 records...
    Processed 60,100,000/179,702,229 records...
    Processed 61,100,000/179,702,229 records...
    Processed 62,100,000/179,702,229 records...
    Processed 63,100,000/179,702,229 records...
    Processed 64,100,000/179,702,229 records...
    Processed 65,100,000/179,702,229 records...
    Processed 66,100,000/179,702,229 records...
    Processed 67,100,000/179,702,229 records...
    Processed 68,100,000/179,702,229 records...
    Processed 69,100,000/179,702,229 records...
    Processed 70,100,000/179,702,229 records...
    Processed 71,100,000/179,702,229 records...
    Processed 72,100,000/179,702,229 records...
    Processed 73,100,000/179,702,229 records...
    Processed 74,100,000/179,702,229 records...
    Processed 75,100,000/179,702,229 records...
    Processed 76,100,000/179,702,229 records...
    Processed 77,100,000/179,702,229 records...
    Processed 78,100,000/179,702,229 records...
    Processed 79,100,000/179,702,229 records...
    Processed 80,100,000/179,702,229 records...
    Processed 81,100,000/179,702,229 records...
    Processed 82,100,000/179,702,229 records...
    Processed 83,100,000/179,702,229 records...
    Processed 84,100,000/179,702,229 records...
    Processed 85,100,000/179,702,229 records...
    Processed 86,100,000/179,702,229 records...
    Processed 87,100,000/179,702,229 records...
    Processed 88,100,000/179,702,229 records...
    Processed 89,100,000/179,702,229 records...
    Processed 90,100,000/179,702,229 records...
    Processed 91,100,000/179,702,229 records...
    Processed 92,100,000/179,702,229 records...
    Processed 93,100,000/179,702,229 records...
    Processed 94,100,000/179,702,229 records...
    Processed 95,100,000/179,702,229 records...
    Processed 96,100,000/179,702,229 records...
    Processed 97,100,000/179,702,229 records...
    Processed 98,100,000/179,702,229 records...
    Processed 99,100,000/179,702,229 records...
    Processed 100,100,000/179,702,229 records...
    Processed 101,100,000/179,702,229 records...
    Processed 102,100,000/179,702,229 records...
    Processed 103,100,000/179,702,229 records...
    Processed 104,100,000/179,702,229 records...
    Processed 105,100,000/179,702,229 records...
    Processed 106,100,000/179,702,229 records...
    Processed 107,100,000/179,702,229 records...
    Processed 108,100,000/179,702,229 records...
    Processed 109,100,000/179,702,229 records...
    Processed 110,100,000/179,702,229 records...
    Processed 111,100,000/179,702,229 records...
    Processed 112,100,000/179,702,229 records...
    Processed 113,100,000/179,702,229 records...
    Processed 114,100,000/179,702,229 records...
    Processed 115,100,000/179,702,229 records...
    Processed 116,100,000/179,702,229 records...
    Processed 117,100,000/179,702,229 records...
    Processed 118,100,000/179,702,229 records...
    Processed 119,100,000/179,702,229 records...
    Processed 120,100,000/179,702,229 records...
    Processed 121,100,000/179,702,229 records...
    Processed 122,100,000/179,702,229 records...
    Processed 123,100,000/179,702,229 records...
    Processed 124,100,000/179,702,229 records...
    Processed 125,100,000/179,702,229 records...
    Processed 126,100,000/179,702,229 records...
    Processed 127,100,000/179,702,229 records...
    Processed 128,100,000/179,702,229 records...
    Processed 129,100,000/179,702,229 records...
    Processed 130,100,000/179,702,229 records...
    Processed 131,100,000/179,702,229 records...
    Processed 132,100,000/179,702,229 records...
    Processed 133,100,000/179,702,229 records...
    Processed 134,100,000/179,702,229 records...
    Processed 135,100,000/179,702,229 records...
    Processed 136,100,000/179,702,229 records...
    Processed 137,100,000/179,702,229 records...
    Processed 138,100,000/179,702,229 records...
    Processed 139,100,000/179,702,229 records...
    Processed 140,100,000/179,702,229 records...
    Processed 141,100,000/179,702,229 records...
    Processed 142,100,000/179,702,229 records...
    Processed 143,100,000/179,702,229 records...
    Processed 144,100,000/179,702,229 records...
    Processed 145,100,000/179,702,229 records...
    Processed 146,100,000/179,702,229 records...
    Processed 147,100,000/179,702,229 records...
    Processed 148,100,000/179,702,229 records...
    Processed 149,100,000/179,702,229 records...
    Processed 150,100,000/179,702,229 records...
    Processed 151,100,000/179,702,229 records...
    Processed 152,100,000/179,702,229 records...
    Processed 153,100,000/179,702,229 records...
    Processed 154,100,000/179,702,229 records...
    Processed 155,100,000/179,702,229 records...
    Processed 156,100,000/179,702,229 records...
    Processed 157,100,000/179,702,229 records...
    Processed 158,100,000/179,702,229 records...
    Processed 159,100,000/179,702,229 records...
    Processed 160,100,000/179,702,229 records...
    Processed 161,100,000/179,702,229 records...
    Processed 162,100,000/179,702,229 records...
    Processed 163,100,000/179,702,229 records...
    Processed 164,100,000/179,702,229 records...
    Processed 165,100,000/179,702,229 records...
    Processed 166,100,000/179,702,229 records...
    Processed 167,100,000/179,702,229 records...
    Processed 168,100,000/179,702,229 records...
    Processed 169,100,000/179,702,229 records...
    Processed 170,100,000/179,702,229 records...
    Processed 171,100,000/179,702,229 records...
    Processed 172,100,000/179,702,229 records...
    Processed 173,100,000/179,702,229 records...
    Processed 174,100,000/179,702,229 records...
    Processed 175,100,000/179,702,229 records...
    Processed 176,100,000/179,702,229 records...
    Processed 177,100,000/179,702,229 records...
    Processed 178,100,000/179,702,229 records...
    Processed 179,100,000/179,702,229 records...
    Processed 179,702,229/179,702,229 records
Saving results...
✅ Assigned 179702229 transactions to clusters
   Results saved to /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
   Cluster distribution: [40034832 42665746 24884738 50933651 21183262]
⏱️  **Step 7 completed in 3m 14s**

### Step 8: Analyze results
Loading results...
Loading CSV with lazy evaluation...

=== CLUSTER ANALYSIS ===

Total transactions: 179,702,229
Number of clusters: 5

--- Cluster Sizes ---
shape: (5, 2)
┌─────────┬──────────┐
│ cluster ┆ count    │
│ ---     ┆ ---      │
│ i64     ┆ u32      │
╞═════════╪══════════╡
│ 0       ┆ 40034832 │
│ 1       ┆ 42665746 │
│ 2       ┆ 24884738 │
│ 3       ┆ 50933651 │
│ 4       ┆ 21183262 │
└─────────┴──────────┘

--- Laundering Rate per Cluster ---
shape: (5, 4)
┌─────────┬──────────┬──────────────────┬─────────────────┐
│ cluster ┆ total    ┆ laundering_count ┆ laundering_rate │
│ ---     ┆ ---      ┆ ---              ┆ ---             │
│ i64     ┆ u32      ┆ i64              ┆ f64             │
╞═════════╪══════════╪══════════════════╪═════════════════╡
│ 0       ┆ 40034832 ┆ 52327            ┆ 0.130704        │
│ 1       ┆ 42665746 ┆ 70450            ┆ 0.165121        │
│ 2       ┆ 24884738 ┆ 16686            ┆ 0.067053        │
│ 3       ┆ 50933651 ┆ 82943            ┆ 0.162845        │
│ 4       ┆ 21183262 ┆ 3140             ┆ 0.014823        │
└─────────┴──────────┴──────────────────┴─────────────────┘

⚠️  HIGH RISK CLUSTERS (>10% laundering):
shape: (0, 4)
┌─────────┬───────┬──────────────────┬─────────────────┐
│ cluster ┆ total ┆ laundering_count ┆ laundering_rate │
│ ---     ┆ ---   ┆ ---              ┆ ---             │
│ i64     ┆ u32   ┆ i64              ┆ f64             │
╞═════════╪═══════╪══════════════════╪═════════════════╡
└─────────┴───────┴──────────────────┴─────────────────┘

--- Feature Averages per Cluster ---
shape: (5, 4)
┌─────────┬─────────────────────┬─────────────────┬───────────┐
│ cluster ┆ avg_amount_received ┆ avg_amount_paid ┆ avg_ratio │
│ ---     ┆ ---                 ┆ ---             ┆ ---       │
│ i64     ┆ f64                 ┆ f64             ┆ f64       │
╞═════════╪═════════════════════╪═════════════════╪═══════════╡
│ 0       ┆ 5.4919e6            ┆ 2.4646e6        ┆ 1.471203  │
│ 1       ┆ 6.1139e6            ┆ 2.9921e6        ┆ 1.587185  │
│ 2       ┆ 5.6362e6            ┆ 5.6090e6        ┆ 1.023403  │
│ 3       ┆ 1.9521e6            ┆ 1.9521e6        ┆ 1.0       │
│ 4       ┆ 1.3555e7            ┆ 1.1746e7        ┆ 6.872849  │
└─────────┴─────────────────────┴─────────────────┴───────────┘

✅ Analysis complete!

⏱️  **Step 8 completed in 48s**


---

## Summary

✅ **Pipeline completed successfully!**

**End Time:** 2025-10-28 21:01:46
**Total Runtime:** 32m 56s

---

*Log saved to: /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251028_202850.md*
