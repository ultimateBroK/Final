# Polars + PySpark Pipeline Execution Log

**Th·ªùi gian b·∫Øt ƒë·∫ßu:** 2025-10-29 01:44:14
**File log:** /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_014414.md

---

## Th·ª±c thi Pipeline

=== POLARS + PYSPARK PIPELINE ===
Th·ªùi gian b·∫Øt ƒë·∫ßu: 2025-10-29 01:44:14
### B∆∞·ªõc 1: Kh√°m ph√° d·ªØ li·ªáu

======================================================================
üîç B∆Ø·ªöC 1: KH√ÅM PH√Å D·ªÆ LI·ªÜU
======================================================================
ƒêang ƒë·ªçc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui l√≤ng ƒë·ª£i...

‚úÖ ƒê√£ load metadata th√†nh c√¥ng!

üìã SCHEMA (C·∫•u tr√∫c d·ªØ li·ªáu):
----------------------------------------------------------------------
<bound method LazyFrame.collect_schema of <LazyFrame at 0x7F84771BAC60>>

üìä L·∫§Y M·∫™U 100,000 D√íNG ƒê·∫¶U:
----------------------------------------------------------------------
D·ªØ li·ªáu m·∫´u:
shape: (100_000, 11)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Timestamp  ‚îÜ From Bank ‚îÜ Account   ‚îÜ To Bank ‚îÜ ‚Ä¶ ‚îÜ Amount    ‚îÜ Payment   ‚îÜ Payment   ‚îÜ Is Launde ‚îÇ
‚îÇ ---        ‚îÜ ---       ‚îÜ ---       ‚îÜ ---     ‚îÜ   ‚îÜ Paid      ‚îÜ Currency  ‚îÜ Format    ‚îÜ ring      ‚îÇ
‚îÇ str        ‚îÜ i64       ‚îÜ str       ‚îÜ i64     ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÇ
‚îÇ            ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ f64       ‚îÜ str       ‚îÜ str       ‚îÜ i64       ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 2022/08/01 ‚îÜ 20        ‚îÜ 800104D70 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 6794.63   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:17      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 3196      ‚îÜ 800107150 ‚îÜ 3196    ‚îÜ ‚Ä¶ ‚îÜ 7739.29   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:02      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E430 ‚îÜ 1208    ‚îÜ ‚Ä¶ ‚îÜ 1880.23   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:17      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E650 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 7.3966883 ‚îÜ US Dollar ‚îÜ Cheque    ‚îÜ 0         ‚îÇ
‚îÇ 00:03      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ e7        ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E650 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 4.5868454 ‚îÜ US Dollar ‚îÜ Cheque    ‚îÜ 0         ‚îÇ
‚îÇ 00:02      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ e7        ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ
‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 111667    ‚îÜ 80E5D9320 ‚îÜ 111667  ‚îÜ ‚Ä¶ ‚îÜ 23.93     ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:06      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 25994     ‚îÜ 80E5DBF50 ‚îÜ 25994   ‚îÜ ‚Ä¶ ‚îÜ 23.41     ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:18      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 310328    ‚îÜ 80E5ED350 ‚îÜ 310328  ‚îÜ ‚Ä¶ ‚îÜ 3297.82   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:04      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 5838      ‚îÜ 80E5ED580 ‚îÜ 5838    ‚îÜ ‚Ä¶ ‚îÜ 3032.53   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:19      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 339249    ‚îÜ 80E5ED620 ‚îÜ 339249  ‚îÜ ‚Ä¶ ‚îÜ 13043.39  ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:26      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Th·ªëng k√™ m√¥ t·∫£:
shape: (9, 12)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ statistic ‚îÜ Timestamp ‚îÜ From Bank ‚îÜ Account   ‚îÜ ‚Ä¶ ‚îÜ Amount    ‚îÜ Payment   ‚îÜ Payment   ‚îÜ Is Laund ‚îÇ
‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ Paid      ‚îÜ Currency  ‚îÜ Format    ‚îÜ ering    ‚îÇ
‚îÇ str       ‚îÜ str       ‚îÜ f64       ‚îÜ str       ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ f64       ‚îÜ str       ‚îÜ str       ‚îÜ f64      ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ count     ‚îÜ 100000    ‚îÜ 100000.0  ‚îÜ 100000    ‚îÜ ‚Ä¶ ‚îÜ 100000.0  ‚îÜ 100000    ‚îÜ 100000    ‚îÜ 100000.0 ‚îÇ
‚îÇ null_coun ‚îÜ 0         ‚îÜ 0.0       ‚îÜ 0         ‚îÜ ‚Ä¶ ‚îÜ 0.0       ‚îÜ 0         ‚îÜ 0         ‚îÜ 0.0      ‚îÇ
‚îÇ t         ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ mean      ‚îÜ null      ‚îÜ 49669.967 ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 1.1422e6  ‚îÜ null      ‚îÜ null      ‚îÜ 0.00001  ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ 7         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ std       ‚îÜ null      ‚îÜ 80891.260 ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 2.9890e7  ‚îÜ null      ‚îÜ null      ‚îÜ 0.003162 ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ 568       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ min       ‚îÜ 2022/08/0 ‚îÜ 0.0       ‚îÜ 100428660 ‚îÜ ‚Ä¶ ‚îÜ 0.01      ‚îÜ Australia ‚îÜ ACH       ‚îÜ 0.0      ‚îÇ
‚îÇ           ‚îÜ 1 00:00   ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ n Dollar  ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ 25%       ‚îÜ null      ‚îÜ 4214.0    ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 20.53     ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ 50%       ‚îÜ null      ‚îÜ 15240.0   ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 2513.06   ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ 75%       ‚îÜ null      ‚îÜ 31996.0   ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 28769.41  ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ max       ‚îÜ 2022/08/0 ‚îÜ 339249.0  ‚îÜ 80E5ED620 ‚îÜ ‚Ä¶ ‚îÜ 5.1154e9  ‚îÜ Yuan      ‚îÜ Wire      ‚îÜ 1.0      ‚îÇ
‚îÇ           ‚îÜ 1 00:29   ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí∞ PH√ÇN T√çCH T·ª∂ L·ªÜ R·ª¨A TI·ªÄN:
----------------------------------------------------------------------
shape: (2, 1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Is Laundering ‚îÇ
‚îÇ ---           ‚îÇ
‚îÇ struct[2]     ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ {1,225546}    ‚îÇ
‚îÇ {0,179476683} ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üíµ TOP 10 LO·∫†I TI·ªÄN T·ªÜ PH·ªî BI·∫æN:
----------------------------------------------------------------------
shape: (10, 1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Receiving Currency       ‚îÇ
‚îÇ ---                      ‚îÇ
‚îÇ struct[2]                ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ {"Rupee",4178243}        ‚îÇ
‚îÇ {"Saudi Riyal",3228262}  ‚îÇ
‚îÇ {"Yen",4841570}          ‚îÇ
‚îÇ {"US Dollar",65292945}   ‚îÇ
‚îÇ {"Mexican Peso",4801493} ‚îÇ
‚îÇ {"Swiss Franc",4829099}  ‚îÇ
‚îÇ {"Euro",41290069}        ‚îÇ
‚îÇ {"Bitcoin",3958153}      ‚îÇ
‚îÇ {"Ruble",5571567}        ‚îÇ
‚îÇ {"Shekel",8047876}       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

======================================================================
‚úÖ HO√ÄN T·∫§T KH√ÅM PH√Å D·ªÆ LI·ªÜU!
======================================================================

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 2: python scripts/polars/prepare_polars.py

‚è±Ô∏è  **B∆∞·ªõc 1 ho√†n th√†nh trong 13s**

### B∆∞·ªõc 2: Chu·∫©n b·ªã ƒë·∫∑c tr∆∞ng v·ªõi Polars

======================================================================
üîß B∆Ø·ªöC 2: X·ª¨ L√ù V√Ä TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG
======================================================================
ƒê·ªçc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui l√≤ng ƒë·ª£i (c√≥ th·ªÉ m·∫•t 5-10 ph√∫t)...

‚úÖ ƒê√£ load 179,702,229 d√≤ng v√†o RAM

üåü TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG T·ª™ D·ªÆ LI·ªÜU TH√î...
‚úÖ ƒê√£ tr√≠ch xu·∫•t 10 ƒë·∫∑c tr∆∞ng

üî¢ M√É H√ìA BI·∫æN PH√ÇN LO·∫†I (CATEGORICAL ENCODING)...
‚úÖ ƒê√£ m√£ h√≥a th√†nh s·ªë

üìä C√≥ 9 ƒë·∫∑c tr∆∞ng s·ªë cho K-means

üìä CHU·∫®N H√ìA D·ªÆ LI·ªÜU (Min-Max Scaling)...
‚úÖ ƒê√£ chu·∫©n h√≥a 9 ƒë·∫∑c tr∆∞ng

üíæ L∆ØU FILE T·∫†M TH·ªúI CHO HDFS...
‚ö†Ô∏è  L∆ØU √ù: File n√†y s·∫Ω t·ª± ƒë·ªông x√≥a sau khi upload HDFS!

   ƒêang ghi: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
   Vui l√≤ng ƒë·ª£i (c√≥ th·ªÉ m·∫•t 3-5 ph√∫t)...

======================================================================
‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU!
======================================================================
üìÑ File t·∫°m: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
üìä K√≠ch th∆∞·ªõc: 31.07 GB
üìä S·ªë d√≤ng: 179,702,229
üìä S·ªë ƒë·∫∑c tr∆∞ng: 9
üìä C√°c ƒë·∫∑c tr∆∞ng: ['amount_received', 'amount_paid', 'amount_ratio', 'hour', 'day_of_week', 'route_hash', 'recv_curr_encoded', 'payment_curr_encoded', 'payment_format_encoded']

‚ö†Ô∏è  QUAN TR·ªåNG:
   File n√†y ch·ªâ t·ªìn t·∫°i T·∫†M TH·ªúI!
   N√≥ s·∫Ω B·ªä X√ìA sau khi upload l√™n HDFS (B∆∞·ªõc 4)
   D·ªØ li·ªáu ch·ªâ l∆∞u tr√™n HDFS ƒë·ªÉ tu√¢n th·ªß quy ƒë·ªãnh b·∫£o m·∫≠t

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 3: python scripts/polars/init_centroids.py

‚è±Ô∏è  **B∆∞·ªõc 2 ho√†n th√†nh trong 1m 5s**

### B∆∞·ªõc 3: Kh·ªüi t·∫°o t√¢m c·ª•m

======================================================================
üéØ B∆Ø·ªöC 3: KH·ªöI T·∫†O T√ÇM C·ª§M BAN ƒê·∫¶U
======================================================================

Ki·ªÉm tra file input: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
‚úÖ File input t·ªìn t·∫°i!

üìä ƒê·ªåC D·ªÆ LI·ªÜU ƒê√É CHU·∫®N H√ìA...
‚úÖ ƒê√£ load 179,702,229 d√≤ng v·ªõi 9 ƒë·∫∑c tr∆∞ng

üé≤ L·∫§Y M·∫™U NG·∫™U NHI√äN ƒê·ªÇ KH·ªöI T·∫†O...
   S·ªë m·∫´u: 100,000 d√≤ng
‚úÖ ƒê√£ l·∫•y m·∫´u 100,000 ƒëi·ªÉm

üéØ KH·ªöI T·∫†O 5 T√ÇM C·ª§M BAN ƒê·∫¶U...
   Thu·∫≠t to√°n: Ch·ªçn ng·∫´u nhi√™n 5 ƒëi·ªÉm t·ª´ 100,000 m·∫´u

‚úÖ ƒê√£ ch·ªçn 5 t√¢m c·ª•m ban ƒë·∫ßu
   M·ªói t√¢m c·ª•m c√≥ 9 ƒë·∫∑c tr∆∞ng

üíæ L∆ØU T√ÇM C·ª§M V√ÄO FILE T·∫†M TH·ªúI...
‚ö†Ô∏è  L∆ØU √ù: File n√†y s·∫Ω t·ª± ƒë·ªông x√≥a sau khi upload HDFS!

   ƒêang ghi: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
======================================================================
‚úÖ HO√ÄN T·∫§T KH·ªöI T·∫†O T√ÇM C·ª§M!
======================================================================
üìÑ File t·∫°m: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
üìä K√≠ch th∆∞·ªõc: 433 bytes (~0.4 KB)
üìä S·ªë c·ª•m: 5
üìä S·ªë ƒë·∫∑c tr∆∞ng m·ªói c·ª•m: 9

üìÑ N·ªòI DUNG FILE (preview):
----------------------------------------------------------------------
Cluster 0: [-0.003, -0.003, -0.001, 0.722, -0.346...]
Cluster 1: [-0.003, -0.003, -0.001, 1.410, -1.454...]
Cluster 2: [-0.003, -0.003, -0.001, -1.204, -1.454...]
Cluster 3: [-0.003, -0.003, -0.001, 0.034, 1.315...]
Cluster 4: [-0.002, -0.002, -0.001, 1.548, -1.454...]

‚ö†Ô∏è  QUAN TR·ªåNG:
   C·∫£ 2 file t·∫°m (hadoop_input_temp.txt v√† centroids_temp.txt)
   s·∫Ω B·ªä X√ìA sau khi upload l√™n HDFS (B∆∞·ªõc 4)
   D·ªØ li·ªáu ch·ªâ l∆∞u tr√™n HDFS ƒë·ªÉ tu√¢n th·ªß quy ƒë·ªãnh b·∫£o m·∫≠t

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 4: ./scripts/spark/setup_hdfs.sh

‚è±Ô∏è  **B∆∞·ªõc 3 ho√†n th√†nh trong 13s**

### B∆∞·ªõc 4: Upload d·ªØ li·ªáu l√™n HDFS

=== THI·∫æT L·∫¨P HDFS CHO PYSPARK K-MEANS ===
‚úÖ HDFS c√≥ th·ªÉ truy c·∫≠p

‚úÖ ƒê√£ t√¨m th·∫•y file d·ªØ li·ªáu t·∫°m

ƒêang t·∫°o th∆∞ m·ª•c HDFS...
ƒêang d·ªçn d·∫πp d·ªØ li·ªáu c≈© trong HDFS...
Deleted /user/spark/hi_large/input/hadoop_input.txt
Deleted /user/spark/hi_large/centroids.txt
Deleted /user/spark/hi_large/output_centroids

ƒêang upload d·ªØ li·ªáu ƒë·∫ßu v√†o l√™n HDFS...
  Ngu·ªìn: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
  ƒê√≠ch: /user/spark/hi_large/input/hadoop_input.txt

ƒêang upload t√¢m c·ª•m l√™n HDFS...
  Ngu·ªìn: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
  ƒê√≠ch: /user/spark/hi_large/centroids.txt

ƒêang d·ªçn d·∫πp file t·∫°m...
‚úÖ ƒê√£ x√≥a file t·∫°m (d·ªØ li·ªáu ch·ªâ c√≤n tr√™n HDFS)

ƒêang x√°c minh upload...
  ‚úÖ D·ªØ li·ªáu ƒë·∫ßu v√†o: 31.1 G
  ‚úÖ T√¢m c·ª•m: 433 433

C·∫•u tr√∫c th∆∞ m·ª•c HDFS:
-rw-r--r--   1 ultimatebrok supergroup        433 2025-10-29 01:46 /user/spark/hi_large/centroids.txt
drwxr-xr-x   - ultimatebrok supergroup          0 2025-10-29 01:46 /user/spark/hi_large/input
-rw-r--r--   1 ultimatebrok supergroup 33362225336 2025-10-29 01:46 /user/spark/hi_large/input/hadoop_input.txt
drwxr-xr-x   - ultimatebrok supergroup           0 2025-10-28 16:52 /user/spark/hi_large/output

===================================
‚úÖ HO√ÄN T·∫§T THI·∫æT L·∫¨P HDFS!
===================================

ƒê∆∞·ªùng d·∫´n HDFS:
  ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

B∆∞·ªõc ti·∫øp theo: Ch·∫°y PySpark job
  ./scripts/spark/run_spark.sh
‚è±Ô∏è  **B∆∞·ªõc 4 ho√†n th√†nh trong 41s**

### B∆∞·ªõc 5: Ch·∫°y PySpark K-means tr√™n HDFS

=== PYSPARK K-MEANS V·ªöI HDFS ===
C·∫•u h√¨nh:
  CPU cores: 24
  S·ªë executor: 4
  Executor cores: 4
  Executor memory: 4g
  Driver memory: 4g

ƒê∆∞·ªùng d·∫´n HDFS:
  ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

ƒêang d·ªçn d·∫πp k·∫øt qu·∫£ c≈©...
ƒêang ch·∫°y PySpark K-means clustering tr√™n HDFS...
S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa: 15

WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 01:46:31 WARN Utils: Your hostname, brokie-hx370, resolves to a loopback address: 127.0.1.1; using 192.168.1.10 instead (on interface wlan0)
25/10/29 01:46:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
HDFS ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
HDFS T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
HDFS ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 01:46:32 INFO SparkContext: Running Spark version 4.0.1
25/10/29 01:46:32 INFO SparkContext: OS info Linux, 6.17.5-2-cachyos, amd64
25/10/29 01:46:32 INFO SparkContext: Java version 17.0.16
25/10/29 01:46:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO SparkContext: Submitted application: K-means Clustering - HDFS
25/10/29 01:46:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/29 01:46:32 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
25/10/29 01:46:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkDriver' on port 41517.
25/10/29 01:46:32 INFO SparkEnv: Registering MapOutputTracker
25/10/29 01:46:32 INFO SparkEnv: Registering BlockManagerMaster
25/10/29 01:46:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/29 01:46:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/29 01:46:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/29 01:46:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7337e060-8b86-400e-93eb-fe255173b67f
25/10/29 01:46:32 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/29 01:46:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO LocalSparkCluster: Starting a local Spark cluster with 4 workers.
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkMaster' on port 45357.
25/10/29 01:46:32 INFO Master: Starting Spark master at spark://192.168.1.10:45357
25/10/29 01:46:32 INFO Master: Running Spark version 4.0.1
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:0 for MasterUI
25/10/29 01:46:32 INFO Utils: Successfully started service 'MasterUI' on port 36869.
25/10/29 01:46:32 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://192.168.1.10:36869
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO Master: I have been elected leader! New state: ALIVE
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkWorker1' on port 40779.
25/10/29 01:46:32 INFO Worker: Worker decommissioning not enabled.
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO Worker: Starting Spark worker 192.168.1.10:40779 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Worker: Running Spark version 4.0.1
25/10/29 01:46:32 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkWorker2' on port 43139.
25/10/29 01:46:32 INFO Worker: Worker decommissioning not enabled.
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO Worker: Starting Spark worker 192.168.1.10:43139 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO Worker: Running Spark version 4.0.1
25/10/29 01:46:32 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 01:46:32 INFO Utils: Successfully started service 'WorkerUI' on port 35283.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 01:46:32 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.10:35283
25/10/29 01:46:32 INFO Worker: Connecting to master 192.168.1.10:45357...
25/10/29 01:46:32 INFO Utils: Successfully started service 'WorkerUI' on port 38371.
25/10/29 01:46:32 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.10:38371
25/10/29 01:46:32 INFO Worker: Connecting to master 192.168.1.10:45357...
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkWorker3' on port 36061.
25/10/29 01:46:32 INFO Worker: Worker decommissioning not enabled.
25/10/29 01:46:32 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:32 INFO Worker: Starting Spark worker 192.168.1.10:36061 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Worker: Running Spark version 4.0.1
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:32 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 01:46:32 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 01:46:32 INFO Utils: Successfully started service 'WorkerUI' on port 40075.
25/10/29 01:46:32 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.10:40075
25/10/29 01:46:32 INFO Worker: Connecting to master 192.168.1.10:45357...
25/10/29 01:46:32 INFO Utils: Successfully started service 'sparkWorker4' on port 44033.
25/10/29 01:46:32 INFO Worker: Worker decommissioning not enabled.
25/10/29 01:46:32 INFO Worker: Starting Spark worker 192.168.1.10:44033 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Worker: Running Spark version 4.0.1
25/10/29 01:46:32 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 01:46:32 INFO ResourceUtils: ==============================================================
25/10/29 01:46:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.10:45357 after 1 ms (0 ms spent in bootstraps)
25/10/29 01:46:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.10:45357 after 28 ms (0 ms spent in bootstraps)
25/10/29 01:46:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.10:45357 after 15 ms (0 ms spent in bootstraps)
25/10/29 01:46:32 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 01:46:32 INFO Utils: Successfully started service 'WorkerUI' on port 37207.
25/10/29 01:46:32 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.10:37207
25/10/29 01:46:32 INFO Worker: Connecting to master 192.168.1.10:45357...
25/10/29 01:46:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.10:45357 after 1 ms (0 ms spent in bootstraps)
25/10/29 01:46:32 INFO Master: Registering worker 192.168.1.10:40779 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Master: Registering worker 192.168.1.10:36061 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Master: Registering worker 192.168.1.10:44033 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Worker: Successfully registered with master spark://192.168.1.10:45357
25/10/29 01:46:32 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 01:46:32 INFO Master: Registering worker 192.168.1.10:43139 with 4 cores, 4.0 GiB RAM
25/10/29 01:46:32 INFO Worker: Successfully registered with master spark://192.168.1.10:45357
25/10/29 01:46:32 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 01:46:32 INFO Worker: Successfully registered with master spark://192.168.1.10:45357
25/10/29 01:46:32 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 01:46:32 INFO Worker: Successfully registered with master spark://192.168.1.10:45357
25/10/29 01:46:32 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 01:46:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://192.168.1.10:45357...
25/10/29 01:46:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.10:45357 after 1 ms (0 ms spent in bootstraps)
25/10/29 01:46:32 INFO Master: Registering app K-means Clustering - HDFS
25/10/29 01:46:32 INFO Master: Registered app K-means Clustering - HDFS with ID app-20251029014632-0000
25/10/29 01:46:32 INFO Master: Start scheduling for app app-20251029014632-0000 with rpId: 0
25/10/29 01:46:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251029014632-0000
25/10/29 01:46:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38723.
25/10/29 01:46:33 INFO NettyBlockTransferService: Server created on 192.168.1.10:38723
25/10/29 01:46:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/29 01:46:33 INFO Master: Launching executor app-20251029014632-0000/0 on worker worker-20251029014632-192.168.1.10-44033
25/10/29 01:46:33 INFO Master: Launching executor app-20251029014632-0000/1 on worker worker-20251029014632-192.168.1.10-43139
25/10/29 01:46:33 INFO Master: Launching executor app-20251029014632-0000/2 on worker worker-20251029014632-192.168.1.10-40779
25/10/29 01:46:33 INFO Master: Launching executor app-20251029014632-0000/3 on worker worker-20251029014632-192.168.1.10-36061
25/10/29 01:46:33 INFO Worker: Asked to launch executor app-20251029014632-0000/0 for K-means Clustering - HDFS
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029014632-0000/0 on worker-20251029014632-192.168.1.10-44033 (192.168.1.10:44033) with 4 core(s)
25/10/29 01:46:33 INFO Worker: Asked to launch executor app-20251029014632-0000/2 for K-means Clustering - HDFS
25/10/29 01:46:33 INFO Worker: Asked to launch executor app-20251029014632-0000/1 for K-means Clustering - HDFS
25/10/29 01:46:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029014632-0000/0 on hostPort 192.168.1.10:44033 with 4 core(s), 4.0 GiB RAM
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029014632-0000/1 on worker-20251029014632-192.168.1.10-43139 (192.168.1.10:43139) with 4 core(s)
25/10/29 01:46:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029014632-0000/1 on hostPort 192.168.1.10:43139 with 4 core(s), 4.0 GiB RAM
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029014632-0000/2 on worker-20251029014632-192.168.1.10-40779 (192.168.1.10:40779) with 4 core(s)
25/10/29 01:46:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029014632-0000/2 on hostPort 192.168.1.10:40779 with 4 core(s), 4.0 GiB RAM
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029014632-0000/3 on worker-20251029014632-192.168.1.10-36061 (192.168.1.10:36061) with 4 core(s)
25/10/29 01:46:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029014632-0000/3 on hostPort 192.168.1.10:36061 with 4 core(s), 4.0 GiB RAM
25/10/29 01:46:33 INFO Worker: Asked to launch executor app-20251029014632-0000/3 for K-means Clustering - HDFS
25/10/29 01:46:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.10, 38723, None)
25/10/29 01:46:33 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 01:46:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 01:46:33 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.10:38723 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.1.10, 38723, None)
25/10/29 01:46:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.10, 38723, None)
25/10/29 01:46:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.10, 38723, None)
25/10/29 01:46:33 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=41517" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.10:41517" "--executor-id" "0" "--hostname" "192.168.1.10" "--cores" "4" "--app-id" "app-20251029014632-0000" "--worker-url" "spark://Worker@192.168.1.10:44033" "--resourceProfileId" "0"
25/10/29 01:46:33 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=41517" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.10:41517" "--executor-id" "1" "--hostname" "192.168.1.10" "--cores" "4" "--app-id" "app-20251029014632-0000" "--worker-url" "spark://Worker@192.168.1.10:43139" "--resourceProfileId" "0"
25/10/29 01:46:33 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=41517" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.10:41517" "--executor-id" "2" "--hostname" "192.168.1.10" "--cores" "4" "--app-id" "app-20251029014632-0000" "--worker-url" "spark://Worker@192.168.1.10:40779" "--resourceProfileId" "0"
25/10/29 01:46:33 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=41517" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.10:41517" "--executor-id" "3" "--hostname" "192.168.1.10" "--cores" "4" "--app-id" "app-20251029014632-0000" "--worker-url" "spark://Worker@192.168.1.10:36061" "--resourceProfileId" "0"
25/10/29 01:46:33 INFO Master: Start scheduling for app app-20251029014632-0000 with rpId: 0
25/10/29 01:46:33 INFO Master: Start scheduling for app app-20251029014632-0000 with rpId: 0
25/10/29 01:46:33 INFO Master: Start scheduling for app app-20251029014632-0000 with rpId: 0
25/10/29 01:46:33 INFO Master: Start scheduling for app app-20251029014632-0000 with rpId: 0
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029014632-0000/2 is now RUNNING
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029014632-0000/3 is now RUNNING
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029014632-0000/1 is now RUNNING
25/10/29 01:46:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029014632-0000/0 is now RUNNING
25/10/29 01:46:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/10/29 01:46:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.10:45090) with ID 3, ResourceProfileId 0
25/10/29 01:46:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.10:45108) with ID 2, ResourceProfileId 0
25/10/29 01:46:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.10:45128) with ID 1, ResourceProfileId 0
25/10/29 01:46:34 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.10:35833 with 2.2 GiB RAM, BlockManagerId(3, 192.168.1.10, 35833, None)
25/10/29 01:46:34 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.10:44205 with 2.2 GiB RAM, BlockManagerId(2, 192.168.1.10, 44205, None)
=== PYSPARK K-MEANS CLUSTERING ===
ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa: 15

ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ HDFS...
ƒê√£ load 179,702,229 ƒëi·ªÉm t·ª´ hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
ƒêang ƒë·ªçc t√¢m c·ª•m t·ª´ hdfs://localhost:9000/user/spark/hi_large/centroids.txt
ƒê√£ kh·ªüi t·∫°o 5 t√¢m c·ª•m

=== L·∫ßn l·∫∑p 1/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 3.235698

=== L·∫ßn l·∫∑p 2/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.432947

=== L·∫ßn l·∫∑p 3/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.229976

=== L·∫ßn l·∫∑p 4/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.143134

=== L·∫ßn l·∫∑p 5/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.113795

=== L·∫ßn l·∫∑p 6/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.093823

=== L·∫ßn l·∫∑p 7/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.064364

=== L·∫ßn l·∫∑p 8/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.051341

=== L·∫ßn l·∫∑p 9/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.048377

=== L·∫ßn l·∫∑p 10/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.053732

=== L·∫ßn l·∫∑p 11/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.065842

=== L·∫ßn l·∫∑p 12/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.090034

=== L·∫ßn l·∫∑p 13/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.064394

=== L·∫ßn l·∫∑p 14/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.036974

=== L·∫ßn l·∫∑p 15/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.027681


ƒêang l∆∞u t√¢m c·ª•m cu·ªëi c√πng v√†o HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

K√≠ch th∆∞·ªõc c√°c c·ª•m:
  C·ª•m 0: 54,769,409 ƒëi·ªÉm (30.48%)
  C·ª•m 1: 48,758,953 ƒëi·ªÉm (27.13%)
  C·ª•m 2: 12,028,812 ƒëi·ªÉm (6.69%)
  C·ª•m 3: 52,250,781 ƒëi·ªÉm (29.08%)
  C·ª•m 4: 11,894,274 ƒëi·ªÉm (6.62%)

‚úÖ Ho√†n th√†nh thu·∫≠t to√°n K-means clustering!

‚úÖ PySpark K-means ho√†n th√†nh!
T√¢m c·ª•m cu·ªëi c√πng ƒë√£ l∆∞u v√†o HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

ƒê·ªÉ xem k·∫øt qu·∫£:
  hdfs dfs -cat /user/spark/hi_large/output_centroids/part-*
‚è±Ô∏è  **B∆∞·ªõc 5 ho√†n th√†nh trong 27m 12s**

### B∆∞·ªõc 6: T·∫£i k·∫øt qu·∫£ t·ª´ HDFS

=== T·∫¢I K·∫æT QU·∫¢ T·ª™ HDFS ===
‚úÖ ƒê√£ t√¨m th·∫•y k·∫øt qu·∫£ trong HDFS

ƒêang t·∫£i t√¢m c·ª•m cu·ªëi c√πng...
  T·ª´: /user/spark/hi_large/output_centroids
  ƒê·∫øn: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt
‚úÖ ƒê√£ t·∫£i t√¢m c·ª•m cu·ªëi c√πng

Th√¥ng tin file local:
  K√≠ch th∆∞·ªõc: 4,0K
  S·ªë d√≤ng (c·ª•m): 5

Xem tr∆∞·ªõc:
0.000904,-0.000975,-0.000284,-0.253267,0.001022,-1.017996,-0.312873,-0.326412,-0.394462
-0.001889,-0.001293,-0.001119,0.140210,-0.953760,0.550492,-0.376812,-0.371990,0.188914
-0.000537,0.000476,0.011740,-0.861240,0.008797,-0.074549,2.314222,2.328195,-0.000088
-0.001620,-0.000956,-0.001112,0.132610,0.876193,0.554546,-0.378161,-0.373485,0.205698
0.011187,0.013501,-0.001112,0.886969,-0.009831,0.097185,2.304992,2.313215,0.148116

‚úÖ Ho√†n th√†nh t·∫£i xu·ªëng!

B∆∞·ªõc ti·∫øp theo:
  1. G√°n c·ª•m: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python assign_clusters_polars.py
  2. Ph√¢n t√≠ch k·∫øt qu·∫£: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python analyze_polars.py
‚è±Ô∏è  **B∆∞·ªõc 6 ho√†n th√†nh trong 3s**

### B∆∞·ªõc 7: G√°n c·ª•m v·ªõi Polars

======================================================================
üè∑Ô∏è  B∆Ø·ªöC 7: G√ÅN NH√ÉN C·ª§M CHO T·ªÆNG GIAO D·ªäCH
======================================================================

üéØ ƒê·ªåC T√ÇM C·ª§M CU·ªêI C√ôNG T·ª™ B∆Ø·ªöC 6...
   File: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt

‚úÖ ƒê√£ load 5 t√¢m c·ª•m
   M·ªói t√¢m c·ª•m c√≥ 9 ƒë·∫∑c tr∆∞ng

üìÇ ƒê·ªåC D·ªÆ LI·ªÜU T·ª™ HDFS...
   File HDFS: /user/spark/hi_large/input/hadoop_input.txt
   (179M d√≤ng, 33GB - ƒë√£ chu·∫©n h√≥a)

üîÑ Streaming t·ª´ HDFS (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...
üìä ƒêang ƒë·ªçc CSV t·ª´ HDFS stream...

‚úÖ ƒê√£ load 179,702,229 b·∫£n ghi t·ª´ HDFS

üìä CHUY·ªÇN SANG NUMPY V√Ä T√çNH KHO·∫¢NG C√ÅCH...
   D·ªØ li·ªáu: 179,702,229 d√≤ng x 9 c·ªôt
   T√¢m c·ª•m: 5 c·ª•m x 9 ƒë·∫∑c tr∆∞ng

üî¢ T√çNH KHO·∫¢NG C√ÅCH EUCLIDEAN (Batch Processing)...
   X·ª≠ l√Ω 1 tri·ªáu giao d·ªãch m·ªói l·∫ßn ƒë·ªÉ ti·∫øt ki·ªám RAM

    ƒê√£ x·ª≠ l√Ω 1,000,000/179,702,229 giao d·ªãch (0.6%)
    ƒê√£ x·ª≠ l√Ω 11,000,000/179,702,229 giao d·ªãch (6.1%)
    ƒê√£ x·ª≠ l√Ω 21,000,000/179,702,229 giao d·ªãch (11.7%)
    ƒê√£ x·ª≠ l√Ω 31,000,000/179,702,229 giao d·ªãch (17.3%)
    ƒê√£ x·ª≠ l√Ω 41,000,000/179,702,229 giao d·ªãch (22.8%)
    ƒê√£ x·ª≠ l√Ω 51,000,000/179,702,229 giao d·ªãch (28.4%)
    ƒê√£ x·ª≠ l√Ω 61,000,000/179,702,229 giao d·ªãch (33.9%)
    ƒê√£ x·ª≠ l√Ω 71,000,000/179,702,229 giao d·ªãch (39.5%)
    ƒê√£ x·ª≠ l√Ω 81,000,000/179,702,229 giao d·ªãch (45.1%)
    ƒê√£ x·ª≠ l√Ω 91,000,000/179,702,229 giao d·ªãch (50.6%)
    ƒê√£ x·ª≠ l√Ω 101,000,000/179,702,229 giao d·ªãch (56.2%)
    ƒê√£ x·ª≠ l√Ω 111,000,000/179,702,229 giao d·ªãch (61.8%)
    ƒê√£ x·ª≠ l√Ω 121,000,000/179,702,229 giao d·ªãch (67.3%)
    ƒê√£ x·ª≠ l√Ω 131,000,000/179,702,229 giao d·ªãch (72.9%)
    ƒê√£ x·ª≠ l√Ω 141,000,000/179,702,229 giao d·ªãch (78.5%)
    ƒê√£ x·ª≠ l√Ω 151,000,000/179,702,229 giao d·ªãch (84.0%)
    ƒê√£ x·ª≠ l√Ω 161,000,000/179,702,229 giao d·ªãch (89.6%)
    ƒê√£ x·ª≠ l√Ω 171,000,000/179,702,229 giao d·ªãch (95.2%)
    ƒê√£ x·ª≠ l√Ω 179,702,229/179,702,229 giao d·ªãch (100.0%)

‚úÖ ƒê√£ ho√†n th√†nh t√≠nh to√°n cho 179,702,229 giao d·ªãch

üíæ L∆ØU K·∫æT QU·∫¢...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
======================================================================
‚úÖ HO√ÄN T·∫§T G√ÅN NH√ÉN C·ª§M!
======================================================================
üìÑ File k·∫øt qu·∫£: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
üìä K√≠ch th∆∞·ªõc: 342.75 MB
üìä T·ªïng giao d·ªãch: 179,702,229

üìä PH√ÇN PH·ªêI C·ª§M:
   Cluster 0: 54,769,397 giao d·ªãch (30.48%)
   Cluster 1: 48,758,964 giao d·ªãch (27.13%)
   Cluster 2: 12,028,821 giao d·ªãch (6.69%)
   Cluster 3: 52,250,789 giao d·ªãch (29.08%)
   Cluster 4: 11,894,258 giao d·ªãch (6.62%)

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 8: python scripts/polars/analyze_polars.py

‚è±Ô∏è  **B∆∞·ªõc 7 ho√†n th√†nh trong 3m 21s**

### B∆∞·ªõc 8: Ph√¢n t√≠ch k·∫øt qu·∫£

======================================================================
üìä B∆Ø·ªöC 8: PH√ÇN T√çCH K·∫æT QU·∫¢
======================================================================

üìÇ ƒê·ªåC K·∫æT QU·∫¢ PH√ÇN C·ª§M T·ª™ B∆Ø·ªöC 7...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
‚úÖ ƒê√£ load 179,702,229 nh√£n c·ª•m

üìä ƒê·ªåC D·ªÆ LI·ªÜU G·ªêC (Lazy Mode)...
   File: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
‚úÖ ƒê√£ load metadata (ch∆∞a load to√†n b·ªô v√†o RAM)

üéØ TH√äM C·ªòT 'cluster' V√ÄO DATA...
‚úÖ ƒê√£ g·∫Øn nh√£n c·ª•m cho m·ªói giao d·ªãch

======================================================================
üìã PH√ÇN T√çCH CHI TI·∫æT
======================================================================

üìà TH·ªêNG K√ä T·ªîNG QUAN:
   T·ªïng s·ªë giao d·ªãch: 179,702,229
   S·ªë c·ª•m: 5

üìâ K√çCH TH∆Ø·ªöC M·ªñI C·ª§M:
----------------------------------------------------------------------
shape: (5, 2)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ count    ‚îÇ
‚îÇ ---     ‚îÜ ---      ‚îÇ
‚îÇ i64     ‚îÜ u32      ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 54769397 ‚îÇ
‚îÇ 1       ‚îÜ 48758964 ‚îÇ
‚îÇ 2       ‚îÜ 12028821 ‚îÇ
‚îÇ 3       ‚îÜ 52250789 ‚îÇ
‚îÇ 4       ‚îÜ 11894258 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí∞ T·ª∂ L·ªÜ R·ª¨A TI·ªÄN TRONG T·ªÆNG C·ª§M:
----------------------------------------------------------------------
shape: (5, 4)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ total    ‚îÜ laundering_count ‚îÜ laundering_rate ‚îÇ
‚îÇ ---     ‚îÜ ---      ‚îÜ ---              ‚îÜ ---             ‚îÇ
‚îÇ i64     ‚îÜ u32      ‚îÜ i64              ‚îÜ f64             ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 54769397 ‚îÜ 48365            ‚îÜ 0.088307        ‚îÇ
‚îÇ 1       ‚îÜ 48758964 ‚îÜ 69348            ‚îÜ 0.142226        ‚îÇ
‚îÇ 2       ‚îÜ 12028821 ‚îÜ 6842             ‚îÜ 0.05688         ‚îÇ
‚îÇ 3       ‚îÜ 52250789 ‚îÜ 92071            ‚îÜ 0.17621         ‚îÇ
‚îÇ 4       ‚îÜ 11894258 ‚îÜ 8920             ‚îÜ 0.074994        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö†Ô∏è  C·ª§M C√ì R·ª¶I RO CAO (>10% r·ª≠a ti·ªÅn):
----------------------------------------------------------------------
‚úÖ KH√îNG c√≥ c·ª•m n√†o v∆∞·ª£t ng∆∞·ª°ng 10%
   T·∫•t c·∫£ c√°c c·ª•m ƒë·ªÅu trong m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.

üìä ƒê·∫∂C TR∆ØNG TRUNG B√åNH M·ªñI C·ª§M:
----------------------------------------------------------------------
shape: (5, 4)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ avg_amount_received ‚îÜ avg_amount_paid ‚îÜ avg_ratio ‚îÇ
‚îÇ ---     ‚îÜ ---                 ‚îÜ ---             ‚îÜ ---       ‚îÇ
‚îÇ i64     ‚îÜ f64                 ‚îÜ f64             ‚îÜ f64       ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 7.2806e6            ‚îÜ 2.6325e6        ‚îÜ 1.703137  ‚îÇ
‚îÇ 1       ‚îÜ 2.1848e6            ‚îÜ 2.1848e6        ‚îÜ 0.999988  ‚îÇ
‚îÇ 2       ‚îÜ 4.6350e6            ‚îÜ 4.6374e6        ‚îÜ 11.811974 ‚îÇ
‚îÇ 3       ‚îÜ 2.6538e6            ‚îÜ 2.6351e6        ‚îÜ 1.005274  ‚îÇ
‚îÇ 4       ‚îÜ 2.5882e7            ‚îÜ 2.2697e7        ‚îÜ 1.005467  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí° NH·∫¨N X√âT:
----------------------------------------------------------------------
1. C·ª§m nghi ng·ªù NH·∫§T: Cluster 3 (0.18% r·ª≠a ti·ªÅn)
   ‚û°Ô∏è  N√™n ki·ªÉm tra k·ªπ c√°c giao d·ªãch trong c·ª•m n√†y

2. C·ª•m an to√†n NH·∫§T: Cluster 2 (0.06% r·ª≠a ti·ªÅn)
   ‚û°Ô∏è  C√≥ th·ªÉ ∆∞u ti√™n th·∫•p khi ki·ªÉm tra

3. ƒê√°nh gi√° t·ªïng th·ªÉ: ‚úÖ R·ª¶I RO TH·∫§P
   H·ªá th·ªëng ho·∫°t ƒë·ªông t·ªët, t·ª∑ l·ªá r·ª≠a ti·ªÅn th·∫•p

======================================================================
‚úÖ HO√ÄN T·∫§T PH√ÇN T√çCH!
======================================================================

üìä T√ìM T·∫¢T:
   - ƒê√£ ph√¢n t√≠ch 179,702,229 giao d·ªãch
   - Ph√¢n th√†nh 5 c·ª•m
   - T·ª∑ l·ªá r·ª≠a ti·ªÅn: 0.06% - 0.18%
   - S·ªë c·ª•m r·ªßi ro cao: 0 (‚úÖ T·ªët!)

üéâ PIPELINE HO√ÄN T·∫§T!
   T·∫•t c·∫£ 8 b∆∞·ªõc ƒë√£ ch·∫°y th√†nh c√¥ng.
   Xem k·∫øt qu·∫£ trong th∆∞ m·ª•c data/results/

‚è±Ô∏è  **B∆∞·ªõc 8 ho√†n th√†nh trong 30s**


---

## T·ªïng k·∫øt

‚úÖ **Pipeline ho√†n th√†nh th√†nh c√¥ng!**

**Th·ªùi gian k·∫øt th√∫c:** 2025-10-29 02:17:32
**T·ªïng th·ªùi gian ch·∫°y:** 33m 18s

---

*Log ƒë√£ l∆∞u t·∫°i: /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_014414.md*
