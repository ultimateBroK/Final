# Polars + PySpark Pipeline Execution Log

**Thời gian bắt đầu:** 2025-10-29 08:45:54
**File log:** /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_084554.md

---

## Thực thi Pipeline

=== POLARS + PYSPARK PIPELINE ===
Thời gian bắt đầu: 2025-10-29 08:45:54
### Bước 1: Khám phá dữ liệu

======================================================================
🔍 BƯỚC 1: KHÁM PHÁ DỮ LIỆU
======================================================================
Đang đọc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui lòng đợi...

✅ Đã load metadata thành công!

📋 SCHEMA (Cấu trúc dữ liệu):
----------------------------------------------------------------------
<bound method LazyFrame.collect_schema of <LazyFrame at 0x7FB261C786B0>>

📊 LẤY MẪU 100,000 DÒNG ĐẦU:
----------------------------------------------------------------------
Dữ liệu mẫu:
shape: (100_000, 11)
┌────────────┬───────────┬───────────┬─────────┬───┬───────────┬───────────┬───────────┬───────────┐
│ Timestamp  ┆ From Bank ┆ Account   ┆ To Bank ┆ … ┆ Amount    ┆ Payment   ┆ Payment   ┆ Is Launde │
│ ---        ┆ ---       ┆ ---       ┆ ---     ┆   ┆ Paid      ┆ Currency  ┆ Format    ┆ ring      │
│ str        ┆ i64       ┆ str       ┆ i64     ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │
│            ┆           ┆           ┆         ┆   ┆ f64       ┆ str       ┆ str       ┆ i64       │
╞════════════╪═══════════╪═══════════╪═════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡
│ 2022/08/01 ┆ 20        ┆ 800104D70 ┆ 20      ┆ … ┆ 6794.63   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:17      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 3196      ┆ 800107150 ┆ 3196    ┆ … ┆ 7739.29   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:02      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E430 ┆ 1208    ┆ … ┆ 1880.23   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:17      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E650 ┆ 20      ┆ … ┆ 7.3966883 ┆ US Dollar ┆ Cheque    ┆ 0         │
│ 00:03      ┆           ┆           ┆         ┆   ┆ e7        ┆           ┆           ┆           │
│ 2022/08/01 ┆ 1208      ┆ 80010E650 ┆ 20      ┆ … ┆ 4.5868454 ┆ US Dollar ┆ Cheque    ┆ 0         │
│ 00:02      ┆           ┆           ┆         ┆   ┆ e7        ┆           ┆           ┆           │
│ …          ┆ …         ┆ …         ┆ …       ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │
│ 2022/08/01 ┆ 111667    ┆ 80E5D9320 ┆ 111667  ┆ … ┆ 23.93     ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:06      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 25994     ┆ 80E5DBF50 ┆ 25994   ┆ … ┆ 23.41     ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:18      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 310328    ┆ 80E5ED350 ┆ 310328  ┆ … ┆ 3297.82   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:04      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 5838      ┆ 80E5ED580 ┆ 5838    ┆ … ┆ 3032.53   ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:19      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
│ 2022/08/01 ┆ 339249    ┆ 80E5ED620 ┆ 339249  ┆ … ┆ 13043.39  ┆ US Dollar ┆ Reinvestm ┆ 0         │
│ 00:26      ┆           ┆           ┆         ┆   ┆           ┆           ┆ ent       ┆           │
└────────────┴───────────┴───────────┴─────────┴───┴───────────┴───────────┴───────────┴───────────┘

Thống kê mô tả:
shape: (9, 12)
┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐
│ statistic ┆ Timestamp ┆ From Bank ┆ Account   ┆ … ┆ Amount    ┆ Payment   ┆ Payment   ┆ Is Laund │
│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ Paid      ┆ Currency  ┆ Format    ┆ ering    │
│ str       ┆ str       ┆ f64       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │
│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆ str       ┆ f64      │
╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡
│ count     ┆ 100000    ┆ 100000.0  ┆ 100000    ┆ … ┆ 100000.0  ┆ 100000    ┆ 100000    ┆ 100000.0 │
│ null_coun ┆ 0         ┆ 0.0       ┆ 0         ┆ … ┆ 0.0       ┆ 0         ┆ 0         ┆ 0.0      │
│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │
│ mean      ┆ null      ┆ 49669.967 ┆ null      ┆ … ┆ 1.1422e6  ┆ null      ┆ null      ┆ 0.00001  │
│           ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │
│ std       ┆ null      ┆ 80891.260 ┆ null      ┆ … ┆ 2.9890e7  ┆ null      ┆ null      ┆ 0.003162 │
│           ┆           ┆ 568       ┆           ┆   ┆           ┆           ┆           ┆          │
│ min       ┆ 2022/08/0 ┆ 0.0       ┆ 100428660 ┆ … ┆ 0.01      ┆ Australia ┆ ACH       ┆ 0.0      │
│           ┆ 1 00:00   ┆           ┆           ┆   ┆           ┆ n Dollar  ┆           ┆          │
│ 25%       ┆ null      ┆ 4214.0    ┆ null      ┆ … ┆ 20.53     ┆ null      ┆ null      ┆ 0.0      │
│ 50%       ┆ null      ┆ 15240.0   ┆ null      ┆ … ┆ 2513.06   ┆ null      ┆ null      ┆ 0.0      │
│ 75%       ┆ null      ┆ 31996.0   ┆ null      ┆ … ┆ 28769.41  ┆ null      ┆ null      ┆ 0.0      │
│ max       ┆ 2022/08/0 ┆ 339249.0  ┆ 80E5ED620 ┆ … ┆ 5.1154e9  ┆ Yuan      ┆ Wire      ┆ 1.0      │
│           ┆ 1 00:29   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │
└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘

💰 PHÂN TÍCH TỶ LỆ RỬA TIỀN:
----------------------------------------------------------------------
shape: (2, 1)
┌───────────────┐
│ Is Laundering │
│ ---           │
│ struct[2]     │
╞═══════════════╡
│ {1,225546}    │
│ {0,179476683} │
└───────────────┘

💵 TOP 10 LOẠI TIỀN TỆ PHỔ BIẾN:
----------------------------------------------------------------------
shape: (10, 1)
┌─────────────────────────────┐
│ Receiving Currency          │
│ ---                         │
│ struct[2]                   │
╞═════════════════════════════╡
│ {"UK Pound",5748874}        │
│ {"Ruble",5571567}           │
│ {"Rupee",4178243}           │
│ {"US Dollar",65292945}      │
│ {"Shekel",8047876}          │
│ {"Canadian Dollar",6140322} │
│ {"Bitcoin",3958153}         │
│ {"Yen",4841570}             │
│ {"Saudi Riyal",3228262}     │
│ {"Yuan",12920668}           │
└─────────────────────────────┘

======================================================================
✅ HOÀN TẤT KHÁM PHÁ DỮ LIỆU!
======================================================================

💡 GỢI Ý TIẾP THEO:
   Chạy bước 2: python scripts/polars/prepare_polars.py

⏱️  **Bước 1 hoàn thành trong 12s**

### Bước 2: Chuẩn bị đặc trưng với Polars

======================================================================
🔧 BƯỚC 2: XỬ LÝ VÀ TRÍCH XUẤT ĐẶC TRƯNG
======================================================================
Đọc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui lòng đợi (có thể mất 5-10 phút)...

✅ Đã load 179,702,229 dòng vào RAM

🌟 TRÍCH XUẤT ĐẶC TRƯNG TỪ DỮ LIỆU THÔ...
✅ Đã trích xuất 10 đặc trưng

🔢 MÃ HÓA BIẾN PHÂN LOẠI (CATEGORICAL ENCODING)...
✅ Đã mã hóa thành số

📊 Có 9 đặc trưng số cho K-means

📊 CHUẨN HÓA DỮ LIỆU (Min-Max Scaling)...
✅ Đã chuẩn hóa 9 đặc trưng

💾 LƯU FILE TẠM THỜI CHO HDFS...
⚠️  LƯU Ý: File này sẽ tự động xóa sau khi upload HDFS!

   Đang ghi: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
   Vui lòng đợi (có thể mất 3-5 phút)...

======================================================================
✅ HOÀN TẤT XỬ LÝ DỮ LIỆU!
======================================================================
📄 File tạm: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
📊 Kích thước: 30.91 GB
📊 Số dòng: 179,702,229
📊 Số đặc trưng: 9
📊 Các đặc trưng: ['amount_received', 'amount_paid', 'amount_ratio', 'hour', 'day_of_week', 'route_hash', 'recv_curr_encoded', 'payment_curr_encoded', 'payment_format_encoded']

⚠️  QUAN TRỌNG:
   File này chỉ tồn tại TẠM THỜI!
   Nó sẽ BỊ XÓA sau khi upload lên HDFS (Bước 4)
   Dữ liệu chỉ lưu trên HDFS để tuân thủ quy định bảo mật

💡 GỢI Ý TIẾP THEO:
   Chạy bước 3: python scripts/polars/init_centroids.py

⏱️  **Bước 2 hoàn thành trong 1m 0s**

### Bước 3: Khởi tạo tâm cụm

======================================================================
🎯 BƯỚC 3: KHỚI TẠO TÂM CỤM BAN ĐẦU
======================================================================

Kiểm tra file input: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
✅ File input tồn tại!

📊 ĐỌC DỮ LIỆU ĐÃ CHUẨN HÓA...
✅ Đã load 179,702,229 dòng với 9 đặc trưng

🎲 LẤY MẪU NGẪU NHIÊN ĐỂ KHỚI TẠO...
   Số mẫu: 100,000 dòng
✅ Đã lấy mẫu 100,000 điểm

🎯 KHỚI TẠO 5 TÂM CỤM BAN ĐẦU...
   Thuật toán: Chọn ngẫu nhiên 5 điểm từ 100,000 mẫu

✅ Đã chọn 5 tâm cụm ban đầu
   Mỗi tâm cụm có 9 đặc trưng

💾 LƯU TÂM CỤM VÀO FILE TẠM THỜI...
⚠️  LƯU Ý: File này sẽ tự động xóa sau khi upload HDFS!

   Đang ghi: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
======================================================================
✅ HOÀN TẤT KHỚI TẠO TÂM CỤM!
======================================================================
📄 File tạm: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
📊 Kích thước: 437 bytes (~0.4 KB)
📊 Số cụm: 5
📊 Số đặc trưng mỗi cụm: 9

📄 NỘI DUNG FILE (preview):
----------------------------------------------------------------------
Cluster 0: [-0.003, -0.003, -0.001, 0.722, -1.454...]
Cluster 1: [-0.003, -0.003, -0.001, -0.516, 0.761...]
Cluster 2: [-0.003, -0.003, -0.001, -0.241, -0.346...]
Cluster 3: [-0.003, -0.003, -0.001, 0.309, 1.315...]
Cluster 4: [-0.003, -0.003, -0.001, -0.654, -1.454...]

⚠️  QUAN TRỌNG:
   Cả 2 file tạm (hadoop_input_temp.txt và centroids_temp.txt)
   sẽ BỊ XÓA sau khi upload lên HDFS (Bước 4)
   Dữ liệu chỉ lưu trên HDFS để tuân thủ quy định bảo mật

💡 GỢI Ý TIẾP THEO:
   Chạy bước 4: ./scripts/spark/setup_hdfs.sh

⏱️  **Bước 3 hoàn thành trong 23s**

### Bước 4: Upload dữ liệu lên HDFS

=== THIẾT LẬP HDFS CHO PYSPARK K-MEANS ===
✅ HDFS có thể truy cập

✅ Đã tìm thấy file dữ liệu tạm

Đang tạo thư mục HDFS...
Đang dọn dẹp dữ liệu cũ trong HDFS...
Deleted /user/spark/hi_large/input/hadoop_input.txt
Deleted /user/spark/hi_large/centroids.txt
Deleted /user/spark/hi_large/output_centroids

Đang upload dữ liệu đầu vào lên HDFS...
  Nguồn: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
  Đích: /user/spark/hi_large/input/hadoop_input.txt

Đang upload tâm cụm lên HDFS...
  Nguồn: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
  Đích: /user/spark/hi_large/centroids.txt

Đang dọn dẹp file tạm...
✅ Đã xóa file tạm (dữ liệu chỉ còn trên HDFS)

Đang xác minh upload...
  ✅ Dữ liệu đầu vào: 30.9 G
  ✅ Tâm cụm: 437 437

Cấu trúc thư mục HDFS:
-rw-r--r--   1 ultimatebrok supergroup        437 2025-10-29 08:48 /user/spark/hi_large/centroids.txt
drwxr-xr-x   - ultimatebrok supergroup          0 2025-10-29 08:48 /user/spark/hi_large/input
-rw-r--r--   1 ultimatebrok supergroup 33194541231 2025-10-29 08:48 /user/spark/hi_large/input/hadoop_input.txt
drwxr-xr-x   - ultimatebrok supergroup           0 2025-10-28 16:52 /user/spark/hi_large/output

===================================
✅ HOÀN TẤT THIẾT LẬP HDFS!
===================================

Đường dẫn HDFS:
  Đầu vào: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  Tâm cụm: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  Đầu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Bước tiếp theo: Chạy PySpark job
  ./scripts/spark/run_spark.sh
⏱️  **Bước 4 hoàn thành trong 41s**

### Bước 5: Chạy PySpark K-means trên HDFS

=== PYSPARK K-MEANS VỚI HDFS ===
Cấu hình:
  CPU cores: 24
  Số executor: 4
  Executor cores: 4
  Executor memory: 4g
  Driver memory: 4g

Đường dẫn HDFS:
  Đầu vào: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  Tâm cụm: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  Đầu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Đang dọn dẹp kết quả cũ...
Đang chạy PySpark K-means clustering trên HDFS...
Số lần lặp tối đa: 15

WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 08:48:15 WARN Utils: Your hostname, brokie-hx370, resolves to a loopback address: 127.0.1.1; using 192.168.1.30 instead (on interface wlan0)
25/10/29 08:48:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
HDFS Đầu vào: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
HDFS Tâm cụm: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
HDFS Đầu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 08:48:16 INFO SparkContext: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SparkContext: OS info Linux, 6.17.5-2-cachyos, amd64
25/10/29 08:48:16 INFO SparkContext: Java version 17.0.16
25/10/29 08:48:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO SparkContext: Submitted application: K-means Clustering - HDFS
25/10/29 08:48:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/29 08:48:16 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
25/10/29 08:48:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkDriver' on port 46785.
25/10/29 08:48:16 INFO SparkEnv: Registering MapOutputTracker
25/10/29 08:48:16 INFO SparkEnv: Registering BlockManagerMaster
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/29 08:48:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/29 08:48:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-785ef593-6f6c-4431-bd12-fbb4b187ec65
25/10/29 08:48:16 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO LocalSparkCluster: Starting a local Spark cluster with 4 workers.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkMaster' on port 42251.
25/10/29 08:48:16 INFO Master: Starting Spark master at spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Running Spark version 4.0.1
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for MasterUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'MasterUI' on port 42345.
25/10/29 08:48:16 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://192.168.1.30:42345
25/10/29 08:48:16 INFO Master: I have been elected leader! New state: ALIVE
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker1' on port 41529.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:41529 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker2' on port 41183.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 34715.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:41183 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:34715
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 45983.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:45983
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker3' on port 37187.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:37187 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 44265.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:44265
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 21 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 12 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker4' on port 43693.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:43693 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 45411.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:45411
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:41183 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:37187 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:43693 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:41529 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Master: Registering app K-means Clustering - HDFS
25/10/29 08:48:16 INFO Master: Registered app K-means Clustering - HDFS with ID app-20251029084816-0000
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251029084816-0000
25/10/29 08:48:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35681.
25/10/29 08:48:16 INFO NettyBlockTransferService: Server created on 192.168.1.30:35681
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/0 on worker worker-20251029084816-192.168.1.30-43693
25/10/29 08:48:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/1 on worker worker-20251029084816-192.168.1.30-41529
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/2 on worker worker-20251029084816-192.168.1.30-41183
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/3 on worker worker-20251029084816-192.168.1.30-37187
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/0 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/1 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/0 on worker-20251029084816-192.168.1.30-43693 (192.168.1.30:43693) with 4 core(s)
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/2 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/0 on hostPort 192.168.1.30:43693 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/3 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/1 on worker-20251029084816-192.168.1.30-41529 (192.168.1.30:41529) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/1 on hostPort 192.168.1.30:41529 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/2 on worker-20251029084816-192.168.1.30-41183 (192.168.1.30:41183) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/2 on hostPort 192.168.1.30:41183 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/3 on worker-20251029084816-192.168.1.30-37187 (192.168.1.30:37187) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/3 on hostPort 192.168.1.30:37187 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:35681 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "2" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:41183" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "3" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:37187" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "1" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:41529" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "0" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:43693" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/1 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/2 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/0 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/3 is now RUNNING
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42502) with ID 0, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42494) with ID 1, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42492) with ID 2, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42518) with ID 3, ResourceProfileId 0
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:40063 with 2.2 GiB RAM, BlockManagerId(0, 192.168.1.30, 40063, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:42199 with 2.2 GiB RAM, BlockManagerId(3, 192.168.1.30, 42199, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:33369 with 2.2 GiB RAM, BlockManagerId(1, 192.168.1.30, 33369, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:37441 with 2.2 GiB RAM, BlockManagerId(2, 192.168.1.30, 37441, None)
=== PYSPARK K-MEANS CLUSTERING ===
Đầu vào: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
Tâm cụm: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
Số lần lặp tối đa: 15

Đang đọc dữ liệu từ HDFS...
Đã load 179,702,229 điểm từ hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
Đang đọc tâm cụm từ hdfs://localhost:9000/user/spark/hi_large/centroids.txt
Đã khởi tạo 5 tâm cụm

=== Lần lặp 1/15 ===
Độ dịch chuyển tâm cụm: 1.921661

=== Lần lặp 2/15 ===
Độ dịch chuyển tâm cụm: 0.683403

=== Lần lặp 3/15 ===
Độ dịch chuyển tâm cụm: 0.459551

=== Lần lặp 4/15 ===
Độ dịch chuyển tâm cụm: 0.344075

=== Lần lặp 5/15 ===
Độ dịch chuyển tâm cụm: 0.205664

=== Lần lặp 6/15 ===
Độ dịch chuyển tâm cụm: 0.172839

=== Lần lặp 7/15 ===
Độ dịch chuyển tâm cụm: 0.181984

=== Lần lặp 8/15 ===
Độ dịch chuyển tâm cụm: 0.185024

=== Lần lặp 9/15 ===
Độ dịch chuyển tâm cụm: 0.171884

=== Lần lặp 10/15 ===
Độ dịch chuyển tâm cụm: 0.174057

=== Lần lặp 11/15 ===
Độ dịch chuyển tâm cụm: 0.191881

=== Lần lặp 12/15 ===
Độ dịch chuyển tâm cụm: 0.202822

=== Lần lặp 13/15 ===
Độ dịch chuyển tâm cụm: 0.350772

=== Lần lặp 14/15 ===
Độ dịch chuyển tâm cụm: 0.781042

=== Lần lặp 15/15 ===
Độ dịch chuyển tâm cụm: 2.036996


Đang lưu tâm cụm cuối cùng vào HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Kích thước các cụm:
  Cụm 0: 51,192,094 điểm (28.49%)
  Cụm 1: 43,618,958 điểm (24.27%)
  Cụm 2: 39,589,984 điểm (22.03%)
  Cụm 3: 41,396,172 điểm (23.04%)
  Cụm 4: 3,905,021 điểm (2.17%)

✅ Hoàn thành thuật toán K-means clustering!

✅ PySpark K-means hoàn thành!
Tâm cụm cuối cùng đã lưu vào HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Để xem kết quả:
  hdfs dfs -cat /user/spark/hi_large/output_centroids/part-*
⏱️  **Bước 5 hoàn thành trong 27m 34s**

### Bước 6: Tải kết quả từ HDFS

=== TẢI KẾT QUẢ TỪ HDFS ===
✅ Đã tìm thấy kết quả trong HDFS

Đang tải tâm cụm cuối cùng...
  Từ: /user/spark/hi_large/output_centroids
  Đến: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt
✅ Đã tải tâm cụm cuối cùng

Thông tin file local:
  Kích thước: 4,0K
  Số dòng (cụm): 5

Xem trước:
-0.002416,-0.002601,-0.000938,0.157297,-1.031620,0.062556,-0.513182,-0.512176,0.136520
-0.000230,-0.002411,-0.000286,-0.029543,0.644693,-0.907091,-0.490709,-0.501816,0.081444
0.006580,0.008891,0.002813,0.002821,-0.021032,0.012481,1.685821,1.690902,0.118926
-0.002799,-0.002482,-0.001118,-0.139795,0.640843,0.946155,-0.503855,-0.498938,0.157001
-0.002737,-0.002401,-0.001121,-0.251926,-0.169359,-0.409522,0.355893,0.364131,-4.562158

✅ Hoàn thành tải xuống!

Bước tiếp theo:
  1. Gán cụm: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python assign_clusters_polars.py
  2. Phân tích kết quả: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python analyze_polars.py
⏱️  **Bước 6 hoàn thành trong 3s**

### Bước 7: Gán cụm với Polars

======================================================================
🏷️  BƯỚC 7: GÁN NHÃN CỤM CHO TỮNG GIAO DỊCH
======================================================================

🎯 ĐỌC TÂM CỤM CUỐI CÙNG TỪ BƯỚC 6...
   File: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt

✅ Đã load 5 tâm cụm
   Mỗi tâm cụm có 9 đặc trưng

📂 ĐỌC DỮ LIỆU TỪ HDFS...
   File HDFS: /user/spark/hi_large/input/hadoop_input.txt
   (179M dòng, 33GB - đã chuẩn hóa)

🔄 Streaming từ HDFS (có thể mất vài phút)...
📊 Đang đọc CSV từ HDFS stream...

✅ Đã load 179,702,229 bản ghi từ HDFS

📊 CHUYỂN SANG NUMPY VÀ TÍNH KHOẢNG CÁCH...
   Dữ liệu: 179,702,229 dòng x 9 cột
   Tâm cụm: 5 cụm x 9 đặc trưng

🔢 TÍNH KHOẢNG CÁCH EUCLIDEAN (Batch Processing)...
   Xử lý 1 triệu giao dịch mỗi lần để tiết kiệm RAM

    Đã xử lý 1,000,000/179,702,229 giao dịch (0.6%)
    Đã xử lý 11,000,000/179,702,229 giao dịch (6.1%)
    Đã xử lý 21,000,000/179,702,229 giao dịch (11.7%)
    Đã xử lý 31,000,000/179,702,229 giao dịch (17.3%)
    Đã xử lý 41,000,000/179,702,229 giao dịch (22.8%)
    Đã xử lý 51,000,000/179,702,229 giao dịch (28.4%)
    Đã xử lý 61,000,000/179,702,229 giao dịch (33.9%)
    Đã xử lý 71,000,000/179,702,229 giao dịch (39.5%)
    Đã xử lý 81,000,000/179,702,229 giao dịch (45.1%)
    Đã xử lý 91,000,000/179,702,229 giao dịch (50.6%)
    Đã xử lý 101,000,000/179,702,229 giao dịch (56.2%)
    Đã xử lý 111,000,000/179,702,229 giao dịch (61.8%)
    Đã xử lý 121,000,000/179,702,229 giao dịch (67.3%)
    Đã xử lý 131,000,000/179,702,229 giao dịch (72.9%)
    Đã xử lý 141,000,000/179,702,229 giao dịch (78.5%)
    Đã xử lý 151,000,000/179,702,229 giao dịch (84.0%)
    Đã xử lý 161,000,000/179,702,229 giao dịch (89.6%)
    Đã xử lý 171,000,000/179,702,229 giao dịch (95.2%)
    Đã xử lý 179,702,229/179,702,229 giao dịch (100.0%)

✅ Đã hoàn thành tính toán cho 179,702,229 giao dịch

💾 LƯU KẾT QUẢ...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
======================================================================
✅ HOÀN TẤT GÁN NHÃN CỤM!
======================================================================
📄 File kết quả: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
📊 Kích thước: 342.75 MB
📊 Tổng giao dịch: 179,702,229

📊 PHÂN PHỐI CỤM:
   Cluster 0: 51,192,096 giao dịch (28.49%)
   Cluster 1: 43,618,956 giao dịch (24.27%)
   Cluster 2: 39,589,983 giao dịch (22.03%)
   Cluster 3: 41,396,173 giao dịch (23.04%)
   Cluster 4: 3,905,021 giao dịch (2.17%)

💡 GỢI Ý TIẾP THEO:
   Chạy bước 8: python scripts/polars/analyze_polars.py

⏱️  **Bước 7 hoàn thành trong 3m 15s**

### Bước 8: Phân tích kết quả

======================================================================
📊 BƯỚC 8: PHÂN TÍCH KẾT QUẢ
======================================================================

📂 ĐỌC KẾT QUẢ PHÂN CỤM TỪ BƯỚC 7...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
✅ Đã load 179,702,229 nhãn cụm

📊 ĐỌC DỮ LIỆU GỐC (Lazy Mode)...
   File: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
✅ Đã load metadata (chưa load toàn bộ vào RAM)

🎯 THÊM CỘT 'cluster' VÀO DATA...
✅ Đã gắn nhãn cụm cho mỗi giao dịch

======================================================================
📋 PHÂN TÍCH CHI TIẾT
======================================================================

📈 THỐNG KÊ TỔNG QUAN:
   Tổng số giao dịch: 179,702,229
   Số cụm: 5

📉 KÍCH THƯỚC MỖI CỤM:
----------------------------------------------------------------------
shape: (5, 2)
┌─────────┬──────────┐
│ cluster ┆ count    │
│ ---     ┆ ---      │
│ i64     ┆ u32      │
╞═════════╪══════════╡
│ 0       ┆ 51192096 │
│ 1       ┆ 43618956 │
│ 2       ┆ 39589983 │
│ 3       ┆ 41396173 │
│ 4       ┆ 3905021  │
└─────────┴──────────┘

💰 TỶ LỆ RỬA TIỀN TRONG TỮNG CỤM:
----------------------------------------------------------------------
shape: (5, 4)
┌─────────┬──────────┬──────────────────┬─────────────────┐
│ cluster ┆ total    ┆ laundering_count ┆ laundering_rate │
│ ---     ┆ ---      ┆ ---              ┆ ---             │
│ i64     ┆ u32      ┆ i64              ┆ f64             │
╞═════════╪══════════╪══════════════════╪═════════════════╡
│ 0       ┆ 51192096 ┆ 67243            ┆ 0.131354        │
│ 1       ┆ 43618956 ┆ 57879            ┆ 0.132692        │
│ 2       ┆ 39589983 ┆ 34091            ┆ 0.08611         │
│ 3       ┆ 41396173 ┆ 64725            ┆ 0.156355        │
│ 4       ┆ 3905021  ┆ 1608             ┆ 0.041178        │
└─────────┴──────────┴──────────────────┴─────────────────┘

⚠️  CỤM CÓ RỦI RO CAO (>10% rửa tiền):
----------------------------------------------------------------------
✅ KHÔNG có cụm nào vượt ngưỡng 10%
   Tất cả các cụm đều trong mức chấp nhận được.

📊 ĐẶC TRƯNG TRUNG BÌNH MỖI CỤM:
----------------------------------------------------------------------
shape: (5, 4)
┌─────────┬─────────────────────┬─────────────────┬───────────┐
│ cluster ┆ avg_amount_received ┆ avg_amount_paid ┆ avg_ratio │
│ ---     ┆ ---                 ┆ ---             ┆ ---       │
│ i64     ┆ f64                 ┆ f64             ┆ f64       │
╞═════════╪═════════════════════╪═════════════════╪═══════════╡
│ 0       ┆ 1.3970e6            ┆ 360672.187453   ┆ 1.161493  │
│ 1       ┆ 4.9691e6            ┆ 641575.511352   ┆ 1.693777  │
│ 2       ┆ 1.7626e7            ┆ 1.6323e7        ┆ 4.293174  │
│ 3       ┆ 518762.191972       ┆ 518762.191972   ┆ 1.0       │
│ 4       ┆ 804.072407          ┆ 804.072407      ┆ 1.0       │
└─────────┴─────────────────────┴─────────────────┴───────────┘

💡 NHẬN XÉT:
----------------------------------------------------------------------
1. CỤm nghi ngờ NHẤT: Cluster 3 (0.16% rửa tiền)
   ➡️  Nên kiểm tra kỹ các giao dịch trong cụm này

2. Cụm an toàn NHẤT: Cluster 4 (0.04% rửa tiền)
   ➡️  Có thể ưu tiên thấp khi kiểm tra

3. Đánh giá tổng thể: ✅ RỦI RO THẤP
   Hệ thống hoạt động tốt, tỷ lệ rửa tiền thấp

======================================================================
✅ HOÀN TẤT PHÂN TÍCH!
======================================================================

📊 TÓM TẢT:
   - Đã phân tích 179,702,229 giao dịch
   - Phân thành 5 cụm
   - Tỷ lệ rửa tiền: 0.04% - 0.16%
   - Số cụm rủi ro cao: 0 (✅ Tốt!)

🎉 PIPELINE HOÀN TẤT!
   Tất cả 8 bước đã chạy thành công.
   Xem kết quả trong thư mục data/results/

⏱️  **Bước 8 hoàn thành trong 27s**


---

## Tổng kết

✅ **Pipeline hoàn thành thành công!**

**Thời gian kết thúc:** 2025-10-29 09:19:29
**Tổng thời gian chạy:** 33m 35s

---

*Log đã lưu tại: /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_084554.md*
