# Polars + PySpark Pipeline Execution Log

**Th·ªùi gian b·∫Øt ƒë·∫ßu:** 2025-10-29 08:45:54
**File log:** /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_084554.md

---

## Th·ª±c thi Pipeline

=== POLARS + PYSPARK PIPELINE ===
Th·ªùi gian b·∫Øt ƒë·∫ßu: 2025-10-29 08:45:54
### B∆∞·ªõc 1: Kh√°m ph√° d·ªØ li·ªáu

======================================================================
üîç B∆Ø·ªöC 1: KH√ÅM PH√Å D·ªÆ LI·ªÜU
======================================================================
ƒêang ƒë·ªçc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui l√≤ng ƒë·ª£i...

‚úÖ ƒê√£ load metadata th√†nh c√¥ng!

üìã SCHEMA (C·∫•u tr√∫c d·ªØ li·ªáu):
----------------------------------------------------------------------
<bound method LazyFrame.collect_schema of <LazyFrame at 0x7FB261C786B0>>

üìä L·∫§Y M·∫™U 100,000 D√íNG ƒê·∫¶U:
----------------------------------------------------------------------
D·ªØ li·ªáu m·∫´u:
shape: (100_000, 11)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Timestamp  ‚îÜ From Bank ‚îÜ Account   ‚îÜ To Bank ‚îÜ ‚Ä¶ ‚îÜ Amount    ‚îÜ Payment   ‚îÜ Payment   ‚îÜ Is Launde ‚îÇ
‚îÇ ---        ‚îÜ ---       ‚îÜ ---       ‚îÜ ---     ‚îÜ   ‚îÜ Paid      ‚îÜ Currency  ‚îÜ Format    ‚îÜ ring      ‚îÇ
‚îÇ str        ‚îÜ i64       ‚îÜ str       ‚îÜ i64     ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÇ
‚îÇ            ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ f64       ‚îÜ str       ‚îÜ str       ‚îÜ i64       ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 2022/08/01 ‚îÜ 20        ‚îÜ 800104D70 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 6794.63   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:17      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 3196      ‚îÜ 800107150 ‚îÜ 3196    ‚îÜ ‚Ä¶ ‚îÜ 7739.29   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:02      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E430 ‚îÜ 1208    ‚îÜ ‚Ä¶ ‚îÜ 1880.23   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:17      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E650 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 7.3966883 ‚îÜ US Dollar ‚îÜ Cheque    ‚îÜ 0         ‚îÇ
‚îÇ 00:03      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ e7        ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 1208      ‚îÜ 80010E650 ‚îÜ 20      ‚îÜ ‚Ä¶ ‚îÜ 4.5868454 ‚îÜ US Dollar ‚îÜ Cheque    ‚îÜ 0         ‚îÇ
‚îÇ 00:02      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ e7        ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ
‚îÇ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 111667    ‚îÜ 80E5D9320 ‚îÜ 111667  ‚îÜ ‚Ä¶ ‚îÜ 23.93     ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:06      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 25994     ‚îÜ 80E5DBF50 ‚îÜ 25994   ‚îÜ ‚Ä¶ ‚îÜ 23.41     ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:18      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 310328    ‚îÜ 80E5ED350 ‚îÜ 310328  ‚îÜ ‚Ä¶ ‚îÜ 3297.82   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:04      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 5838      ‚îÜ 80E5ED580 ‚îÜ 5838    ‚îÜ ‚Ä¶ ‚îÜ 3032.53   ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:19      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îÇ 2022/08/01 ‚îÜ 339249    ‚îÜ 80E5ED620 ‚îÜ 339249  ‚îÜ ‚Ä¶ ‚îÜ 13043.39  ‚îÜ US Dollar ‚îÜ Reinvestm ‚îÜ 0         ‚îÇ
‚îÇ 00:26      ‚îÜ           ‚îÜ           ‚îÜ         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ ent       ‚îÜ           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Th·ªëng k√™ m√¥ t·∫£:
shape: (9, 12)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ statistic ‚îÜ Timestamp ‚îÜ From Bank ‚îÜ Account   ‚îÜ ‚Ä¶ ‚îÜ Amount    ‚îÜ Payment   ‚îÜ Payment   ‚îÜ Is Laund ‚îÇ
‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ Paid      ‚îÜ Currency  ‚îÜ Format    ‚îÜ ering    ‚îÇ
‚îÇ str       ‚îÜ str       ‚îÜ f64       ‚îÜ str       ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ f64       ‚îÜ str       ‚îÜ str       ‚îÜ f64      ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ count     ‚îÜ 100000    ‚îÜ 100000.0  ‚îÜ 100000    ‚îÜ ‚Ä¶ ‚îÜ 100000.0  ‚îÜ 100000    ‚îÜ 100000    ‚îÜ 100000.0 ‚îÇ
‚îÇ null_coun ‚îÜ 0         ‚îÜ 0.0       ‚îÜ 0         ‚îÜ ‚Ä¶ ‚îÜ 0.0       ‚îÜ 0         ‚îÜ 0         ‚îÜ 0.0      ‚îÇ
‚îÇ t         ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ mean      ‚îÜ null      ‚îÜ 49669.967 ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 1.1422e6  ‚îÜ null      ‚îÜ null      ‚îÜ 0.00001  ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ 7         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ std       ‚îÜ null      ‚îÜ 80891.260 ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 2.9890e7  ‚îÜ null      ‚îÜ null      ‚îÜ 0.003162 ‚îÇ
‚îÇ           ‚îÜ           ‚îÜ 568       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ min       ‚îÜ 2022/08/0 ‚îÜ 0.0       ‚îÜ 100428660 ‚îÜ ‚Ä¶ ‚îÜ 0.01      ‚îÜ Australia ‚îÜ ACH       ‚îÜ 0.0      ‚îÇ
‚îÇ           ‚îÜ 1 00:00   ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ n Dollar  ‚îÜ           ‚îÜ          ‚îÇ
‚îÇ 25%       ‚îÜ null      ‚îÜ 4214.0    ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 20.53     ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ 50%       ‚îÜ null      ‚îÜ 15240.0   ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 2513.06   ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ 75%       ‚îÜ null      ‚îÜ 31996.0   ‚îÜ null      ‚îÜ ‚Ä¶ ‚îÜ 28769.41  ‚îÜ null      ‚îÜ null      ‚îÜ 0.0      ‚îÇ
‚îÇ max       ‚îÜ 2022/08/0 ‚îÜ 339249.0  ‚îÜ 80E5ED620 ‚îÜ ‚Ä¶ ‚îÜ 5.1154e9  ‚îÜ Yuan      ‚îÜ Wire      ‚îÜ 1.0      ‚îÇ
‚îÇ           ‚îÜ 1 00:29   ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí∞ PH√ÇN T√çCH T·ª∂ L·ªÜ R·ª¨A TI·ªÄN:
----------------------------------------------------------------------
shape: (2, 1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Is Laundering ‚îÇ
‚îÇ ---           ‚îÇ
‚îÇ struct[2]     ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ {1,225546}    ‚îÇ
‚îÇ {0,179476683} ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üíµ TOP 10 LO·∫†I TI·ªÄN T·ªÜ PH·ªî BI·∫æN:
----------------------------------------------------------------------
shape: (10, 1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Receiving Currency          ‚îÇ
‚îÇ ---                         ‚îÇ
‚îÇ struct[2]                   ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ {"UK Pound",5748874}        ‚îÇ
‚îÇ {"Ruble",5571567}           ‚îÇ
‚îÇ {"Rupee",4178243}           ‚îÇ
‚îÇ {"US Dollar",65292945}      ‚îÇ
‚îÇ {"Shekel",8047876}          ‚îÇ
‚îÇ {"Canadian Dollar",6140322} ‚îÇ
‚îÇ {"Bitcoin",3958153}         ‚îÇ
‚îÇ {"Yen",4841570}             ‚îÇ
‚îÇ {"Saudi Riyal",3228262}     ‚îÇ
‚îÇ {"Yuan",12920668}           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

======================================================================
‚úÖ HO√ÄN T·∫§T KH√ÅM PH√Å D·ªÆ LI·ªÜU!
======================================================================

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 2: python scripts/polars/prepare_polars.py

‚è±Ô∏è  **B∆∞·ªõc 1 ho√†n th√†nh trong 12s**

### B∆∞·ªõc 2: Chu·∫©n b·ªã ƒë·∫∑c tr∆∞ng v·ªõi Polars

======================================================================
üîß B∆Ø·ªöC 2: X·ª¨ L√ù V√Ä TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG
======================================================================
ƒê·ªçc file: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
Vui l√≤ng ƒë·ª£i (c√≥ th·ªÉ m·∫•t 5-10 ph√∫t)...

‚úÖ ƒê√£ load 179,702,229 d√≤ng v√†o RAM

üåü TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG T·ª™ D·ªÆ LI·ªÜU TH√î...
‚úÖ ƒê√£ tr√≠ch xu·∫•t 10 ƒë·∫∑c tr∆∞ng

üî¢ M√É H√ìA BI·∫æN PH√ÇN LO·∫†I (CATEGORICAL ENCODING)...
‚úÖ ƒê√£ m√£ h√≥a th√†nh s·ªë

üìä C√≥ 9 ƒë·∫∑c tr∆∞ng s·ªë cho K-means

üìä CHU·∫®N H√ìA D·ªÆ LI·ªÜU (Min-Max Scaling)...
‚úÖ ƒê√£ chu·∫©n h√≥a 9 ƒë·∫∑c tr∆∞ng

üíæ L∆ØU FILE T·∫†M TH·ªúI CHO HDFS...
‚ö†Ô∏è  L∆ØU √ù: File n√†y s·∫Ω t·ª± ƒë·ªông x√≥a sau khi upload HDFS!

   ƒêang ghi: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
   Vui l√≤ng ƒë·ª£i (c√≥ th·ªÉ m·∫•t 3-5 ph√∫t)...

======================================================================
‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU!
======================================================================
üìÑ File t·∫°m: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
üìä K√≠ch th∆∞·ªõc: 30.91 GB
üìä S·ªë d√≤ng: 179,702,229
üìä S·ªë ƒë·∫∑c tr∆∞ng: 9
üìä C√°c ƒë·∫∑c tr∆∞ng: ['amount_received', 'amount_paid', 'amount_ratio', 'hour', 'day_of_week', 'route_hash', 'recv_curr_encoded', 'payment_curr_encoded', 'payment_format_encoded']

‚ö†Ô∏è  QUAN TR·ªåNG:
   File n√†y ch·ªâ t·ªìn t·∫°i T·∫†M TH·ªúI!
   N√≥ s·∫Ω B·ªä X√ìA sau khi upload l√™n HDFS (B∆∞·ªõc 4)
   D·ªØ li·ªáu ch·ªâ l∆∞u tr√™n HDFS ƒë·ªÉ tu√¢n th·ªß quy ƒë·ªãnh b·∫£o m·∫≠t

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 3: python scripts/polars/init_centroids.py

‚è±Ô∏è  **B∆∞·ªõc 2 ho√†n th√†nh trong 1m 0s**

### B∆∞·ªõc 3: Kh·ªüi t·∫°o t√¢m c·ª•m

======================================================================
üéØ B∆Ø·ªöC 3: KH·ªöI T·∫†O T√ÇM C·ª§M BAN ƒê·∫¶U
======================================================================

Ki·ªÉm tra file input: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
‚úÖ File input t·ªìn t·∫°i!

üìä ƒê·ªåC D·ªÆ LI·ªÜU ƒê√É CHU·∫®N H√ìA...
‚úÖ ƒê√£ load 179,702,229 d√≤ng v·ªõi 9 ƒë·∫∑c tr∆∞ng

üé≤ L·∫§Y M·∫™U NG·∫™U NHI√äN ƒê·ªÇ KH·ªöI T·∫†O...
   S·ªë m·∫´u: 100,000 d√≤ng
‚úÖ ƒê√£ l·∫•y m·∫´u 100,000 ƒëi·ªÉm

üéØ KH·ªöI T·∫†O 5 T√ÇM C·ª§M BAN ƒê·∫¶U...
   Thu·∫≠t to√°n: Ch·ªçn ng·∫´u nhi√™n 5 ƒëi·ªÉm t·ª´ 100,000 m·∫´u

‚úÖ ƒê√£ ch·ªçn 5 t√¢m c·ª•m ban ƒë·∫ßu
   M·ªói t√¢m c·ª•m c√≥ 9 ƒë·∫∑c tr∆∞ng

üíæ L∆ØU T√ÇM C·ª§M V√ÄO FILE T·∫†M TH·ªúI...
‚ö†Ô∏è  L∆ØU √ù: File n√†y s·∫Ω t·ª± ƒë·ªông x√≥a sau khi upload HDFS!

   ƒêang ghi: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
======================================================================
‚úÖ HO√ÄN T·∫§T KH·ªöI T·∫†O T√ÇM C·ª§M!
======================================================================
üìÑ File t·∫°m: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
üìä K√≠ch th∆∞·ªõc: 437 bytes (~0.4 KB)
üìä S·ªë c·ª•m: 5
üìä S·ªë ƒë·∫∑c tr∆∞ng m·ªói c·ª•m: 9

üìÑ N·ªòI DUNG FILE (preview):
----------------------------------------------------------------------
Cluster 0: [-0.003, -0.003, -0.001, 0.722, -1.454...]
Cluster 1: [-0.003, -0.003, -0.001, -0.516, 0.761...]
Cluster 2: [-0.003, -0.003, -0.001, -0.241, -0.346...]
Cluster 3: [-0.003, -0.003, -0.001, 0.309, 1.315...]
Cluster 4: [-0.003, -0.003, -0.001, -0.654, -1.454...]

‚ö†Ô∏è  QUAN TR·ªåNG:
   C·∫£ 2 file t·∫°m (hadoop_input_temp.txt v√† centroids_temp.txt)
   s·∫Ω B·ªä X√ìA sau khi upload l√™n HDFS (B∆∞·ªõc 4)
   D·ªØ li·ªáu ch·ªâ l∆∞u tr√™n HDFS ƒë·ªÉ tu√¢n th·ªß quy ƒë·ªãnh b·∫£o m·∫≠t

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 4: ./scripts/spark/setup_hdfs.sh

‚è±Ô∏è  **B∆∞·ªõc 3 ho√†n th√†nh trong 23s**

### B∆∞·ªõc 4: Upload d·ªØ li·ªáu l√™n HDFS

=== THI·∫æT L·∫¨P HDFS CHO PYSPARK K-MEANS ===
‚úÖ HDFS c√≥ th·ªÉ truy c·∫≠p

‚úÖ ƒê√£ t√¨m th·∫•y file d·ªØ li·ªáu t·∫°m

ƒêang t·∫°o th∆∞ m·ª•c HDFS...
ƒêang d·ªçn d·∫πp d·ªØ li·ªáu c≈© trong HDFS...
Deleted /user/spark/hi_large/input/hadoop_input.txt
Deleted /user/spark/hi_large/centroids.txt
Deleted /user/spark/hi_large/output_centroids

ƒêang upload d·ªØ li·ªáu ƒë·∫ßu v√†o l√™n HDFS...
  Ngu·ªìn: /home/ultimatebrok/Downloads/Final/data/processed/hadoop_input_temp.txt
  ƒê√≠ch: /user/spark/hi_large/input/hadoop_input.txt

ƒêang upload t√¢m c·ª•m l√™n HDFS...
  Ngu·ªìn: /home/ultimatebrok/Downloads/Final/data/processed/centroids_temp.txt
  ƒê√≠ch: /user/spark/hi_large/centroids.txt

ƒêang d·ªçn d·∫πp file t·∫°m...
‚úÖ ƒê√£ x√≥a file t·∫°m (d·ªØ li·ªáu ch·ªâ c√≤n tr√™n HDFS)

ƒêang x√°c minh upload...
  ‚úÖ D·ªØ li·ªáu ƒë·∫ßu v√†o: 30.9 G
  ‚úÖ T√¢m c·ª•m: 437 437

C·∫•u tr√∫c th∆∞ m·ª•c HDFS:
-rw-r--r--   1 ultimatebrok supergroup        437 2025-10-29 08:48 /user/spark/hi_large/centroids.txt
drwxr-xr-x   - ultimatebrok supergroup          0 2025-10-29 08:48 /user/spark/hi_large/input
-rw-r--r--   1 ultimatebrok supergroup 33194541231 2025-10-29 08:48 /user/spark/hi_large/input/hadoop_input.txt
drwxr-xr-x   - ultimatebrok supergroup           0 2025-10-28 16:52 /user/spark/hi_large/output

===================================
‚úÖ HO√ÄN T·∫§T THI·∫æT L·∫¨P HDFS!
===================================

ƒê∆∞·ªùng d·∫´n HDFS:
  ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

B∆∞·ªõc ti·∫øp theo: Ch·∫°y PySpark job
  ./scripts/spark/run_spark.sh
‚è±Ô∏è  **B∆∞·ªõc 4 ho√†n th√†nh trong 41s**

### B∆∞·ªõc 5: Ch·∫°y PySpark K-means tr√™n HDFS

=== PYSPARK K-MEANS V·ªöI HDFS ===
C·∫•u h√¨nh:
  CPU cores: 24
  S·ªë executor: 4
  Executor cores: 4
  Executor memory: 4g
  Driver memory: 4g

ƒê∆∞·ªùng d·∫´n HDFS:
  ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
  T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
  ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

ƒêang d·ªçn d·∫πp k·∫øt qu·∫£ c≈©...
ƒêang ch·∫°y PySpark K-means clustering tr√™n HDFS...
S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa: 15

WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 08:48:15 WARN Utils: Your hostname, brokie-hx370, resolves to a loopback address: 127.0.1.1; using 192.168.1.30 instead (on interface wlan0)
25/10/29 08:48:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
HDFS ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
HDFS T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
HDFS ƒê·∫ßu ra: hdfs://localhost:9000/user/spark/hi_large/output_centroids

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/29 08:48:16 INFO SparkContext: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SparkContext: OS info Linux, 6.17.5-2-cachyos, amd64
25/10/29 08:48:16 INFO SparkContext: Java version 17.0.16
25/10/29 08:48:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO SparkContext: Submitted application: K-means Clustering - HDFS
25/10/29 08:48:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/29 08:48:16 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
25/10/29 08:48:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkDriver' on port 46785.
25/10/29 08:48:16 INFO SparkEnv: Registering MapOutputTracker
25/10/29 08:48:16 INFO SparkEnv: Registering BlockManagerMaster
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/29 08:48:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/29 08:48:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-785ef593-6f6c-4431-bd12-fbb4b187ec65
25/10/29 08:48:16 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO LocalSparkCluster: Starting a local Spark cluster with 4 workers.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkMaster' on port 42251.
25/10/29 08:48:16 INFO Master: Starting Spark master at spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Running Spark version 4.0.1
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for MasterUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'MasterUI' on port 42345.
25/10/29 08:48:16 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://192.168.1.30:42345
25/10/29 08:48:16 INFO Master: I have been elected leader! New state: ALIVE
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker1' on port 41529.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:41529 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker2' on port 41183.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 34715.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:41183 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:34715
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 45983.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:45983
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker3' on port 37187.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:37187 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 44265.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:44265
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 21 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 12 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Utils: Successfully started service 'sparkWorker4' on port 43693.
25/10/29 08:48:16 INFO Worker: Worker decommissioning not enabled.
25/10/29 08:48:16 INFO Worker: Starting Spark worker 192.168.1.30:43693 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Running Spark version 4.0.1
25/10/29 08:48:16 INFO Worker: Spark home: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO ResourceUtils: No custom resources configured for spark.worker.
25/10/29 08:48:16 INFO ResourceUtils: ==============================================================
25/10/29 08:48:16 INFO JettyUtils: Start Jetty 0.0.0.0:0 for WorkerUI
25/10/29 08:48:16 INFO Utils: Successfully started service 'WorkerUI' on port 45411.
25/10/29 08:48:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.30:45411
25/10/29 08:48:16 INFO Worker: Connecting to master 192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:41183 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:37187 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:43693 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Master: Registering worker 192.168.1.30:41529 with 4 cores, 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Worker: Successfully registered with master spark://192.168.1.30:42251
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO Worker: Worker cleanup enabled; old application directories will be deleted in: /home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/work
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://192.168.1.30:42251...
25/10/29 08:48:16 INFO TransportClientFactory: Successfully created connection to /192.168.1.30:42251 after 1 ms (0 ms spent in bootstraps)
25/10/29 08:48:16 INFO Master: Registering app K-means Clustering - HDFS
25/10/29 08:48:16 INFO Master: Registered app K-means Clustering - HDFS with ID app-20251029084816-0000
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251029084816-0000
25/10/29 08:48:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35681.
25/10/29 08:48:16 INFO NettyBlockTransferService: Server created on 192.168.1.30:35681
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/0 on worker worker-20251029084816-192.168.1.30-43693
25/10/29 08:48:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/1 on worker worker-20251029084816-192.168.1.30-41529
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/2 on worker worker-20251029084816-192.168.1.30-41183
25/10/29 08:48:16 INFO Master: Launching executor app-20251029084816-0000/3 on worker worker-20251029084816-192.168.1.30-37187
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/0 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/1 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/0 on worker-20251029084816-192.168.1.30-43693 (192.168.1.30:43693) with 4 core(s)
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/2 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/0 on hostPort 192.168.1.30:43693 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO Worker: Asked to launch executor app-20251029084816-0000/3 for K-means Clustering - HDFS
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/1 on worker-20251029084816-192.168.1.30-41529 (192.168.1.30:41529) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/1 on hostPort 192.168.1.30:41529 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/2 on worker-20251029084816-192.168.1.30-41183 (192.168.1.30:41183) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/2 on hostPort 192.168.1.30:41183 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251029084816-0000/3 on worker-20251029084816-192.168.1.30-37187 (192.168.1.30:37187) with 4 core(s)
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20251029084816-0000/3 on hostPort 192.168.1.30:37187 with 4 core(s), 4.0 GiB RAM
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing view acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: Changing modify acls groups to: ultimatebrok
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ultimatebrok groups with view permissions: EMPTY; users with modify permissions: ultimatebrok; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/29 08:48:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:35681 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.30, 35681, None)
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "2" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:41183" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "3" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:37187" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "1" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:41529" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk/bin/java" "-cp" "/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/conf:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/slf4j-api-2.0.16.jar:/home/ultimatebrok/Downloads/Final/.venv/lib/python3.12/site-packages/pyspark/jars/*:/opt/hadoop/etc/hadoop/" "-Xmx4096M" "-Dspark.driver.port=46785" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-modules=jdk.incubator.vector" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "-Dio.netty.tryReflectionSetAccessible=true" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.30:46785" "--executor-id" "0" "--hostname" "192.168.1.30" "--cores" "4" "--app-id" "app-20251029084816-0000" "--worker-url" "spark://Worker@192.168.1.30:43693" "--resourceProfileId" "0"
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO Master: Start scheduling for app app-20251029084816-0000 with rpId: 0
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/1 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/2 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/0 is now RUNNING
25/10/29 08:48:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251029084816-0000/3 is now RUNNING
25/10/29 08:48:16 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42502) with ID 0, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42494) with ID 1, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42492) with ID 2, ResourceProfileId 0
25/10/29 08:48:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.30:42518) with ID 3, ResourceProfileId 0
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:40063 with 2.2 GiB RAM, BlockManagerId(0, 192.168.1.30, 40063, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:42199 with 2.2 GiB RAM, BlockManagerId(3, 192.168.1.30, 42199, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:33369 with 2.2 GiB RAM, BlockManagerId(1, 192.168.1.30, 33369, None)
25/10/29 08:48:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.30:37441 with 2.2 GiB RAM, BlockManagerId(2, 192.168.1.30, 37441, None)
=== PYSPARK K-MEANS CLUSTERING ===
ƒê·∫ßu v√†o: hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
T√¢m c·ª•m: hdfs://localhost:9000/user/spark/hi_large/centroids.txt
S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa: 15

ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ HDFS...
ƒê√£ load 179,702,229 ƒëi·ªÉm t·ª´ hdfs://localhost:9000/user/spark/hi_large/input/hadoop_input.txt
ƒêang ƒë·ªçc t√¢m c·ª•m t·ª´ hdfs://localhost:9000/user/spark/hi_large/centroids.txt
ƒê√£ kh·ªüi t·∫°o 5 t√¢m c·ª•m

=== L·∫ßn l·∫∑p 1/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 1.921661

=== L·∫ßn l·∫∑p 2/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.683403

=== L·∫ßn l·∫∑p 3/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.459551

=== L·∫ßn l·∫∑p 4/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.344075

=== L·∫ßn l·∫∑p 5/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.205664

=== L·∫ßn l·∫∑p 6/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.172839

=== L·∫ßn l·∫∑p 7/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.181984

=== L·∫ßn l·∫∑p 8/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.185024

=== L·∫ßn l·∫∑p 9/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.171884

=== L·∫ßn l·∫∑p 10/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.174057

=== L·∫ßn l·∫∑p 11/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.191881

=== L·∫ßn l·∫∑p 12/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.202822

=== L·∫ßn l·∫∑p 13/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.350772

=== L·∫ßn l·∫∑p 14/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 0.781042

=== L·∫ßn l·∫∑p 15/15 ===
ƒê·ªô d·ªãch chuy·ªÉn t√¢m c·ª•m: 2.036996


ƒêang l∆∞u t√¢m c·ª•m cu·ªëi c√πng v√†o HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

K√≠ch th∆∞·ªõc c√°c c·ª•m:
  C·ª•m 0: 51,192,094 ƒëi·ªÉm (28.49%)
  C·ª•m 1: 43,618,958 ƒëi·ªÉm (24.27%)
  C·ª•m 2: 39,589,984 ƒëi·ªÉm (22.03%)
  C·ª•m 3: 41,396,172 ƒëi·ªÉm (23.04%)
  C·ª•m 4: 3,905,021 ƒëi·ªÉm (2.17%)

‚úÖ Ho√†n th√†nh thu·∫≠t to√°n K-means clustering!

‚úÖ PySpark K-means ho√†n th√†nh!
T√¢m c·ª•m cu·ªëi c√πng ƒë√£ l∆∞u v√†o HDFS: hdfs://localhost:9000/user/spark/hi_large/output_centroids

ƒê·ªÉ xem k·∫øt qu·∫£:
  hdfs dfs -cat /user/spark/hi_large/output_centroids/part-*
‚è±Ô∏è  **B∆∞·ªõc 5 ho√†n th√†nh trong 27m 34s**

### B∆∞·ªõc 6: T·∫£i k·∫øt qu·∫£ t·ª´ HDFS

=== T·∫¢I K·∫æT QU·∫¢ T·ª™ HDFS ===
‚úÖ ƒê√£ t√¨m th·∫•y k·∫øt qu·∫£ trong HDFS

ƒêang t·∫£i t√¢m c·ª•m cu·ªëi c√πng...
  T·ª´: /user/spark/hi_large/output_centroids
  ƒê·∫øn: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt
‚úÖ ƒê√£ t·∫£i t√¢m c·ª•m cu·ªëi c√πng

Th√¥ng tin file local:
  K√≠ch th∆∞·ªõc: 4,0K
  S·ªë d√≤ng (c·ª•m): 5

Xem tr∆∞·ªõc:
-0.002416,-0.002601,-0.000938,0.157297,-1.031620,0.062556,-0.513182,-0.512176,0.136520
-0.000230,-0.002411,-0.000286,-0.029543,0.644693,-0.907091,-0.490709,-0.501816,0.081444
0.006580,0.008891,0.002813,0.002821,-0.021032,0.012481,1.685821,1.690902,0.118926
-0.002799,-0.002482,-0.001118,-0.139795,0.640843,0.946155,-0.503855,-0.498938,0.157001
-0.002737,-0.002401,-0.001121,-0.251926,-0.169359,-0.409522,0.355893,0.364131,-4.562158

‚úÖ Ho√†n th√†nh t·∫£i xu·ªëng!

B∆∞·ªõc ti·∫øp theo:
  1. G√°n c·ª•m: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python assign_clusters_polars.py
  2. Ph√¢n t√≠ch k·∫øt qu·∫£: cd /home/ultimatebrok/Downloads/Final/scripts/polars && python analyze_polars.py
‚è±Ô∏è  **B∆∞·ªõc 6 ho√†n th√†nh trong 3s**

### B∆∞·ªõc 7: G√°n c·ª•m v·ªõi Polars

======================================================================
üè∑Ô∏è  B∆Ø·ªöC 7: G√ÅN NH√ÉN C·ª§M CHO T·ªÆNG GIAO D·ªäCH
======================================================================

üéØ ƒê·ªåC T√ÇM C·ª§M CU·ªêI C√ôNG T·ª™ B∆Ø·ªöC 6...
   File: /home/ultimatebrok/Downloads/Final/data/processed/final_centroids.txt

‚úÖ ƒê√£ load 5 t√¢m c·ª•m
   M·ªói t√¢m c·ª•m c√≥ 9 ƒë·∫∑c tr∆∞ng

üìÇ ƒê·ªåC D·ªÆ LI·ªÜU T·ª™ HDFS...
   File HDFS: /user/spark/hi_large/input/hadoop_input.txt
   (179M d√≤ng, 33GB - ƒë√£ chu·∫©n h√≥a)

üîÑ Streaming t·ª´ HDFS (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...
üìä ƒêang ƒë·ªçc CSV t·ª´ HDFS stream...

‚úÖ ƒê√£ load 179,702,229 b·∫£n ghi t·ª´ HDFS

üìä CHUY·ªÇN SANG NUMPY V√Ä T√çNH KHO·∫¢NG C√ÅCH...
   D·ªØ li·ªáu: 179,702,229 d√≤ng x 9 c·ªôt
   T√¢m c·ª•m: 5 c·ª•m x 9 ƒë·∫∑c tr∆∞ng

üî¢ T√çNH KHO·∫¢NG C√ÅCH EUCLIDEAN (Batch Processing)...
   X·ª≠ l√Ω 1 tri·ªáu giao d·ªãch m·ªói l·∫ßn ƒë·ªÉ ti·∫øt ki·ªám RAM

    ƒê√£ x·ª≠ l√Ω 1,000,000/179,702,229 giao d·ªãch (0.6%)
    ƒê√£ x·ª≠ l√Ω 11,000,000/179,702,229 giao d·ªãch (6.1%)
    ƒê√£ x·ª≠ l√Ω 21,000,000/179,702,229 giao d·ªãch (11.7%)
    ƒê√£ x·ª≠ l√Ω 31,000,000/179,702,229 giao d·ªãch (17.3%)
    ƒê√£ x·ª≠ l√Ω 41,000,000/179,702,229 giao d·ªãch (22.8%)
    ƒê√£ x·ª≠ l√Ω 51,000,000/179,702,229 giao d·ªãch (28.4%)
    ƒê√£ x·ª≠ l√Ω 61,000,000/179,702,229 giao d·ªãch (33.9%)
    ƒê√£ x·ª≠ l√Ω 71,000,000/179,702,229 giao d·ªãch (39.5%)
    ƒê√£ x·ª≠ l√Ω 81,000,000/179,702,229 giao d·ªãch (45.1%)
    ƒê√£ x·ª≠ l√Ω 91,000,000/179,702,229 giao d·ªãch (50.6%)
    ƒê√£ x·ª≠ l√Ω 101,000,000/179,702,229 giao d·ªãch (56.2%)
    ƒê√£ x·ª≠ l√Ω 111,000,000/179,702,229 giao d·ªãch (61.8%)
    ƒê√£ x·ª≠ l√Ω 121,000,000/179,702,229 giao d·ªãch (67.3%)
    ƒê√£ x·ª≠ l√Ω 131,000,000/179,702,229 giao d·ªãch (72.9%)
    ƒê√£ x·ª≠ l√Ω 141,000,000/179,702,229 giao d·ªãch (78.5%)
    ƒê√£ x·ª≠ l√Ω 151,000,000/179,702,229 giao d·ªãch (84.0%)
    ƒê√£ x·ª≠ l√Ω 161,000,000/179,702,229 giao d·ªãch (89.6%)
    ƒê√£ x·ª≠ l√Ω 171,000,000/179,702,229 giao d·ªãch (95.2%)
    ƒê√£ x·ª≠ l√Ω 179,702,229/179,702,229 giao d·ªãch (100.0%)

‚úÖ ƒê√£ ho√†n th√†nh t√≠nh to√°n cho 179,702,229 giao d·ªãch

üíæ L∆ØU K·∫æT QU·∫¢...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
======================================================================
‚úÖ HO√ÄN T·∫§T G√ÅN NH√ÉN C·ª§M!
======================================================================
üìÑ File k·∫øt qu·∫£: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
üìä K√≠ch th∆∞·ªõc: 342.75 MB
üìä T·ªïng giao d·ªãch: 179,702,229

üìä PH√ÇN PH·ªêI C·ª§M:
   Cluster 0: 51,192,096 giao d·ªãch (28.49%)
   Cluster 1: 43,618,956 giao d·ªãch (24.27%)
   Cluster 2: 39,589,983 giao d·ªãch (22.03%)
   Cluster 3: 41,396,173 giao d·ªãch (23.04%)
   Cluster 4: 3,905,021 giao d·ªãch (2.17%)

üí° G·ª¢I √ù TI·∫æP THEO:
   Ch·∫°y b∆∞·ªõc 8: python scripts/polars/analyze_polars.py

‚è±Ô∏è  **B∆∞·ªõc 7 ho√†n th√†nh trong 3m 15s**

### B∆∞·ªõc 8: Ph√¢n t√≠ch k·∫øt qu·∫£

======================================================================
üìä B∆Ø·ªöC 8: PH√ÇN T√çCH K·∫æT QU·∫¢
======================================================================

üìÇ ƒê·ªåC K·∫æT QU·∫¢ PH√ÇN C·ª§M T·ª™ B∆Ø·ªöC 7...
   File: /home/ultimatebrok/Downloads/Final/data/results/clustered_results.txt
‚úÖ ƒê√£ load 179,702,229 nh√£n c·ª•m

üìä ƒê·ªåC D·ªÆ LI·ªÜU G·ªêC (Lazy Mode)...
   File: /home/ultimatebrok/Downloads/Final/data/raw/HI-Large_Trans.csv
‚úÖ ƒê√£ load metadata (ch∆∞a load to√†n b·ªô v√†o RAM)

üéØ TH√äM C·ªòT 'cluster' V√ÄO DATA...
‚úÖ ƒê√£ g·∫Øn nh√£n c·ª•m cho m·ªói giao d·ªãch

======================================================================
üìã PH√ÇN T√çCH CHI TI·∫æT
======================================================================

üìà TH·ªêNG K√ä T·ªîNG QUAN:
   T·ªïng s·ªë giao d·ªãch: 179,702,229
   S·ªë c·ª•m: 5

üìâ K√çCH TH∆Ø·ªöC M·ªñI C·ª§M:
----------------------------------------------------------------------
shape: (5, 2)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ count    ‚îÇ
‚îÇ ---     ‚îÜ ---      ‚îÇ
‚îÇ i64     ‚îÜ u32      ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 51192096 ‚îÇ
‚îÇ 1       ‚îÜ 43618956 ‚îÇ
‚îÇ 2       ‚îÜ 39589983 ‚îÇ
‚îÇ 3       ‚îÜ 41396173 ‚îÇ
‚îÇ 4       ‚îÜ 3905021  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí∞ T·ª∂ L·ªÜ R·ª¨A TI·ªÄN TRONG T·ªÆNG C·ª§M:
----------------------------------------------------------------------
shape: (5, 4)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ total    ‚îÜ laundering_count ‚îÜ laundering_rate ‚îÇ
‚îÇ ---     ‚îÜ ---      ‚îÜ ---              ‚îÜ ---             ‚îÇ
‚îÇ i64     ‚îÜ u32      ‚îÜ i64              ‚îÜ f64             ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 51192096 ‚îÜ 67243            ‚îÜ 0.131354        ‚îÇ
‚îÇ 1       ‚îÜ 43618956 ‚îÜ 57879            ‚îÜ 0.132692        ‚îÇ
‚îÇ 2       ‚îÜ 39589983 ‚îÜ 34091            ‚îÜ 0.08611         ‚îÇ
‚îÇ 3       ‚îÜ 41396173 ‚îÜ 64725            ‚îÜ 0.156355        ‚îÇ
‚îÇ 4       ‚îÜ 3905021  ‚îÜ 1608             ‚îÜ 0.041178        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö†Ô∏è  C·ª§M C√ì R·ª¶I RO CAO (>10% r·ª≠a ti·ªÅn):
----------------------------------------------------------------------
‚úÖ KH√îNG c√≥ c·ª•m n√†o v∆∞·ª£t ng∆∞·ª°ng 10%
   T·∫•t c·∫£ c√°c c·ª•m ƒë·ªÅu trong m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.

üìä ƒê·∫∂C TR∆ØNG TRUNG B√åNH M·ªñI C·ª§M:
----------------------------------------------------------------------
shape: (5, 4)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cluster ‚îÜ avg_amount_received ‚îÜ avg_amount_paid ‚îÜ avg_ratio ‚îÇ
‚îÇ ---     ‚îÜ ---                 ‚îÜ ---             ‚îÜ ---       ‚îÇ
‚îÇ i64     ‚îÜ f64                 ‚îÜ f64             ‚îÜ f64       ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 0       ‚îÜ 1.3970e6            ‚îÜ 360672.187453   ‚îÜ 1.161493  ‚îÇ
‚îÇ 1       ‚îÜ 4.9691e6            ‚îÜ 641575.511352   ‚îÜ 1.693777  ‚îÇ
‚îÇ 2       ‚îÜ 1.7626e7            ‚îÜ 1.6323e7        ‚îÜ 4.293174  ‚îÇ
‚îÇ 3       ‚îÜ 518762.191972       ‚îÜ 518762.191972   ‚îÜ 1.0       ‚îÇ
‚îÇ 4       ‚îÜ 804.072407          ‚îÜ 804.072407      ‚îÜ 1.0       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí° NH·∫¨N X√âT:
----------------------------------------------------------------------
1. C·ª§m nghi ng·ªù NH·∫§T: Cluster 3 (0.16% r·ª≠a ti·ªÅn)
   ‚û°Ô∏è  N√™n ki·ªÉm tra k·ªπ c√°c giao d·ªãch trong c·ª•m n√†y

2. C·ª•m an to√†n NH·∫§T: Cluster 4 (0.04% r·ª≠a ti·ªÅn)
   ‚û°Ô∏è  C√≥ th·ªÉ ∆∞u ti√™n th·∫•p khi ki·ªÉm tra

3. ƒê√°nh gi√° t·ªïng th·ªÉ: ‚úÖ R·ª¶I RO TH·∫§P
   H·ªá th·ªëng ho·∫°t ƒë·ªông t·ªët, t·ª∑ l·ªá r·ª≠a ti·ªÅn th·∫•p

======================================================================
‚úÖ HO√ÄN T·∫§T PH√ÇN T√çCH!
======================================================================

üìä T√ìM T·∫¢T:
   - ƒê√£ ph√¢n t√≠ch 179,702,229 giao d·ªãch
   - Ph√¢n th√†nh 5 c·ª•m
   - T·ª∑ l·ªá r·ª≠a ti·ªÅn: 0.04% - 0.16%
   - S·ªë c·ª•m r·ªßi ro cao: 0 (‚úÖ T·ªët!)

üéâ PIPELINE HO√ÄN T·∫§T!
   T·∫•t c·∫£ 8 b∆∞·ªõc ƒë√£ ch·∫°y th√†nh c√¥ng.
   Xem k·∫øt qu·∫£ trong th∆∞ m·ª•c data/results/

‚è±Ô∏è  **B∆∞·ªõc 8 ho√†n th√†nh trong 27s**


---

## T·ªïng k·∫øt

‚úÖ **Pipeline ho√†n th√†nh th√†nh c√¥ng!**

**Th·ªùi gian k·∫øt th√∫c:** 2025-10-29 09:19:29
**T·ªïng th·ªùi gian ch·∫°y:** 33m 35s

---

*Log ƒë√£ l∆∞u t·∫°i: /home/ultimatebrok/Downloads/Final/logs/pipeline_log_20251029_084554.md*
